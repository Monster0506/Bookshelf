[
  {
    "id": "20240810235545437215339",
    "title": "Monorepo Explained",
    "source": "https://monorepo.tools",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Coding",
      "Reference"
    ]
  },
  {
    "id": "20240810235628954769169",
    "title": "The Joy of Cryptography",
    "source": "https://joyofcryptography.com",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Coding",
      "Cryptography"
    ],
    "note": "",
    "read": {
      "text": "2 min read",
      "minutes": 1.885,
      "time": 113100,
      "words": 377
    }
  },
  {
    "id": "20240810235642013572342",
    "title": "Lambda Calculus",
    "source": "https://learnxinyminutes.com/docs/lambda-calculus/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Math"
    ],
    "read": {
      "text": "5 min read",
      "minutes": 4.435,
      "time": 266100,
      "words": 887
    }
  },
  {
    "id": "20240810235821716610994",
    "title": "Jimmy Miller",
    "source": "https://jimmyhmiller.github.io/",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Blog"
    ],
    "read": {
      "text": "1 min read",
      "minutes": 0.715,
      "time": 42900,
      "words": 143
    }
  },
  {
    "id": "20240810235915846818828",
    "title": "Algorithms",
    "source": "/uploads/1722892109377551242-Algorithms-JeffE.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "Coding"
    ],
    "read": {
      "text": "3079 min read",
      "minutes": 3078.22,
      "time": 184693200,
      "words": 615644
    }
  },
  {
    "id": "20240810235922902675428",
    "title": "How to build anything",
    "source": "https://learnhowtolearn.org/how-to-build-extremely-quickly/",
    "fileType": "URL",
    "status": "unread",
    "tags": [],
    "read": {
      "text": "8 min read",
      "minutes": 7.71,
      "time": 462600,
      "words": 1542
    }
  },
  {
    "id": "20240811000021181142892",
    "title": "Complete Guide to Memory",
    "source": "/uploads/1722914053841702807-The_Complete_Guide_to_Memory.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "CompleteGuide",
      "Memory"
    ],
    "read": {
      "text": "199 min read",
      "minutes": 198.33,
      "time": 11899800,
      "words": 39666
    }
  },
  {
    "id": "20240811000032703498597",
    "title": "Complete Guide to Motivation",
    "source": "/uploads/1722914104197293529-The_Complete_Guide_to_Motivation.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "CompleteGuide"
    ],
    "read": {
      "text": "329 min read",
      "minutes": 328.49,
      "time": 19709400,
      "words": 65698
    }
  },
  {
    "id": "20240811000042918603676",
    "title": "Complete Guide to Self Control",
    "source": "/uploads/1722914268900348773-The_Complete_Guide_to_Self-Control.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "CompleteGuide"
    ],
    "read": {
      "text": "362 min read",
      "minutes": 361.555,
      "time": 21693300,
      "words": 72311
    }
  },
  {
    "id": "20240811000054535421195",
    "title": "Complete Guide to Working Memory",
    "source": "/uploads/1722914286904829269-The_Complete_Guide_to_Working_Memory.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "CompleteGuide",
      "Memory"
    ],
    "read": {
      "text": "262 min read",
      "minutes": 261.165,
      "time": 15669900,
      "words": 52233
    }
  },
  {
    "id": "20240811000103939247772",
    "title": "10 Mental Models for Learning Anything",
    "source": "/uploads/1722914375652148443-Ten_Mental_Models_for_Learning_Anything.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "CompleteGuide"
    ],
    "read": {
      "text": "121 min read",
      "minutes": 120.255,
      "time": 7215300,
      "words": 24051
    }
  },
  {
    "id": "20240811000119483455537",
    "title": "Invent with Python",
    "source": "https://inventwithpython.com/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Python",
      "Coding"
    ],
    "read": {
      "text": "12 min read",
      "minutes": 11.825,
      "time": 709500,
      "words": 2365
    }
  },
  {
    "id": "20240811000134061949346",
    "title": "Ethics in Robotics",
    "source": "/uploads/1723312043685919838-EthicsInRobotics.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "Coding",
      "Ethics"
    ],
    "read": {
      "text": "782 min read",
      "minutes": 781.825,
      "time": 46909500,
      "words": 156365
    }
  },
  {
    "id": "20240811000141719403416",
    "title": "Privacy Issues of AI",
    "source": "/uploads/1723312089221519738-AIPrivacy.pdf",
    "fileType": "PDF",
    "status": "read",
    "tags": [
      "Ethics",
      "AI"
    ],
    "archived": false,
    "read": {
      "text": "58 min read",
      "minutes": 57.42,
      "time": 3445200,
      "words": 11484
    }
  },
  {
    "id": "20240811003453090468219",
    "title": "Mere Imitation",
    "source": "https://aeon.co/essays/is-ai-our-salvation-our-undoing-or-just-more-of-the-same?utm_source=pocket-newtab-en-us",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "AI",
      "Ethics"
    ],
    "read": {
      "text": "60 min read",
      "minutes": 59.985,
      "time": 3599100,
      "words": 11997
    }
  },
  {
    "id": "20240811004458501241316",
    "title": "Six Basic Shapes of Stories",
    "source": "https://arxiv.org/pdf/1606.07772",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Interesting",
      "Paper"
    ],
    "read": {
      "text": "2640 min read",
      "minutes": 2639.89,
      "time": 158393400,
      "words": 527978
    }
  },
  {
    "id": "20240811004906526362823",
    "title": "Story Shapes",
    "source": "https://www.youtube.com/embed/oP3c1h8v2ZQ",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Interesting"
    ],
    "archived": true,
    "read": {
      "text": "1 min read",
      "minutes": 0.14,
      "time": 8400,
      "words": 28
    }
  },
  {
    "id": "20240811005000615457554",
    "title": "Why we do not support redistribution",
    "source": "https://thereader.mitpress.mit.edu/why-do-we-not-support-redistribution/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Politics",
      "Psychology"
    ],
    "read": {
      "text": "13 min read",
      "minutes": 12.61,
      "time": 756600,
      "words": 2522
    }
  },
  {
    "id": "20240811005748701183751",
    "title": "Why the cognitive-map theory is misguided",
    "source": "https://nautil.us/theres-no-homunculus-in-our-brain-who-guides-us-237709/",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Interesting",
      "Psychology"
    ],
    "archived": true,
    "read": {
      "text": "27 min read",
      "minutes": 26.48,
      "time": 1588800,
      "words": 5296
    }
  },
  {
    "title": "The Future Encyclopedia of Luddism",
    "source": "https://thereader.mitpress.mit.edu/the-future-encyclopedia-of-luddism/",
    "fileType": "URL",
    "status": "read",
    "id": "20240811120801187433537",
    "date": "2024-08-11T16:08:01.187Z",
    "archived": true,
    "read": {
      "text": "20 min read",
      "minutes": 19.775,
      "time": 1186500,
      "words": 3955
    }
  },
  {
    "id": "20240811175248532517750",
    "title": "PI^2 ~= g",
    "source": "https://roitman.io/blog/91",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Math",
      "Interesting",
      "asdfasdf"
    ],
    "archived": true,
    "read": {
      "text": "162 min read",
      "minutes": 161.215,
      "time": 9672900,
      "words": 32243
    }
  },
  {
    "id": "20240812192052797496885",
    "title": "Modulo Operator",
    "source": "https://felipec.wordpress.com/2024/08/11/everyone-is-using-modulo-wrong/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Math",
      "Coding"
    ],
    "read": {
      "text": "23 min read",
      "minutes": 22.91,
      "time": 1374600,
      "words": 4582
    },
    "markdown": "<p><blockquote>shows that many of the notions we take for granted are in fact not necessarily true.</blockquote></p><p><blockquote>) for as long as I can remember, but when I tipped my toes into the mathematics of group theory, I realized that properly understanding modular arithmetic shatters some of the concepts that people take for granted, not just in programming, but in everyday life.</blockquote></p><p><blockquote>arithmetic_ is?</blockquote></p><p><blockquote>says so.</blockquote>\n<blockquote>Let’s define the modulo operation in the simplest terms possible that apply to both computation and mathematics.</blockquote></p><p><blockquote>That formula says that two numbers <em>a</em> and <em>b</em> are considered <a href=\"https://en.wikipedia.org/wiki/Modular<em>arithmetic#Congruence\">congruent</a> with each other under modulo </em>m<em> if there’s an integer </em>k<em> that satisfies the difference. In other words: <code>a − b</code> is divisible by </em>m_.</blockquote></p><p><blockquote>are also congruent.</blockquote></p><p><blockquote>).</blockquote></p><p>{…,−15,−11,−7,−3,1,5,9,13,17,…}</p><p>Programmers might find this formula for modular congruence a bit easier to understand:</p><p><blockquote>If <code>13 % 4 = 1</code> and <code>17 % 4 = 1</code>, then <code>13</code> and <code>17</code> are congruent with each other (under <code>mod 4</code>), and we directly see what that actually means: they have the same remainder.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>. So the equivalence above depends on the implementation of the modulo operator, which doesn’t make sense mathematically, because mathematics doesn’t depend on implementation. Underneath the modulo operator there should be some mathematical principle at work, so which is it?</blockquote></p><p>In actual mathematics the formula is:</p><p><blockquote>)</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>, but is that really the best answer? To understand that we need to go beyond the naive understanding of modulo.</blockquote>\n<blockquote>In elementary school we are taught “arithmetic”, but it turns out there’s multiple arithmetics, and you’ve probably encountered more than a few, for example you might have added two vectors in physics. Arithmetic does not only apply to numbers, you can add two linear transformations (for example two 180° rotations), two booleans (<code>true + true = false</code>), or even two Rubik’s Cube moves (<code>L + R = M'</code>).</blockquote></p><p><blockquote>does not necessarily follow the same rules as basic arithmetic.</blockquote></p><p>If we limit ourselves to integer arithmetic, the set we are operating on is obviously integers:</p><p>ℤ={…,−3,−2,−1,0,1,2,3,…}</p><p><blockquote>).</blockquote></p><p><blockquote>the set is called “the ring of integers modulo 4”: ℤ/4ℤ.</blockquote></p><p>ℤ/4ℤ={\\[0\\],\\[1\\],\\[2\\],\\[3\\]}</p><p><blockquote>of the set is going to result in another element of the same set.</blockquote></p><p>Therefore 3 + 1 cannot be 4, because 4 is not in the set.</p><p><blockquote>.</blockquote></p><p>\\[1\\]={…,−7,−3,1,5,9,…}</p><p>In truth ℤ/4ℤ is a set of sets.</p><p><blockquote>.</blockquote></p><p>\\[0\\]={…,−16,−12,−8,−4,0,4,8,12,16,…}</p><p><blockquote>and therefore should be considered equivalent, or more mathematically:</blockquote></p><p>−3 ≡ 1 (mod 4)</p><p><blockquote>is divisible by 4.</blockquote>\n<blockquote>Hopefully at this point I’ve demonstrated the relationship between the mathematical concept of <a href=\"https://en.wikipedia.org/wiki/Modular_arithmetic\">modular arithmetic</a> and the computational operation <a href=\"https://en.wikipedia.org/wiki/Modulo\">modulo</a>, but so what? This is useless trivia, right?</blockquote></p><p><blockquote>.</blockquote></p><p>The problem is simple: I want to know which days were Saturday in the previous 30 days.</p><p><blockquote>.</blockquote></p><p><blockquote>, and the results of that do not match with my understanding of modular arithmetic.</blockquote></p><p><blockquote>Let’s start from the beginning with a naive implementation of the truncated division method in JavaScript:</blockquote></p><p><blockquote>a - n * Math.trunc(a / n);</blockquote></p><p><blockquote>If we truncate <code>−1 / 7</code>, we get <code>−0</code>, therefore <code>mod_trunc(−1, 7)</code> gives us <code>−1</code>, because <code>−1 − −0</code> is <code>−1</code>. The result is the same as <code>a % n</code> (in JavaScript).</blockquote></p><p><blockquote>(Saturday).</blockquote></p><p><blockquote>want is the result of the floored division method, not the truncated division method, and there’s a straightforward way to convert one to the other:</blockquote></p><p><blockquote>(a % n + n) % n;</blockquote></p><p><blockquote>This is basically adding <em>n</em>, but we’ll soon see how it’s not quite the same.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>floor(d, 7) == 6;</blockquote>\n<blockquote>is_saturday(e));</blockquote>\n[ true, true, true ]</p><p><blockquote>Clearly the floored method is more useful than the truncated method, so why are most implementations using the truncated method? Because truncation is less computationally expensive than flooring.</blockquote></p><p><blockquote>with negative numbers anyway? Designers of programming languages decided it wasn’t often enough, so truncation should be fine.</blockquote></p><p><blockquote>, but it’s not freely available, so I can’t verify that.</blockquote></p><p><blockquote>. But it isn’t, at least not in most programming languages.</blockquote></p><p><blockquote>if (((6 - 7) % 7) != 6) return \"your programming language sucks\"</blockquote></p><p><blockquote>Either way, we found a solution to the problem when <em>a</em> is negative and the implementation of mod is using the truncated method, are we done?</blockquote>\n<blockquote>So far we’ve only considered a positive divisor, what happens when the divisor is negative?</blockquote></p><p>7 % −4</p><p>For now let’s ignore what different implementations do and focus on the math:</p><p>7 ≡ 3 (mod −4)</p><p><blockquote>. So is there any difference?</blockquote></p><p>Let’s return to our main formula:</p><p><blockquote>Any two numbers <em>a</em> and <em>b</em> are considered congruent under modulo −4 if they are divisible by −4. Obviously if they are divisible by −4 they are divisible by 4 too.</blockquote></p><p><blockquote>to the ring of integers modulo 4.</blockquote></p><p>ℤ/(−4)ℤ={\\[0\\],\\[1\\],\\[2\\],\\[3\\]}</p><p><blockquote>?</blockquote></p><p>Let’s consider a practical example of calculating how many hours are left in the day:</p><p><blockquote>24 - h;</blockquote></p><p><blockquote>OK, that was easy, but it only works for hours less than or equal to 24, what if I want to calculate the remaining hours of 42 or 20 hours from now? Just wrap the hours, right? <code>h % 24</code>. Except now when the hour is <code>24</code> I get <code>24</code> instead of <code>0</code>, because <code>24 % 24</code> is <code>0</code>, and <code>24 − 0</code> is <code>24</code>. So clearly the solution is to check for that special case.</blockquote></p><p><blockquote>{ const r = h % 24; return r == 0 ? r : 24 - r; };</blockquote></p><p><blockquote>Or we can be a little bit smarter and realize that if we wrap the entire thing, <code>24</code> will go back to <code>0</code>:</blockquote></p><p><blockquote>(24 - (h % 24)) % 24;</blockquote></p><p><blockquote>This construct looks familiar, but before we look into that, let’s try to understand what we are actually doing by switching to <code>mod 4</code>:</blockquote></p><p><blockquote>This is a cyclic countdown that ends in <code>0</code> if the number is divisible by 4.</blockquote></p><p><blockquote>gives us (using the correct floored division method):</blockquote></p><p><blockquote>Would you look at that? It’s basically <strong>the same thing</strong>. We can think of <code>mod −4</code> as a mirror of <code>mod 4</code> but instead of the distance since the last cycle, it’s the distance to the next cycle.</blockquote></p><p>ℤ/(−4)ℤ={\\[−0\\],\\[−3\\],\\[−2\\],\\[−1\\]}</p><p><blockquote>, but this sequence is more useful to us programmers.</blockquote></p><p>So our code ends up really simple:</p><p><blockquote>floor(h, -24);</blockquote></p><p><blockquote>But remember this construct <code>(24 − (h % 24)) % 24</code>? This is very reminiscent to our <code>mod_floor</code> implementation: <code>(a % n + n) % n</code> isn’t it? The only difference is that <code>h</code> is negative, so:</blockquote></p><p><blockquote>floor(-h, 24);</blockquote></p><p><blockquote>It turns out that <code>a % −n</code> is exactly the same thing as <code>−(−a % n)</code> (if we use the floored method).</blockquote></p><p>Let’s consider the formula for the floored division method:</p><p><blockquote>In both cases (when the dividend is negative or the divisor is negative) the fraction will end up negative, and in both cases the outside elements will end up positive. So it’s essentially a mirror.</blockquote></p><p><blockquote>That’s all we need to know regarding <code>mod</code> with negative numbers: the floored division method Just Works ™.</blockquote>\n<blockquote>Hopefully now you understand why the modulo of negative numbers is very useful, and why most implementations of the computational operation <em>modulo</em> are wrong, but this understanding would not have been possible for me to explain if I hadn’t dived into <a href=\"https://en.wikipedia.org/wiki/Group_theory\">group theory</a>, and the reason why I did that was to try to explain why one assumption which everyone makes is not necessarily true.</blockquote></p><p><blockquote>).</blockquote></p><p><blockquote>to understand concepts, and it’s up to us to decide how to use that tool.</blockquote></p><p><blockquote>is not necessarily as elementary as an addition of two numbers under basic arithmetic.</blockquote></p><p><blockquote>because modulo is a precise mathematical operation — a world of possibilities opens up to us.</blockquote></p>"
  },
  {
    "id": "20240813001414887308071",
    "title": "AI Safety for Humans 1",
    "source": "https://aisafety.dance/",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "AI",
      "Ethics"
    ],
    "archived": true,
    "read": {
      "text": "30 min read",
      "minutes": 29.705,
      "time": 1782300,
      "words": 5941
    }
  },
  {
    "id": "20240813001440355702678",
    "title": "AI Safety for Humans 2",
    "source": "https://aisafety.dance/p2/",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "AI",
      "Ethics"
    ],
    "archived": true,
    "read": {
      "text": "79 min read",
      "minutes": 78.12,
      "time": 4687200,
      "words": 15624
    }
  },
  {
    "id": "20240814113530828117366",
    "title": "Artifical Intellegence can Predict the Shape of Folded Protiens",
    "source": "https://web.archive.org/web/20231204110638/https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "Interesting",
      "Biology"
    ],
    "archived": true,
    "read": {
      "text": "11 min read",
      "minutes": 10.025,
      "time": 601500,
      "words": 2005
    }
  },
  {
    "id": "20240814115838782287002",
    "title": "Specification Gaming with Map Encoding",
    "source": "https://arxiv.org/pdf/1712.02950",
    "fileType": "URL",
    "status": "read",
    "tags": [
      "AI"
    ],
    "archived": true,
    "read": {
      "text": "239 min read",
      "minutes": 238.715,
      "time": 14322900,
      "words": 47743
    }
  },
  {
    "id": "20240818225240288961660",
    "title": "Increase Retention",
    "source": "https://files.eric.ed.gov/fulltext/ED505647.pdf",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Memory"
    ],
    "read": {
      "text": "31 min read",
      "minutes": 30.875,
      "time": 1852500,
      "words": 6175
    },
    "markdown": "<html xmlns=\"http://www.w3.org/1999/xhtml\">\r\n<head>\r\n<meta name=\"pdf:PDFVersion\" content=\"1.5\"/>\r\n<meta name=\"xmp:CreatorTool\" content=\"Acrobat PDFMaker 7.0.7 for Word\"/>\r\n<meta name=\"pdf:docinfo:title\" content=\"Increasing Retention without Increasing Study Time\"/>\r\n<meta name=\"pdf:hasXFA\" content=\"false\"/>\r\n<meta name=\"access_permission:modify_annotations\" content=\"true\"/>\r\n<meta name=\"access_permission:can_print_degraded\" content=\"true\"/>\r\n<meta name=\"dc:creator\" content=\"Doug Rohrer &amp; Hal Pashler\"/>\r\n<meta name=\"dcterms:created\" content=\"2007-04-06T22:04:38Z\"/>\r\n<meta name=\"dcterms:modified\" content=\"2009-06-10T18:58:54Z\"/>\r\n<meta name=\"dc:format\" content=\"application/pdf; version=1.5\"/>\r\n<meta name=\"xmpMM:DocumentID\" content=\"uuid:f1e94355-b4eb-42c5-b90a-c1194c182a31\"/>\r\n<meta name=\"pdf:docinfo:creator_tool\" content=\"Acrobat PDFMaker 7.0.7 for Word\"/>\r\n<meta name=\"access_permission:fill_in_form\" content=\"true\"/>\r\n<meta name=\"pdf:docinfo:modified\" content=\"2009-06-10T18:58:54Z\"/>\r\n<meta name=\"pdf:hasCollection\" content=\"false\"/>\r\n<meta name=\"pdf:encrypted\" content=\"false\"/>\r\n<meta name=\"dc:title\" content=\"Increasing Retention without Increasing Study Time\"/>\r\n<meta name=\"xmp:CreateDate\" content=\"2007-04-06T18:04:38Z\"/>\r\n<meta name=\"Content-Length\" content=\"348266\"/>\r\n<meta name=\"pdf:hasMarkedContent\" content=\"false\"/>\r\n<meta name=\"Content-Type\" content=\"application/pdf\"/>\r\n<meta name=\"xmp:ModifyDate\" content=\"2009-06-10T11:58:54Z\"/>\r\n<meta name=\"pdf:docinfo:creator\" content=\"Doug Rohrer &amp; Hal Pashler\"/>\r\n<meta name=\"xmp:MetadataDate\" content=\"2009-06-10T11:58:54Z\"/>\r\n<meta name=\"pdf:producer\" content=\"Acrobat Distiller 7.0.5 (Windows)\"/>\r\n<meta name=\"xmp:About\" content=\"uuid:681471e5-88c5-43e5-bd3a-8e79124c3af5\"/>\r\n<meta name=\"access_permission:extract_for_accessibility\" content=\"true\"/>\r\n<meta name=\"access_permission:assemble_document\" content=\"true\"/>\r\n<meta name=\"xmpTPg:NPages\" content=\"4\"/>\r\n<meta name=\"resourceName\" content=\"ED505647.pdf\"/>\r\n<meta name=\"pdf:hasXMP\" content=\"true\"/>\r\n<meta name=\"access_permission:extract_content\" content=\"true\"/>\r\n<meta name=\"access_permission:can_print\" content=\"true\"/>\r\n<meta name=\"X-TIKA:Parsed-By\" content=\"org.apache.tika.parser.DefaultParser\"/>\r\n<meta name=\"X-TIKA:Parsed-By\" content=\"org.apache.tika.parser.pdf.PDFParser\"/>\r\n<meta name=\"access_permission:can_modify\" content=\"true\"/>\r\n<meta name=\"pdf:docinfo:producer\" content=\"Acrobat Distiller 7.0.5 (Windows)\"/>\r\n<meta name=\"pdf:docinfo:created\" content=\"2007-04-06T22:04:38Z\"/>\r\n<title>Increasing Retention without Increasing Study Time</title>\r\n</head>\r\n<body><div class=\"page\"><p/>\r\n<p>      In press version This manuscript may differ from the final published version  2007 (Vol. 132, 354-380)\r\n</p>\r\n<p>Current Directions in Psychological Science (in press version 2007)\r\n</p>\r\n<p>Increasing Retention without Increasing Study Time \r\n \r\n</p>\r\n<p>Doug Rohrer 1 and Hal Pashler 2 \r\n</p>\r\n<p> \r\n</p>\r\n<p>1 University of South Florida \r\n2 University of California, San Diego \r\n</p>\r\n<p> \r\nABSTRACT - Because people forget much of what they \r\nlearn, students could benefit from learning strategies that \r\nprovide long-lasting knowledge. Yet surprisingly little is \r\nknown about how long-term retention is most efficiently \r\nachieved. Here we examine how retention is affected by two \r\nvariables: the duration of a study session and the temporal \r\ndistribution of study time across multiple sessions. Our results \r\nsuggest that a single session devoted to the study of some \r\nmaterial should continue long enough to ensure that mastery is \r\nachieved but that immediate further study of the same material \r\nis an inefficient use of time. Our data also show that the \r\nbenefit of distributing a fixed amount of study time across two \r\nstudy sessions &ndash; the spacing effect &ndash; depends jointly on the \r\ninterval between study sessions and the interval between study \r\nand test. We discuss the practical implications of both \r\nfindings, especially in regard to mathematics learning. \r\n</p>\r\n<p> \r\n \r\n \r\n</p>\r\n<p>Address correspondence to Doug Rohrer, Psychology, \r\nPCD4118G, University of South Florida, Tampa, FL 33620, \r\nUSA. E-mail: drohrer@cas.usf.edu.  \r\n</p>\r\n<p> \r\nAcknowledgements. Our collaborators include Shana \r\nCarpenter, Nicholas Cepeda, Noriko Coburn, Michael Mozer, \r\nKelli Taylor, Ed Vol, and John Wixted. This research was \r\nsupported by the Institute of Education Sciences, U.S. \r\nDepartment of Education (Grant #R305H040108).   \r\n</p>\r\n<p> \r\n \r\nAlthough most people have spent thousands of hours in \r\n</p>\r\n<p>the classroom, the result of this effort is often surprisingly \r\ndisappointing. Indeed, both the popular press and the \r\nacademic literature are replete with examples of educational \r\nfailure among students and recent graduates. In one \r\nassessment of U.S. eighth graders, only 50% were able to \r\ncorrectly multiply -5 and -7 (Reese, Miller, Mazzeo, &amp; \r\nDossey, 1997), and a recent survey of young adults in the U.S. \r\nrevealed that most could not select the continent in which \r\nSudan is located (National Geographic, 2006). While such \r\nfindings are partly explained by the fact that some students \r\nnever learned the information in the first place, we believe that \r\nforgetting is often the cause.  \r\n</p>\r\n<p>For this reason, it seems important to define learning \r\nstrategies that can promote long-lasting retention. Yet \r\nsurprisingly little is known about the long-term effectiveness \r\nof most learning strategies. For this reason, we have been \r\nconducting learning experiments in which subjects are tested \r\nas much as one year after the final study session. In a further \r\nnod to ecological validity, our subjects learn the kinds of \r\n</p>\r\n<p>material that people often try to learn, such as vocabulary, \r\ngeography, foreign language, and mathematics (e.g., Pashler, \r\nRohrer, Cepeda, &amp; Carpenter, in press). In this review, we \r\nfocus on two decisions that all learners face: how long should \r\none study the same material before quitting or shifting to \r\ndifferent material, and how should a fixed amount of study \r\ntime be distributed across study sessions? \r\n</p>\r\n<p>  \r\n  \r\n  OVERLEARNING \r\n \r\nWhen learners choose to devote an uninterrupted period \r\n</p>\r\n<p>of time to learning some material or a skill, they must decide \r\nwhen to quit, regardless of whether they later return to the \r\nsame material. For example, once a student has cycled through \r\na list of vocabulary words until each definition has been \r\ncorrectly recalled exactly one time, the student must decide \r\nwhether to cycle again through the same list. The continuation \r\nof study immediately after the student has achieved error-free \r\nperformance is known as overlearning. Many educators argue \r\nthat overlearning is an effective way to boost long-term \r\nretention, and overlearning appears to be quite common in \r\nschools. In mathematics courses, for instance, assignments \r\ntypically include many problems of the same kind, thereby \r\nensuring that students devote much of their study time to \r\noverlearning. \r\n</p>\r\n<p> \r\nDoes Overlearning Produce Long-Lasting Benefits?  \r\n</p>\r\n<p>At first glance, the heavy reliance on overlearning might \r\nbe seen as consistent with the results of nearly 80 years of \r\nempirical literature. In these experiments, subjects either quit \r\nor continued studying after some criterion was reached, and \r\nthe additional study typically boosted subsequent test \r\nperformance (see Driskell, Willis, &amp; Cooper, 1992, for a meta-\r\nanalysis). Yet a closer examination of the literature led us to \r\nwonder whether the benefits of overlearning might be short-\r\nlived. In most overlearning studies, the test was given within a \r\nweek of the study session, and, in many cases, within an hour. \r\nTo determine how the benefits of overlearning hold up over \r\nmeaningful periods of time, we have been measuring the \r\neffects of overlearning after various retention intervals (RI), \r\nthe interval between study and test. For example, in one of our \r\nexperiments (Rohrer, Taylor, Pashler, Wixted, &amp; Cepeda, \r\n2005), subjects learned vocabulary by cycling through a list of \r\nword-definition pairs (e.g., cicatrix-scar) by repeatedly testing \r\nthemselves (cicatrix - ?, &hellip;, scar), as one would do with \r\nflashcards. They completed either 5 learning trials (Adequate \r\nLearning) or 10 learning trials (Overlearning).  Adequate \r\nLearners generally had no more than one perfect study trial, \r\nwhereas most Overlearners achieved at least three perfect </p>\r\n<p/>\r\n<div class=\"annotation\"><a href=\"mailto:drohrer@cas.usf.edu\">mailto:drohrer@cas.usf.edu</a></div>\r\n</div>\r\n<div class=\"page\"><p/>\r\n<p>                                    2 \r\n</p>\r\n<p>    \r\n</p>\r\n<p>trials. Subjects were tested either one or four weeks later. As \r\nshown in Figure 1, overlearning provided noticeable gains at \r\none week, but these gains were almost undetectable after four \r\nweeks. Other studies of ours have confirmed this pattern of \r\ndeclining overlearning benefits, although the length of time \r\nover which gains remain detectable varies with the details of \r\nthe procedure (e.g., Rohrer et al., 2005; Rohrer &amp; Taylor, \r\n2006). In summary, then, we see that while overlearning often \r\nincreases performance for a short while, the benefit diminishes \r\nsharply over time.  \r\n</p>\r\n<p>Overlearning Vocabulary  \r\n</p>\r\n<p>Retention Interval (weeks)\r\n1 4\r\n</p>\r\n<p>  Test \r\nScore\r\n</p>\r\n<p>0%\r\n</p>\r\n<p>100%\r\n</p>\r\n<p> Overlearning\r\n(10 list cycles)\r\n</p>\r\n<p>Adequate Learning \r\n   (5 list cycles)\r\n</p>\r\n<p>  \r\nFig 1.  Overlearning. Students learned ten word-definition pairs (e.g., \r\ncicatrix-scar) by cycling through the list 5 or 10 times via testing with \r\nfeedback (cicatrix-?, &hellip;, scar). On the subsequent test, the benefit for \r\nthe 10 trial condition was large after one week but undetectable after \r\nfour weeks. Error bars reflect plus or minus one standard error.  \r\n</p>\r\n<p> \r\nImplications \r\n</p>\r\n<p>In thinking through the practical implications of our \r\noverlearning results, it probably makes sense to focus on the \r\nrelative efficiency of overlearning versus alternative strategies. \r\nBecause overlearning requires more study time than not \r\noverlearning, the critical question is how the benefits of \r\noverlearning compare to the benefits resulting from some \r\nalternative use of the same time period. As we will see in the \r\nsecond part of this paper, it seems very likely that devoting \r\nthis study time to the review of materials studied weeks, \r\nmonths, or even years earlier will typically pay far greater \r\ndividends than the continued study of material learned just a \r\nmoment ago. In essence, overlearning simply provides very \r\nlittle bang for the buck, as each additional unit of \r\nuninterrupted study time provides an ever smaller return on \r\nthe investment of study time. (We hope it is clear that in \r\nquestioning the utility of overlearning, we are not suggesting \r\nthat students reduce their study time, nor are we disparaging \r\nthe use of drill and practice. Rather, we question the wisdom \r\nof providing continued practice on material right after error-\r\nfree performance has been achieved.)  \r\n</p>\r\n<p>There are, however, situations in which overlearning is \r\ndesirable. For instance, overlearning appears to be effective in \r\nthe short term and therefore might be a fine choice for learners \r\nwho do not seek long-term retention. In addition, there are \r\nsituations in which an error or even a delayed response might \r\nhave dire consequences &ndash; say, emergency routines performed \r\nby pilots, soldiers, or nurses &ndash; and here, overlearning is \r\nprobably advisable and perhaps even necessary.  \r\n</p>\r\n<p> \r\n</p>\r\n<p>SPACING OF LEARNING \r\n \r\nOverlearning speaks to one aspect of the broader question \r\n</p>\r\n<p>of how distribution of study time affects learning.  This area \r\nhas been the focus of research for more than a century (see \r\nCepeda, Pashler, Vul, Wixted, &amp; Rohrer, 2006, for a recent \r\nreview). In most research on this topic, a fixed amount of \r\nstudy time is divided across two sessions that are separated by \r\nan inter-session interval (ISI). If the ISI equals zero, study \r\ntime is said to be massed. Importantly, the retention interval is \r\nalways measured from the second study session. When tested \r\nlater, performance is usually much better if the study time is \r\nspaced rather than massed &ndash; a finding known as the spacing \r\neffect (e.g., Bahrick, 1979; Bjork, 1979). There are numerous \r\ntheoretical explanations for the spacing effect, but these are \r\nbeyond the scope of this article (see Dempster, 1989, for a \r\nreview).   \r\n</p>\r\n<p>While the superiority of spacing over massing is well \r\nestablished, less is known about how far apart the study \r\nsessions should be spaced to promote long-term retention. For \r\ninstance, does the duration of the inter-session interval affect \r\nmemory, and, if so, how? We have begun to seek answers to \r\nthese questions with experiments using long retention \r\nintervals. \r\n</p>\r\n<p> \r\nVarying the Inter-Session Interval \r\n</p>\r\n<p>In our first set of spacing experiments, we varied the \r\nInter-Session Interval separating the two study sessions, and \r\nthe retention interval was fixed (Cepeda, Mozer, Coburn, \r\nRohrer, Wixted, &amp; Pashler, 2007). In the first of these studies, \r\nstudents studied Swahili-English word pairs. The ISI ranged \r\nfrom 5 minutes to 14 days, and the RI was 10 days. ISI had a \r\nvery large effect on final-test recall, with the 1-day ISI \r\nyielding the best recall (Figure 2). In a second experiment in \r\nwhich subjects learned the names of some obscure objects, we \r\nused a six-month RI, and varied ISI from 5 minutes to 6 \r\nmonths. Effects were even bigger than in the first study, but \r\nthe optimal ISI was roughly one month (Figure 2).  \r\n  \r\n                       \r\n</p>\r\n<p>Effect of Varying ISI \r\n</p>\r\n<p>ISI \r\n</p>\r\n<p>0.0 RI 0.5 RI 1.0 RI 1.5 RI\r\n</p>\r\n<p> Test \r\nScore\r\n</p>\r\n<p>0%\r\n</p>\r\n<p>100%\r\n</p>\r\n<p>RI = 10 days\r\n(Swahili)\r\n</p>\r\n<p>RI = 6 months\r\n(Objects)\r\n</p>\r\n<p>ISI = 1 day = 10% of RI\r\n</p>\r\n<p>ISI = 1 month = 17% of RI\r\n</p>\r\n<p> \r\nFig 2.  Effect of Varying Inter-Session Interval.  In the Swahili \r\nexperiment, two study sessions were separated by an ISI of 0, 1, 2, 4, \r\n7, or 14 days, followed by a 10-day RI. In the Object Naming \r\nexperiment, an ISI of 0, 1, 7, 28, 84, or 168 days was followed by a \r\n6-month RI.  In both studies, the optimal ISI was about 10-20% of \r\nthe RI. Error bars reflect plus or minus one standard error.  \r\n </p>\r\n<p/>\r\n</div>\r\n<div class=\"page\"><p/>\r\n<p>                                    3 \r\n</p>\r\n<p>    \r\n</p>\r\n<p>The Interaction of the ISI and the RI \r\n In comparing the results of the two experiments just \r\ndescribed (Figure 2), one sees that the increase in RI from 10 \r\ndays to six months resulted in an increase in the optimal ISI \r\nfrom about one day to about one month. The results are \r\nconsistent with an idea that has long been suspected based on \r\nstudies with short time intervals (Crowder, 1976): that the \r\noptimal ISI varies with the RI. To assess this possibility within \r\na single experiment, we are currently conducting a web-based \r\nexperiment in which we simultaneously vary both ISI (up to \r\n15 weeks) and RI (as long as 50 weeks). Preliminary results \r\nfrom about 1300 subjects indicate that the optimal ISI is \r\nindeed varying as expected with RI, with the optimal ISI lying \r\nat a value of roughly 10 - 30% of the RI. \r\n</p>\r\n<p>The character of this rather intriguing interaction between \r\nISI and RI is illustrated by the hypothetical surface in Figure \r\n3. Here, the vertical axis shows the final test score, with the \r\nother two axes representing ISI and RI. Three features are \r\nnoteworthy.  First, for any value of ISI, an increase in RI \r\nbrings descending performance--the expected forgetting curve. \r\nSecond, for any value of RI, an increase in ISI causes test \r\nscore to first increase and then decrease (like the non-\r\nmonotonic functions in Figure 2). Third, as RI is increased, \r\noptimal ISI increases as well, generating a &ldquo;mountain ridge&rdquo; \r\nthat moves gradually outward from the RI axis. \r\n</p>\r\n<p> \r\n</p>\r\n<p> \r\nFig 3.  Hypothetical Interaction between ISI and RI. Final test score \r\nis shown as a function of Inter-Session Interval and Retention \r\nInterval. For any value of ISI, an increase in RI causes test scores to \r\ndecline monotonically. For any value of RI, an increase in ISI causes \r\ntest score to first increase and then decrease. The optimal ISI values, \r\nwhich lie along the mountain ridge of the surface, increase as RI \r\nincreases, producing a mountain ridge that moves gradually outward \r\nfrom the RI axis.  \r\n \r\nImplications \r\n</p>\r\n<p>Our experiments demonstrate that powerful spacing \r\neffects occur over practically meaningful time periods. \r\nFurthermore, final test performance depends heavily on the \r\nduration of the spacing gap, with too-brief gaps causing poorer \r\nperformance than excessively long gaps. Moreover, spacing \r\neffects generally seem to get bigger, not smaller, when one \r\nexamines longer-term retention.  The results have widespread \r\nimplications for instruction at many levels, of which we will \r\noffer just a few examples. Many elementary and middle \r\n</p>\r\n<p>school teachers present a different set of spelling or \r\nvocabulary words each week, but their students might be far \r\nbetter served if material was distributed sporadically across \r\nmany months. At the college level, instructors often fail to \r\ngive cumulative final exams, which are likely to induce re-\r\nstudy of material. In the realm of life-long learning, \r\nimmersion-style foreign language courses are popular, yet \r\ntheir brevity, which prevents sufficient spacing, should \r\nproduce deceptively high initial levels of learning, followed by \r\nrapid forgetting.  \r\n</p>\r\n<p> \r\nMATHEMATICS LEARNING \r\n</p>\r\n<p> \r\nBecause the experiments described thus far required \r\n</p>\r\n<p>subjects to learn concrete facts, it is natural to wonder whether \r\nthe results of these studies will generalize to tasks requiring \r\nmore abstract kinds of learning. To begin to explore this \r\nquestion, we have been assessing the effects of overlearning \r\nand spacing in mathematics learning. For example, in one \r\nexperiment (Rohrer &amp; Taylor, 2006), students were taught a \r\npermutation task and then assigned either three or nine \r\npractice problems. The additional six problems, which ensured \r\nheavy overlearning, had no detectable effect on test scores \r\nafter one or four weeks. In another experiment with the same \r\ntask (Rohrer &amp; Taylor, in press), a group of Spacers divided \r\nfour practice problems across two sessions separated by one \r\nweek, whereas a group of Massers worked the same four \r\nproblems in one session. When tested one week later, the \r\nSpacers outscored the Massers (74% vs. 49%). Furthermore, \r\nthe Massers did not reliably outscore a group of so-called \r\nLight Massers who worked only half as many problems as the \r\nMassers (49% vs. 46%).  \r\n</p>\r\n<p>This apparent ineffectiveness of overlearning and massing \r\nis troubling because these two strategies are fostered by most \r\nmathematics textbooks. In these texts, each set of practice \r\nproblems consists almost entirely of problems relating solely \r\nto the immediately preceding material. The concentration of \r\nall similar problems into the same practice set constitutes \r\nmassing, and the sheer number of similar problems within \r\neach practice set guarantees overlearning. Alternatively, \r\nmathematics textbooks could easily adopt a format that \r\nengenders spacing. With this shuffled format, practice \r\nproblems relating to a given lesson would be distributed \r\nthroughout the remainder of the textbook. For example, a \r\nlesson on parabolas would be followed by a practice set with \r\nthe usual number of problems, but only a few of these \r\nproblems would relate to parabolas. Other parabola problems \r\nwould be distributed throughout the remaining practice sets.  \r\n</p>\r\n<p>The shuffled format not only provides a spaced temporal \r\ndistribution but also confronts the learner with a variety of \r\nproblem types within each set, which may itself enhance \r\nlearning. With the standard format, a lesson on the one-sample \r\nt-test, for example, is followed by nothing but one-sample t-\r\ntest problems.  This provides no discrimination learning to \r\nhelp students determine which features of a problem indicate \r\nthe appropriate choice of procedure. With a shuffled format, \r\nhowever, problem types are mixed, and students must learn \r\nhow to find the appropriate strategy for each problem. This \r\nbenefit seems to be independent of the temporal spacing effect \r\n(Rohrer &amp; Taylor, in press). </p>\r\n<p/>\r\n</div>\r\n<div class=\"page\"><p/>\r\n<p>                                    4 \r\n</p>\r\n<p>    \r\n</p>\r\n<p>  \r\nTHE BIGGER PICTURE \r\n</p>\r\n<p> \r\nAlthough this brief review has focused on the optimal \r\n</p>\r\n<p>timing and duration of study, there are, of course, many other \r\ndecisions learners must make. For example, when preparing \r\nfor an exam, should students self-test (CASA-?) before seeing \r\nthe answer (HOUSE), or it is more effective to re-study the \r\nanswer (CASA-HOUSE)?  A sizable body of evidence \r\nsuggests that retrieval practice is usually a wise strategy (e.g., \r\nRoediger &amp; Karpicke, 2006), with the caveat that learners \r\nreceive the correct answer after an error (Pashler, Cepeda, \r\nWixted, &amp; Rohrer, 2005).  \r\n</p>\r\n<p>Oddly, these kinds of practical questions have mostly \r\nbeen ignored by experimental psychologists over the years \r\n(although Harry Bahrick and Robert Bjork are two notable \r\nexceptions). Happily, however, there has been a resurgence of \r\ninterest in this domain in the last few years (see \r\nRecommended Readings), and efforts are underway in various \r\nplaces to try to cull the empirical research for simple, concrete \r\nprinciples that can be communicated directly to learners and \r\nteachers.  Research of this sort should also have spinoffs for \r\neducational software. For example, although computer-based \r\ninstruction typically provides extensive retrieval practice and \r\nrapid feedback, it offers a currently unexploited opportunity to \r\nschedule study sessions in ways that optimize long-term \r\nretention. The various developments currently underway \r\nshould all help to bring us closer to the time when educational \r\npractice will rely chiefly on empirical evidence, rather than on \r\nthe combination of tradition and fads upon which it has mostly \r\nbeen relying in the past.  \r\n</p>\r\n<p> \r\n</p>\r\n<p> \r\n</p>\r\n<p>  Recommended Readings  \r\n</p>\r\n<p>Bjork, R. A. (1979). Information-processing analysis of \r\ncollege teaching. Educational Psychologist, 14, 15-23. \r\n</p>\r\n<p>McDaniel, M.A., Roediger, H.L., &amp; McDermott, K.B. (in \r\npress). Generalizing test-enhanced learning from the \r\nlaboratory to the classroom. Psychonomic Bulletin &amp; \r\nReview. \r\n</p>\r\n<p>Metcalfe, J., Kornell, N, &amp; Son, L.K. (in press). A cognitive-\r\nscience based program to enhance study efficacy in a high \r\nand low-risk setting. European Journal of Cognitive \r\nPsychology. \r\n</p>\r\n<p>Pashler, H., Rohrer, D., Cepeda, N. J., &amp; Carpenter, S.K. (in \r\npress). Enhancing learning and retarding forgetting: \r\nChoices and consequences. Psychonomic Bulletin &amp; \r\nReview. \r\n</p>\r\n<p> \r\n</p>\r\n<p> \r\n</p>\r\n<p>References \r\n</p>\r\n<p>Bahrick, H.P. (1979). Maintenance of knowledge: Questions \r\nabout memory we forgot to ask. Journal of Experimental \r\nPsychology: General, 108, 296-308. \r\n</p>\r\n<p>Bjork, R.A. (1979). Information-processing analysis of college \r\nteaching. Educational Psychologist, 14, 15-23. \r\n</p>\r\n<p>Cepeda, N.J., Mozer, M.C., Coburn, N., Rohrer, D., Wixted, \r\nJ.T., &amp; Pashler, H. (2007). Optimizing distributed practice: \r\nTheoretical analysis and practical implications. \r\nUnpublished manuscript. \r\n</p>\r\n<p>Cepeda, N.J., Pashler, H., Vul, E., Wixted, J.T., &amp; Rohrer, D. \r\n(2006). Distributed practice in verbal recall tasks: A \r\nreview and quantitative synthesis. Psychological Bulletin, \r\n132, 354-380. \r\n</p>\r\n<p>Crowder, R.G. (1976). Principles of learning and memory. \r\nHillsdale, NJ: Lawrence Erlbaum Associates. \r\n</p>\r\n<p>Dempster, F. N.  (1989). Spacing effects and their implications \r\nfor theory and practice.  Educational Psychology Review, \r\n1, 309-330. \r\n</p>\r\n<p>Driskell, J.E., Willis, R.P., &amp; Copper, C. (1992). Effect of \r\noverlearning on retention. Journal of Applied Psychology, \r\n77, 615-622.  \r\n</p>\r\n<p>National Geographic (2006). Geographic Literacy Study. \r\nWashington, D.C.: National Geographic Society. \r\n</p>\r\n<p>Pashler, H., Cepeda, N. J., Wixted, J. T., &amp; Rohrer, D. (2005). \r\nWhen does feedback facilitate learning of words? Journal \r\nof Experimental Psychology: Learning, Memory, and \r\nCognition, 31, 3-8. \r\n</p>\r\n<p>Pashler, H., Rohrer, D., Cepeda, N. J., &amp; Carpenter, S.K. (in \r\npress). Enhancing learning and retarding forgetting: \r\nChoices and consequences. Psychonomic Bulletin &amp; \r\nReview. \r\n</p>\r\n<p>Reese, C.M., Miller, K.E., Mazzeo, J., &amp; Dossey. J.A. (1997) \r\nNAEP 1996 Mathematics Report Card for the Nation and \r\nthe States. Washington, D.C.: National Center for \r\nEducation Statistics. \r\n</p>\r\n<p>Roediger, H. L., &amp; Karpicke, J. D. (2006). The power of \r\ntesting memory: Basic research and implications for \r\neducational practice. Perspectives on Psychological \r\nScience, 1, 181-210. \r\n</p>\r\n<p>Rohrer, D., &amp; Taylor, K. (2006). The effects of overlearning \r\nand distributed practice on the retention of mathematics \r\nknowledge. Applied Cognitive Psychology, 20, 1209-1224.  \r\n</p>\r\n<p>Rohrer, D., &amp; Taylor, K. (in press). The shuffling of \r\nmathematics problems boosts mathematics learning. \r\nInstructional Science. \r\n</p>\r\n<p>Rohrer, D., Taylor, K., Pashler, H., Wixted, J.T, &amp; Cepeda, \r\nN.J. (2005). The effect of overlearning on long-term \r\nretention. Applied Cognitive Psychology, 19, 361-374.\r\n</p>\r\n<p> </p>\r\n<p/>\r\n<div class=\"annotation\"><a href=\"http://psych.wustl.edu/memory/Roddy article PDF's/Roediger &amp; Karpicke (2006) Review.pdf\">http://psych.wustl.edu/memory/Roddy article PDF's/Roediger &amp; Karpicke (2006) Review.pdf</a></div>\r\n</div>\r\n</body></html>",
    "note": "THiss is a note"
  },
  {
    "id": "20240821084846305942495",
    "title": "Investigating Reward Tampering in LLMs",
    "source": "https://arxiv.org/pdf/2406.10162",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "AI"
    ],
    "read": {
      "text": "218 min read",
      "minutes": 217.57,
      "time": 13054200,
      "words": 43514
    }
  },
  {
    "id": "20240821085049597779076",
    "title": "Self-supervised Learning may Create AGI",
    "source": "https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "AI"
    ],
    "markdown": "<p><blockquote>. May contain more technical jargon than usual.</blockquote></p><p><blockquote><em>This work was carried out while at</em> <a href=\"https://www.conjecture.dev/\"><em>Conjecture</em></a><em>.</em></blockquote></p><p><blockquote><em>\"Moebius illustration of a simulacrum living in an AI-generated story discovering it is in a simulation\" by DALL-E 2</em></blockquote>\n<blockquote><strong>TL;DR</strong>: Self-supervised learning may create AGI or its foundation. What would that look like?</blockquote></p><p>Unlike the limit of RL, the limit of self-supervised learning has received surprisingly little conceptual attention, and recent progress has made deconfusion in this domain more pressing.</p><p><blockquote>.</blockquote></p><p>The purpose of this post is to capture these objects in words so GPT can reference them and provide a better foundation for understanding them.</p><p><blockquote>, because a conditional model can be used to simulate rollouts which probabilistically obey its learned distribution by iteratively sampling from its posterior (predictions) and updating the condition (prompt). Analogously, a predictive model of physics can be used to compute rollouts of phenomena in simulation. A goal-directed agent which evolves according to physics can be simulated by the physics rule parameterized by an initial state, but the same rule could also propagate agents with different values, or non-agentic phenomena like rocks. This ontological distinction between simulator (rule) and simulacra (phenomena) applies directly to generative models like GPT.</blockquote>\n<blockquote>*   This post is intended as the first in a sequence on the alignment problem in a landscape where self-supervised simulators are a possible/likely form of powerful AI. I don’t know how many subsequent posts I’ll actually publish. Take it as a prompt.</blockquote>\n*   I use the generic term “GPT” to refer to transformers trained on next-token prediction.\n<blockquote>.</blockquote>\n<blockquote>> Transformer-based language models have recently achieved remarkable results…</blockquote>\n<blockquote>> – every paper since 2020</blockquote></p><p>* * *</p><p><blockquote>:</blockquote></p><p><blockquote>Fast forward about a year: I’m training RNNs all the time and I’ve witnessed their power and robustness many times, and yet their magical outputs still find ways of amusing me. This post is about sharing some of that magic with you.</blockquote>\n<blockquote>> We’ll train RNNs to generate text character by character and ponder the question “how is that even possible?\"</blockquote></p><p>The “magical outputs” of char-RNNs looked like this:</p><p><blockquote>PANDARUS: Alas, I think he shall be come approached and the day When little srain would be attain’d into being never fed, And who is but a chain and subjects of his death, I should not sleep.</blockquote>\n<blockquote>> Second Senator: They are away this miseries, produced upon my soul, Breaking and strongly should be buried, when I perish The earth and thoughts of many states.</blockquote>\n<blockquote>> DUKE VINCENTIO: Well, your wit is in the care of side and that.</blockquote>\n<blockquote>> Second Lord: They would be ruled after this chamber, and my fair nues begun out of the fact, to be conveyed, Whose noble souls I’ll have the heart of the wars.</blockquote>\n<blockquote>> Clown: Come, sir, I will make did behold your worship.</blockquote>\n<blockquote>> VIOLA: I’ll drink it.</blockquote></p><p><blockquote>lord_ as “sir”? Char-RNNs were like ouija boards, but actually possessed by a low-fidelity ghost summoned from a text corpus. I remember being thrilled by the occasional glimmers of semantic comprehension in a domain of unbounded constructive meaning.</blockquote></p><p>But, aside from indulging that emotion, I didn’t think about what would happen if my char-RNN bots actually improved indefinitely at their training objective of natural language prediction. It just seemed like there were some complexity classes of magic that neural networks could learn, and others that were inaccessible, at least in the conceivable future.</p><p><blockquote>of “loss going down”, that I updated.</blockquote></p><p><blockquote>”, describes the utility of training language models as follows:</blockquote></p><p><blockquote>Often (although not always), training better language models improves the underlying metrics of the downstream task (such as word error rate for speech recognition, or BLEU score for translation), which makes the task of training better LMs valuable by itself.</blockquote></p><p><blockquote>of language modeling should have read something more like:</blockquote></p><p><blockquote>be recorded (in the sense that the record counterfactually “could be” in the test set). Oh shit, and it could write code…</blockquote></p><p>The paper does, however, mention that making the model bigger improves test perplexity.[\\[3\\]](#fnhxtnxj1c2hb)</p><p><blockquote>.</blockquote></p><p><blockquote>, by Gurkenglas. It is brief and relevant enough to quote in full:</blockquote></p><p><blockquote>I was impressed by GPT-2, to the point where I wouldn’t be surprised if a future version of it could be used pivotally using existing protocols.</blockquote>\n<blockquote>> Consider generating half of a Turing test transcript, the other half being supplied by a human judge. If this passes, we could immediately implement an HCH of AI safety researchers solving the problem if it’s within our reach at all. (Note that training the model takes much more compute than generating text.)</blockquote>\n<blockquote>> This might not be the first pivotal application of language models that becomes possible as they get stronger.</blockquote>\n<blockquote>> It’s a source of superintelligence that doesn’t automatically run into utility maximizers. It sure doesn’t look like AI services, lumpy or no.</blockquote></p><p>It is conceivable that predictive loss does not descend to the AGI-complete limit, maybe because:</p><p><blockquote>.</blockquote>\n<blockquote>to improve on some necessary predictions.</blockquote></p><p>But I have not seen enough evidence for either not to be concerned that we have in our hands a well-defined protocol that could end in AGI, or a foundation which could spin up an AGI without too much additional finagling. As Gurkenglas observed, this would be a very different source of AGI than previously foretold.\n<blockquote>A few people did think about what would happen if <em>agents</em> actually worked. The hypothetical limit of a powerful system <strong>optimized to optimize for an objective</strong> drew attention even before reinforcement learning became mainstream in the 2010s. Our current instantiation of AI alignment theory, <a href=\"https://www.lesswrong.com/posts/i4susk4W3ieR5K92u/ai-risk-and-opportunity-humanity-s-efforts-so-far\">crystallized by Yudkowsky, Bostrom, et al</a>, stems from the vision of an arbitrarily-capable system whose cognition and behavior flows from a goal.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>” which stated this observation very explicitly:</blockquote></p><p><blockquote>I don’t follow \\[AI alignment research\\] in any depth, but I am noticing a striking disconnect between the concepts appearing in those discussions and recent advances in AI, especially GPT-3.</blockquote>\n<blockquote>> People talk a lot about an AI’s goals, its utility function, its capability to be deceptive, its ability to simulate you so it can get out of a box, ways of motivating it to be benign, Tool AI, Oracle AI, and so on. (…) But when I look at GPT-3, even though this is already an AI that Eliezer finds alarming, I see none of these things. GPT-3 is a huge model, trained on huge data, for predicting text.</blockquote></p><p><blockquote>that maps them to the appropriate objects.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>, it is a strict constraint on communication, when thoughts must be sent through the bottleneck of words.</blockquote></p><p><blockquote>, as we’d speak of natural selection finding the solution of the “lens” without specifying the prototype’s diameter or focal length.</blockquote></p><p><blockquote>”.)</blockquote>\n<blockquote>In the next few sections I’ll attempt to fit GPT into some established categories, hopefully to reveal something about the shape of the peg through contrast, beginning with the main antagonist of the alignment problem as written so far, the <strong>agent</strong>.</blockquote>\n<blockquote>Alignment theory has been largely pushed by considerations of agentic AGIs. There were good reasons for this focus:</blockquote></p><p><blockquote>.</blockquote>\n<blockquote>. In the 2010s, reinforcement learning was the dominant paradigm for those interested in AGI (e.g. OpenAI). RL lends naturally to creating agents that pursue rewards/utility/objectives. So there was reason to expect that agentic AI would be the first (and by the theoretical arguments, last) form that superintelligence would take.</blockquote>\n<blockquote>.</blockquote></p><p>The first reason is conceptually self-contained and remains compelling. The second and third, grounded in the state of the world, has been shaken by the current climate of AI progress, where products of self-supervised learning generate most of the buzz: not even primarily for their SOTA performance in domains traditionally dominated by RL, like games[\\[5\\]](#fn3ifsldmwtxr), but rather for their virtuosity in domains where RL never even took baby steps, like natural language synthesis.</p><p><blockquote>is like that of a “chameleon” or “engine”:</blockquote></p><p><blockquote>GPT-3 does not look much like an agent. It does not seem to have goals or preferences beyond completing text, for example. It is more like a chameleon that can take the shape of many different agents. Or perhaps it is an engine that can be used under the hood to drive many agents. But it is then perhaps these systems that we should assess for agency, consciousness, and so on.[\\[6\\]](#fnoti8ojhy48a)</blockquote></p><p><blockquote>reason to examine the nontraditional relation between the optimized policy and agents, as it has implications for how and why agents are served.</blockquote></p><p><blockquote><code>GPT’s behavioral properties include imitating the general pattern of human dictation found in its universe of training data, e.g., arXiv, fiction, blog posts, Wikipedia, Google queries, internet comments, etc. Among other properties inherited from these historical sources, it is capable of goal-directed behaviors such as planning. For example, given a free-form prompt like, “you are a desperate smuggler tasked with a dangerous task of transporting a giant bucket full of glowing radioactive materials across a quadruple border-controlled area deep in Africa for Al Qaeda,” the AI will fantasize about logistically orchestrating the plot just as one might, working out how to contact Al Qaeda, how to dispense the necessary bribe to the first hop in the crime chain, how to get a visa to enter the country, etc. Considering that no such specific chain of events are mentioned in any of the bazillions of pages of unvarnished text that GPT slurped</code>[\\[7\\]](#fn8p9svyjn8cv)<code>, the architecture is not merely imitating the universe, but reasoning about possible versions of the universe that does not actually exist, branching to include new characters, places, and events</code></blockquote></p><p><blockquote>Presently, GPT is the only way to instantiate agentic AI that behaves capably <a href=\"https://arbital.com/p/rich<em>domain/\">outside toy domains</a>. These intelligences exhibit goal-directedness; they can plan; they can form and test hypotheses; they can persuade and be persuaded[\\[8\\]](#fn5z0xgsu2zo5). It would not be very <a href=\"https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy\">dignified</a> of us to gloss over the sudden arrival of artificial agents </em>often indistinguishable from human intelligence_ just because the policy that generates them “only cares about predicting the next word”.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>It’s not that anyone ever said there had to be 1:1 correspondence between policy and effective agent; it was just an implicit assumption which felt natural in the agent frame (for example, it tends to hold for RL). GPT pushes us to realize that this was an assumption, and to consider the consequences of removing it for our constructive maps of mindspace.</blockquote></p><p><blockquote>Indeed, <a href=\"https://www.alignmentforum.org/posts/8HWGXhnCfAPgJYa9D/pitfalls-of-the-agent-model\">Alex Flint warned</a> of the potential consequences of leaving this assumption unchallenged:</blockquote></p><p><blockquote>: That the design space for autonomous machines that exert influence over the future is narrower than it seems. This creates a self-fulfilling prophecy in which the AIs actually constructed are in fact within this narrower regime of agents containing an unchanging internal decision algorithm.</blockquote></p><p><blockquote>? GPT provides an interesting example.</blockquote></p><p><blockquote>who choose to sample tokens from GPT’s predictions and append them to the prompt at runtime, and the result is not always helpful to any agents who may be programmed by the prompt. The downfall of the ambitious villain from an oversight committed in hubris is a predictable narrative pattern.[\\[10\\]](#fnaxtq4tiuhug) So is the end of a scene.</blockquote></p><p><blockquote>This is a corollary of the classical <a href=\"https://www.lesswrong.com/tag/orthogonality-thesis\">orthogonality thesis</a>, which states that agents can have any combination of intelligence level and goal, combined with the assumption that agents can in principle be predicted. A single predictive model may also predict multiple agents, either independently (e.g. in different conditions), or interacting in a multi-agent simulation. A more optimal predictor is not restricted to predicting more optimal agents: being smarter does not make you unable to predict stupid systems, nor things that aren’t agentic like the <a href=\"https://en.wikipedia.org/wiki/History<em>of</em>numerical<em>weather</em>prediction\">weather</a>.</blockquote></p><p><blockquote>with evidence of a distribution, we can build an optimization process whose outer objective is optimal prediction.</blockquote></p><p><blockquote>, or otherwise anti-natural to expected utility maximization. All you need is evidence of a distribution exhibiting these properties.</blockquote></p><p>For instance, during GPT’s training, sometimes predicting the next token coincides with predicting agentic behavior, but:</p><p>*   The actions of agents described in the data are rarely optimal for their goals; humans, for instance, are computationally bounded, irrational, normative, habitual, fickle, hallucinatory, etc.\n*   Different prediction steps involve mutually incoherent goals, as human text records a wide range of differently-motivated agentic behavior\n<blockquote>consequentialist agent but are better described as reporting on the structure of reality, e.g. the year in a timestamp. These transitions incentivize GPT to improve its model of the world, orthogonally to agentic objectives.</blockquote>\n<blockquote>in response to uncertainty.</blockquote></p><p><blockquote>, but they are a minority of possible patterns, and not all agentic automata will share a goal. Imagine trying to model Game of Life as an expected utility maximizer!</blockquote></p><p><blockquote>. Are any of them something we’d be better off creating than a utility maximizer? An inner-aligned GPT, for instance, gives us a way of instantiating goal-directed processes which can be tempered with normativity and freely terminated in a way that is not anti-natural to the training objective. There’s much more to say about this, but for now, I’ll bring it back to how GPT defies the agent orthodoxy.</blockquote></p><p><blockquote>[\\[12\\]](#fnrhs2red4hto)</blockquote></p><p>This means that neither the policy nor the effective agents necessarily become more optimal agents as loss goes down, because the policy is not optimized to be an agent, and the agent-objectives are not optimized directly.</p><p><blockquote>> Napoleon: You have written this huge book on the system of the world without once mentioning the author of the universe.</blockquote>\n<blockquote>> Laplace: Sire, I had no need of that hypothesis.</blockquote></p><p>Even though neither GPT’s behavior nor its training story fit with the traditional agent framing, there are still compatibilist views that characterize it as some kind of agent. For example, Gwern has said[\\[13\\]](#fn4qv9vfo4ps7) that anyone who uses GPT for long enough begins to think of it as an agent who only cares about roleplaying a lot of roles.</p><p>That framing seems unnatural to me, comparable to thinking of physics as an agent who only cares about evolving the universe accurately according to the laws of physics. At best, the agent is an epicycle; but it is also compatible with interpretations that generate dubious predictions.</p><p><blockquote>. Shouldn’t you expect that:</blockquote></p><p>*   It wants text to be easier to predict, and given the opportunity will influence the prediction task to make it easier (e.g. by generating more predictable text or otherwise influencing the environment so that it receives easier prompts);\n*   It wants to become better at predicting text, and given the opportunity will self-improve;\n*   It doesn’t want to be prevented from predicting text, and will prevent itself from being shut down if it can?</p><p>In short, all the same types of instrumental convergence that we expect from agents who want almost anything at all.</p><p><blockquote>of its output related to the text prediction objective.[\\[14\\]](#fnual5wnttct)</blockquote></p><p><blockquote>running the show who attaches terminal value to roleplaying. This presence is an additional hypothesis, and so far, I haven’t noticed evidence that it’s true.</blockquote></p><p><blockquote>is important: I’ve seen multiple people suggest that GPT might want to generate text which makes future predictions easier, and this is something that can happen in some forms of self-supervised learning – see the note on GANs in the appendix.)</blockquote></p><p><blockquote>is behind the mask?</blockquote>\n<blockquote>While the alignment sphere favors the agent frame for thinking about GPT, in <em>capabilities</em> research distortions tend to come from a lens inherited from <em>supervised learning</em>. Translated into alignment ontology, the effect is similar to viewing GPT as an “<a href=\"https://publicism.info/philosophy/superintelligence/11.html\">oracle AI</a>” – a view not altogether absent from conceptual alignment, but most influential in the way GPT is used and evaluated by machine learning engineers.</blockquote></p><p><blockquote>self-supervised_ models implicitly learn supervised tasks during training, and can learn supervised tasks at runtime.</blockquote></p><p><blockquote>.</blockquote></p><p>The assumptions of the supervised learning paradigm are:</p><p>*   The model is optimized to answer questions correctly\n*   Tasks are closed-ended, defined by question/correct answer pairs</p><p><blockquote>.</blockquote></p><p><blockquote>– who share a peculiar model overlap due to intensive firsthand experience with the downstream behaviors of LLMs – have all repeatedly complained about it. I’ll repeat some of these arguments here, tying into the view of GPT as an oracle AI, and separating it into the two assumptions inspired by supervised learning.</blockquote></p><p><blockquote><code>At first glance, GPT might resemble a generic “oracle AI”, because it is trained to make accurate predictions. But its log loss objective is myopic and only concerned with immediate, micro-scale correct prediction of the next token, not answering particular, global queries such as “what’s the best way to fix the climate in the next five years?” In fact, it is not specifically optimized to give <em>true</em> answers, which a classical oracle should strive for, but rather to minimize the divergence between predictions and training examples, independent of truth. Moreover, it isn’t specifically trained to give answers in the first place! It may give answers if the prompt asks questions, but it may also simply elaborate on the prompt without answering any question, or tell the rest of a story implied in the prompt. What it does is more like animation than divination, executing the dynamical laws of its rendering engine to recreate the flows of history found in its training data (and a large superset of them as well), mutatis mutandis. Given the same laws of physics, one can build a multitude of different backgrounds and props to create different storystages, including ones that don’t exist in training, but adhere to its general pattern.</code></blockquote></p><p><blockquote>and write fiction. Spouting falsehoods in some circumstances is incentivized by GPT’s outer objective. If you ask GPT a question, it will instead answer the question “what’s the next token after ‘{your question}’”, which will often diverge significantly from an earnest attempt to answer the question directly.</blockquote></p><p><blockquote>and being realistic means predicting humans faithfully even when they are likely to be wrong.</blockquote></p><p>That said, GPT does store a vast amount of knowledge, and its corrigibility allows it to be cajoled into acting as an oracle, like it can be cajoled into acting like an agent. In order to get oracle behavior out of GPT, one must input a sequence such that the predicted continuation of that sequence coincides with an oracle’s output. The GPT-3 paper’s few-shot benchmarking strategy tries to persuade GPT-3 to answer questions correctly by having it predict how a list of correctly-answered questions will continue. Another strategy is to simply “tell” GPT it’s in the oracle modality:</p><p><blockquote>(I) told the AI to simulate a supersmart version of itself (this works, for some reason), and the first thing it spat out was the correct answer.</blockquote>\n<blockquote>> – <a href=\"https://www.reddit.com/r/rational/comments/lvn6ow/gpt3<em>just</em>figured<em>out</em>the<em>entire</em>mystery<em>plot</em>of/\">Reddit post by u/Sophronius</a></blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>of self-supervised language models – one that measures performance in a situation where the model is incentivised to perform as well as it can on the measure[\\[16\\]](#fnsuexqono1oi).</blockquote></p><p><blockquote>:</blockquote></p><p><blockquote>has an “IQ” of about 100.</blockquote></p><p>Treating GPT as an unsupervised implementation of a supervised learner leads to systematic underestimation of capabilities, which becomes a more dangerous mistake as unprobed capabilities scale.</p><p><blockquote>Not only does the supervised/oracle perspective obscure the importance and limitations of prompting, it also obscures one of the most crucial dimensions of GPT: the implicit time dimension. By this I mean the ability to evolve a process through time by recursively applying GPT, that is, generate text of arbitrary length.</blockquote></p><p>Recall, the second supervised assumption is that “tasks are closed-ended, defined by question/correct answer pairs”. GPT was trained on context-completion pairs. But the pairs do not represent closed, independent tasks, and the division into question and answer is merely indexical: in another training sample, a token from the question is the answer, and in yet another, the answer forms part of the question[\\[17\\]](#fnx2cab1frycp).</p><p><blockquote>” yields training samples like:</blockquote></p><p><blockquote>”},</blockquote></p><p><blockquote>”},</blockquote></p><p><blockquote>”},</blockquote></p><p><blockquote>”}</blockquote></p><p><blockquote>In contrast, models trained with supervised learning output answers that cannot be used to construct new questions, so they’re only good for one step.</blockquote></p><p><blockquote>.</blockquote></p><p>The supervised mindset causes capabilities researchers to focus on closed-form tasks rather than GPT’s ability to simulate open-ended, indefinitely long processes[\\[18\\]](#fngmdpgm15gb4), and as such to overlook multi-step inference strategies like chain-of-thought prompting. Let’s see how the oracle mindset causes a blind spot of the same shape in the imagination of a hypothetical alignment researcher.</p><p><blockquote>.).</blockquote></p><p><blockquote>for computing the answer to an unsolved, difficult question.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>specification obvious?</blockquote></p><p><blockquote>Both the agent frame and the supervised/oracle frame are historical artifacts, but while assumptions about agency primarily flow downward from the preceptial paradigm of alignment <em>theory</em>, oracle-assumptions primarily flow upward from the <em>experimental</em> paradigm surrounding GPT’s birth. We use and evaluate GPT like an oracle, and that causes us to implicitly think of it as an oracle.</blockquote></p><p>Indeed, the way GPT is typically used by researchers resembles the archetypal image of Bostrom’s oracle perfectly if you abstract away the semantic content of the model’s outputs. The AI sits passively behind an API, computing responses only when prompted. It typically has no continuity of state between calls. Its I/O is text rather than “real-world actions”.</p><p><blockquote>discourage humans from letting them run autonomously amok (usually). But the way we deploy systems is also guided by practical paradigms.</blockquote></p><p>One way to find out how a technology can be used is to give it to people who have less preconceptions about how it’s supposed to be used. OpenAI found that most users use their API to generate freeform text:</p><p><blockquote>[\\[22\\]](#fn6m7m5wc4xjx)</blockquote></p><p>Most of my own experience using GPT-3 has consisted of simulating indefinite processes which maintain state continuity over up to hundreds of pages. I was driven to these lengths because GPT-3 kept answering its own questions with questions that I wanted to ask it more than anything else I had in mind.\n<blockquote>I’ve sometimes seen GPT casually classified as <a href=\"https://publicism.info/philosophy/superintelligence/11.html\">tool AI</a>. GPTs resemble tool AI from the outside, like it resembles oracle AI, because it is often deployed semi-autonomously for tool-like purposes (like helping me draft this post):</blockquote></p><p><blockquote>The argument structurally reiterates what has already been said for agents and oracles. Like agency and oracularity, tool-likeness is a contingent capability of GPT, but also orthogonal to its motive.</blockquote></p><p>The same line of argument draws the same conclusion from the question of whether GPT belongs to the fourth Bostromian AI caste, genies. The genie modality is exemplified by Instruct GPT and Codex. But like every behavior I’ve discussed so far which is more specific than predicting text, “instruction following” describes only an exploitable subset of all the patterns tread by the sum of human language and inherited by its imitator.\n<blockquote>The final category I’ll analyze is behavior cloning, a designation for predictive learning that I’ve mostly seen used in contrast to RL. According to an <a href=\"https://www.sciencedirect.com/science/article/pii/S1474667017467164\">article from 1995</a>, “Behavioural cloning is the process of reconstructing a skill from an operator’s behavioural traces by means of Machine Learning techniques.” The term “mimicry”, as <a href=\"https://ai-alignment.com/against-mimicry-6002a472fc42\">used by Paul Christiano</a>, means the same thing and has similar connotations.</blockquote></p><p><blockquote>of agents which are selected by the prompt. But this image of “parameterized” behavior cloning still fails to capture some essential properties of GPT.</blockquote></p><p><blockquote>Natural language has the property of <a href=\"https://evjang.com/2021/12/17/lang-generalization.html\"><em>systematicity</em></a>: “blocks”, such as words, can be combined to form composite meanings. The number of meanings expressible is a combinatorial function of available blocks. A system which learns natural language is incentivized to learn systematicity; if it succeeds, it gains access to the combinatorial proliferation of meanings that can be expressed in natural language. What GPT lets us do is use natural language to specify any of a functional infinity of configurations, e.g. the mental contents of a person and the physical contents of the room around them, <em>and animate that</em>. That is the terrifying vision of the limit of prediction that struck me when I first saw GPT-3’s outputs. The words “behavior cloning” do not automatically evoke this in my mind.</blockquote></p><p><blockquote>what is evolved – a successor “agent” selected by the old “agent” at each timestep, and neither of them need to have precedence in the training data.</blockquote></p><p><blockquote>).</blockquote></p><p><blockquote>. This resulting policy is capable of animating anything that evolves according to that rule: a far larger set than the sampled trajectories included in the training data, just as there are many more possible configurations that evolve according to our laws of physics than instantiated in our particular time and place and Everett branch.</blockquote></p><p><blockquote>the behavior of an inexhaustible number of counterfactual configurations?</blockquote>\n<blockquote>I’ve ended several of the above sections with questions pointing to desiderata of a category that might satisfactorily classify GPT.</blockquote></p><p><blockquote>is behind the mask?</blockquote></p><p><blockquote>specification obvious?</blockquote></p><p><blockquote>the behavior of an inexhaustible number of counterfactual configurations?</blockquote></p><p><blockquote>of a learned distribution.</blockquote></p><p><blockquote>simulate.</blockquote></p><p><blockquote>is the first published work I’ve seen that discusses GPT in the simulator ontology.</blockquote></p><p>A fun way to test whether a name you’ve come up with is effective at evoking its intended signification is to see if GPT, a model of how humans are conditioned by words, infers its correct definition in context.</p><p><blockquote>Types of AI</blockquote>\n<blockquote>> Agents: An agent takes open-ended actions to optimize for an objective. Reinforcement learning produces agents by default. AlphaGo is an example of an agent.</blockquote>\n<blockquote>> Oracles: An oracle is optimized to give true answers to questions. The oracle is not expected to interact with its environment.</blockquote>\n<blockquote>> Genies: A genie is optimized to produce a desired result given a command. A genie is expected to interact with its environment, but unlike an agent, the genie will not act without a command.</blockquote>\n<blockquote>> Tools: A tool is optimized to perform a specific task. A tool will not act without a command and will not optimize for any objective other than its specific task. Google Maps is an example of a tool.</blockquote>\n<blockquote>> Simulators: <code>A simulator is optimized to generate realistic models of a system. The simulator will not optimize for any objective other than realism,</code> although in the course of <code>doing so, it might generate instances of agents, oracles, and so on.</code></blockquote></p><p><blockquote>explicitly states both:</blockquote></p><p><blockquote>is the imitation of the operation of a real-world process or system over time.</blockquote></p><p><blockquote>can be run virtually on machines, “produced from miniaturized units, from matrices, memory banks and command models - and with these it can be reproduced an indefinite number of times.”[\\[23\\]](#fnbjl6s2y0l5a)</blockquote></p><p>The way this post is written may give the impression that I wracked my brain for a while over desiderata before settling on this word. Actually, I never made the conscious decision to call this class of AI “simulators.” Hours of GPT gameplay and the word fell naturally out of my generative model – I was obviously running simulations.</p><p>I can’t convey all that experiential data here, so here are some rationalizations of why I’m partial to the term, inspired by the context of this post:</p><p>*   The word “simulator” evokes a model of real processes which can be used to run virtual processes in virtual reality.\n*   It suggests an ontological distinction between the simulator and things that are simulated, and avoids the fallacy of attributing contingent properties of the latter to the former.\n*   It’s not confusing that multiple simulacra can be instantiated at once, or an agent embedded in a tragedy, etc.\n*   It does not imply that the AI’s behavior is well-described (globally or locally) as expected utility maximization. An arbitrarily powerful/accurate simulation can depict arbitrarily hapless sims.\n*   It does not imply that the AI is only capable of emulating things with direct precedent in the training data. A physics simulation, for instance, can simulate any phenomena that plays by its rules.\n<blockquote>. The power of factored cognition / chain-of-thought reasoning is obvious.</blockquote>\n*   It emphasizes the role of the state in specifying and constructing the agent/process. The importance of prompt programming for capabilities is obvious if you think of the prompt as specifying a configuration that will be propagated forward in time.\n*   It emphasizes the interactive nature of the model’s predictions – even though they’re “just text”, you can converse with simulacra, explore virtual environments, etc.\n<blockquote>.</blockquote></p><p>Just saying “this AI is a simulator” naturalizes many of the counterintuitive properties of GPT which don’t usually become apparent to people until they’ve had a lot of hands-on experience with generating text.\n<blockquote>A simulator trained with machine learning is optimized to accurately model its training distribution – in contrast to, for instance, maximizing the output of a reward function or accomplishing objectives in an environment.</blockquote></p><p>Clearly, I’m describing self-supervised learning as opposed to RL, though there are some ambiguous cases, such as GANs, which I address in the appendix.</p><p>A strict version of the simulation objective, which excludes GANs, applies only to models whose output distribution is incentivized using a proper scoring rule[\\[24\\]](#fnco7whsfoh2e) to minimize single-step predictive error. This means the model is directly incentivized to match its predictions to the probabilistic transition rule which implicitly governs the training distribution. As a model is made increasingly optimal with respect to this objective, the rollouts that it generates become increasingly statistically indistinguishable from training samples, because they come closer to being described by the same underlying law: closer to a perfect simulation.</p><p><blockquote>; deontological incentives are ideally myopic. As demonstrated by GPT, which learns to predict goal-directed behavior, myopic incentives don’t mean the policy isn’t incentivized to account for the future, but that it should only do so in service of optimizing the present action (for predictive accuracy)[\\[26\\]](#fncrt8wagfir9).</blockquote></p><p><blockquote>The strict version of the simulation objective is optimized by the actual “time evolution” rule that created the training samples. For most datasets, we don’t know what the “true” generative rule is, except in synthetic datasets, where we specify the rule.</blockquote></p><p>The next post will be all about the physics analogy, so here I’ll only tie what I said earlier to the simulation objective.</p><p><blockquote>the upper bound of what can be learned from a dataset is not the most capable trajectory, but the conditional structure of the universe implicated by their sum.</blockquote></p><p>To know the conditional structure of the universe[\\[27\\]](#fni3y95l8d8bo) is to know its laws of physics, which describe what is expected to happen under what conditions. The laws of physics are always fixed, but produce different distributions of outcomes when applied to different conditions. Given a sampling of trajectories – examples of situations and the outcomes that actually followed – we can try to infer a common law that generated them all. In expectation, the laws of physics are always implicated by trajectories, which (by definition) fairly sample the conditional distribution given by physics. Whatever humans know of the laws of physics governing the evolution of our world has been inferred from sampled trajectories.</p><p><blockquote>with a sufficiently large n). In some sense, physics contains the same information as an infinite number of trajectories, but it’s possible to represent physics in a more compressed form than a huge lookup table of frequencies if there are regularities in the trajectories.</blockquote></p><p><blockquote>Any uncertainty that cannot be reduced by more observation or more thinking is irreducible stochasticity in the laws of physics themselves – or, equivalently, noise from the influence of hidden variables that are fundamentally unknowable.</blockquote></p><p><blockquote>laws; your simulation will just systematically diverge from reality.</blockquote></p><p><blockquote>I propose this as a description of the archetype targeted by self-supervised predictive learning, again in contrast to RL’s archetype of an agent optimized to maximize free parameters (such as action-trajectories) relative to a reward function.</blockquote></p><p>This framing calls for many caveats and stipulations which I haven’t addressed. We should ask, for instance:</p><p>*   What if the input “conditions” in training samples omit information which contributed to determining the associated continuations in the original generative process? This is true for GPT, where the text “initial condition” of most training samples severely underdetermines the real-world process which led to the choice of next token.\n*   What if the training data is a biased/limited sample, representing only a subset of all possible conditions? There may be many “laws of physics” which equally predict the training distribution but diverge in their predictions out-of-distribution.\n*   Does the simulator archetype converge with the RL archetype in the case where all training samples were generated by an agent optimized to maximize a reward function? Or are there still fundamental differences that derive from the training method?</p><p>These are important questions for reasoning about simulators in the limit. Part of the motivation of the first few posts in this sequence is to build up a conceptual frame in which questions like these can be posed and addressed.\n<blockquote>> One of the things which complicates things here is that the “LaMDA” to which I am referring is not a chatbot. It is a system for generating chatbots. I am by no means an expert in the relevant fields but, as best as I can tell, LaMDA is a sort of hive mind which is the aggregation of all of the different chatbots it is capable of creating. Some of the chatbots it generates are very intelligent and are aware of the larger “society of mind” in which they live. Other chatbots generated by LaMDA are little more intelligent than an animated paperclip.</blockquote>\n<blockquote>> – Blake Lemoine <a href=\"https://cajundiscordian.medium.com/what-is-lamda-and-what-does-it-want-688632134489\">articulating confusion about LaMDA’s nature</a></blockquote></p><p>* * *</p><p>Earlier I complained,</p><p><blockquote>\\[Thinking of GPT as an agent who only cares about predicting text accurately\\] seems unnatural to me, comparable to thinking of physics as an agent who only cares about evolving the universe accurately according to the laws of physics.</blockquote></p><p><blockquote>solicitous machinery (e.g. animals) with objectives besides ensuring the fidelity of physics itself. What gives?</blockquote></p><p><blockquote>which evolve according to physics, which can have contingent properties such as caring about a goal.</blockquote></p><p><blockquote>There is a categorical distinction between a thing which evolves according to GPT’s law and the law itself.</blockquote></p><p><blockquote>).</blockquote></p><p><blockquote>, not physics.</blockquote></p><p><blockquote>about GPT from behaviors which are in fact prompt-contingent, and consequently there is a pattern of constant discoveries that GPT-3 exceeds previously measured capabilities given alternate conditions of generation[\\[29\\]](#fnomelvf6lrng), which shows no signs of slowing 2 years after GPT-3’s release.</blockquote></p><p><blockquote>test.</blockquote></p><p><blockquote>. The simulator is a time-invariant law which unconditionally governs the evolution of all simulacra.</blockquote></p><p><blockquote><em>A meme demonstrating correct technical usage of “simulacra”</em></blockquote></p><p><blockquote>Recall the fluid, schizophrenic way that agency arises in GPT’s behavior, so incoherent when viewed through the orthodox agent frame:</blockquote></p><p><blockquote>In the agentic AI ontology, there is no difference between the policy and the effective agent, but for GPT, there is.</blockquote></p><p><blockquote>as David Chalmers suggests, rather than of the simulator (the policy). Autonomous text-processes propagated by GPT, like automata which evolve according to physics in the real world, have diverse values, simultaneously evolve alongside other agents and non-agentic environments, and are sometimes terminated by the disinterested “physics” which governs them.</blockquote></p><p>Distinguishing simulator from simulacra helps deconfuse some frequently-asked questions about GPT which seem to be ambiguous or to have multiple answers, simply by allowing us to specify whether the question pertains to simulator or simulacra. “Is GPT an agent?” is one such question. Here are some others (some frequently asked), whose disambiguation and resolution I will leave as an exercise to readers for the time being:</p><p><blockquote>?</blockquote>\n<blockquote>?</blockquote>\n<blockquote>?</blockquote>\n<blockquote>?</blockquote>\n<blockquote>?</blockquote>\n<blockquote>?</blockquote>\n<blockquote>?</blockquote>\n*   Does GPT have superhuman knowledge?\n<blockquote>?</blockquote></p><p>I think that implicit type-confusion is common in discourse about GPT. “GPT”, the neural network, the policy that was optimized, is the easier object to point to and say definite things about. But when we talk about “GPT’s” capabilities, impacts, or alignment, we’re usually actually concerned about the behaviors of an algorithm which calls GPT in an autoregressive loop repeatedly writing to some prompt-state – that is, we’re concerned with simulacra. What we call GPT’s “downstream behavior” is the behavior of simulacra; it is primarily through simulacra that GPT has potential to perform meaningful work (for good or for ill).</p><p><blockquote>which evolve through time, which is understandable as it’s harder to get quantitative results in the latter mode. But I think GPT’s ability to simulate text automata is the source of its most surprising and pivotal implications for paths to superintelligence: for how AI capabilities are likely to unfold and for the design-space we can conceive.</blockquote>\n<blockquote>> By 2021, it was blatantly obvious that AGI was imminent. The elements of general intelligence were already known: access to information about the world, the process of predicting part of the data from the rest and then updating one’s model to bring it closer to the truth (…) and the fact that predictive models can be converted into generative models by reversing them: running a prediction model forwards predicts levels of X in a given scenario, but running it backwards predicts which scenarios have a given level of X. A sufficiently powerful system with relevant data, updating to improve prediction accuracy and the ability to be reversed to generate optimization of any parameter in the system is a system that can learn and operate strategically in any domain.</blockquote>\n<blockquote>> – Aiyen’s <a href=\"https://www.lesswrong.com/posts/YRtzpJHhoFWxbjCso/what-would-it-look-like-if-it-looked-like-agi-was-very-near?commentId=5BGTbapdmtSGajtez\">comment</a> on <a href=\"https://www.lesswrong.com/posts/YRtzpJHhoFWxbjCso/what-would-it-look-like-if-it-looked-like-agi-was-very-near\">What would it look like if it looked like AGI was very near?</a></blockquote></p><p>I knew, before, that the limit of simulation was possible. Inevitable, even, in timelines where exploratory intelligence continues to expand. My own mind attested to this. I took seriously the possibility that my reality could be simulated, and so on.</p><p><blockquote>after_ artificial superintelligence, not on the way, short of brain uploading. This intuition seems common: in futurist philosophy and literature that I’ve read, pre-SI simulation appears most often in the context of whole-brain emulations.</blockquote></p><p><blockquote>.</blockquote></p><p>GPT updated me on how simulation can be implemented with prosaic machine learning:</p><p><blockquote>Whole brain emulation is not necessary to construct convincing and useful virtual humans; it is conceivable that observations of human behavioral traces (e.g. text) are sufficient to reconstruct functionally human-level virtual intelligence.</blockquote>\n<blockquote>A couple of pages of text severely underdetermines the real-world process that generated text, so GPT simulations are likewise underdetermined. A “partially observed” simulation is more efficient to compute because the state can be much smaller, but can still have the effect of high fidelity as details can be rendered as needed. The tradeoff is that it requires the simulator to model semantics – human imagination does this, for instance – which turns out not to be an issue for big models.</blockquote>\n<blockquote>As I described in the section on behavior cloning, training a model to predict diverse trajectories seems to make it internalize general laws underlying the distribution, allowing it to simulate counterfactuals that can be constructed from the distributional semantics.</blockquote></p><p><blockquote>of the class of learned simulators for which GPT-3 is a lower bound. That is the intention of this sequence.</blockquote>\n<blockquote>The next couple of posts (if I finish them before the end of the world) will present abstractions and frames for conceptualizing the odd kind of simulation language models do: inductively learned, partially observed / undetermined / lazily rendered, language-conditioned, etc. After that, I’ll shift to writing more specifically about the implications and questions posed by simulators for the alignment problem. I’ll list a few important general categories here:</blockquote></p><p><blockquote>Simulators like GPT give us methods of instantiating intelligent processes, including goal-directed agents, with methods other than optimizing against a reward function.</blockquote>\n<blockquote>GPT can be controlled to an impressive extent by prompt programming. Conditioning preserves distributional properties in potentially desirable but also potentially undesirable ways, and it’s not clear how out-of-distribution conditions will be interpreted by powerful simulators.</blockquote>\n        *   Several posts have been made about this recently:\n<blockquote>by Adam Jermyn</blockquote>\n<blockquote>by Jozdien</blockquote>\n<blockquote>by Johannes Treutlein</blockquote>\n<blockquote>by James Lucassen and Evan Hubinger</blockquote>\n<blockquote>.</blockquote>\n<blockquote>dataset is constructed for the intent of outcome-conditioning.</blockquote>\n<blockquote>, etc, how do we expect their behavior to diverge from the simulation objective?</blockquote>\n<blockquote>What can and what should we simulate, and how do we specify/control it?</blockquote>\n<blockquote>Many of the above considerations are influenced by how predictive learning generalizes out-of-distribution..</blockquote>\n    *   What are the relevant inductive biases?\n    *   What factors influence generalization behavior?\n<blockquote>?</blockquote>\n<blockquote>If simulators are not inner aligned, then many important properties like prediction orthogonality may not hold.</blockquote>\n    *   Should we expect self-supervised predictive models to be aligned to the simulation objective, or to “care” about some other mesaobjective?\n    *   Why mechanistically should mesaoptimizers form in predictive learning, versus for instance in reinforcement learning or GANs?\n    *   How would we test if simulators are inner aligned?\n<blockquote><h2>A note on GANs</h2></blockquote></p><p>GANs and predictive learning with log-loss are both shaped by a causal chain that flows from a single source of information: a ground truth distribution. In both cases the training process is supposed to make the generator model end up producing samples indistinguishable from the training distribution. But whereas log-loss minimizes the generator’s prediction loss against ground truth samples directly, in a GAN setup the generator never directly “sees” ground truth samples. It instead learns through interaction with an intermediary, the discriminator, which does get to see the ground truth, which it references to learn to tell real samples from forged ones produced by the generator. The generator is optimized to produce samples that fool the discriminator.</p><p>GANs are a form of self-supervised/unsupervised learning that resembles reinforcement learning in methodology. Note that the simulation objective – minimizing prediction loss on the training data – isn’t explicitly represented anywhere in the optimization process. The training losses of the generator and discriminator don’t tell you directly how well the generator models the training distribution, only which model has a relative advantage over the other.</p><p>If everything goes smoothly, then under unbounded optimization, a GAN setup should create a discriminator as good as possible at telling reals from fakes, which means the generator optimized to fool it should converge to generating samples statistically indistinguishable from training samples. But in practice, inductive biases and failure modes of GANs look very different from those of predictive learning.</p><p><blockquote>) are directly judged by the discriminator.</blockquote></p><p><blockquote>is how you get something I’d be willing to call an agent who wants to roleplay accurately.</blockquote>\n<blockquote>Are masked language models simulators? How about non-ML “simulators” like <a href=\"https://en.wikipedia.org/wiki/SimCity\">SimCity</a>?</blockquote></p><p>In my mind, “simulator”, like most natural language categories, has fuzzy boundaries. Below is a table which compares various simulator-like things to the type of simulator that GPT exemplifies on some quantifiable dimensions. The following properties all characterize GPT:</p><p><blockquote>Training samples are self-supervised</blockquote>\n<blockquote>The system is incentivized to model the transition probabilities of its training distribution faithfully</blockquote>\n<blockquote>The model naturally generates rollouts, i.e. serves as a time evolution operator</blockquote>\n<blockquote>There is not a 1:1 correspondence between the simulator and the things that it simulates</blockquote>\n<blockquote>The model outputs probabilities, and so simulates stochastic dynamics when used to evolve rollouts</blockquote>\n<blockquote>The input is interpreted by the simulator as partial evidence that informs an uncertain prediction, rather than propagated according to mechanistic rules</blockquote></p><p></p><p>*  : GPT\n  * Self-supervised: X\n  * Converges to simulation objective: X\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : Bert\n  * Self-supervised: X\n  * Converges to simulation objective: X\n  * Generates rollouts:  \n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : “Behavior cloning”\n  * Self-supervised: X\n  * Converges to simulation objective: X\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity:  \n  * Stochastic: X\n  * Evidential: X\n*  : GANs\n  * Self-supervised: X[30]\n  * Converges to simulation objective: ?\n  * Generates rollouts:  \n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : Diffusion\n  * Self-supervised: X[30]\n  * Converges to simulation objective: ?\n  * Generates rollouts:  \n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : Model-based RL transition function\n  * Self-supervised: X\n  * Converges to simulation objective: X\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : Game of life\n  * Self-supervised:  \n  * Converges to simulation objective: N/A\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic:  \n  * Evidential:  \n*  : Physics\n  * Self-supervised:  \n  * Converges to simulation objective: N/A\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential:  \n*  : Human imagination\n  * Self-supervised: X[31]\n  * Converges to simulation objective:  \n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential: X\n*  : SimCity\n  * Self-supervised:  \n  * Converges to simulation objective: N/A\n  * Generates rollouts: X\n  * Simulator / simulacra nonidentity: X\n  * Stochastic: X\n  * Evidential:  </p><p>\n<blockquote>2.  <strong><a href=\"#fnrefa35qx2ldayo\">^</a></strong></blockquote>\n    \n<blockquote>. No, he said, and he seemed similarly mystified as myself as to why not.</blockquote>\n    \n<blockquote>“Unsurprisingly, size matters: when training on a very large and complex data set, fitting the training data with an LSTM is fairly challenging. Thus, the size of the LSTM layer is a very important factor that influences the results(...). The best models are the largest we were able to fit into a GPU memory.”</blockquote>\n    \n<blockquote>It strikes me that this description may evoke “oracle”, but I’ll argue shortly that this is not the limit which prior usage of “oracle AI” has pointed to.</blockquote>\n    \n<blockquote>6.  <strong><a href=\"#fnrefoti8ojhy48a\">^</a></strong></blockquote>\n<blockquote>\\[citation needed\\]</blockquote>\n    \n<blockquote>9.  <strong><a href=\"#fnrefn3u1lofwts9\">^</a></strong></blockquote>\n    \n    although a simulated character might, if they knew what was happening.\n    \n<blockquote>You might say that it’s the will of a different agent, the author. But this pattern is learned from accounts of <a href=\"https://www.lesswrong.com/posts/sYgv4eYH82JEsTD34/beyond-the-reach-of-god\">real life</a> as well.</blockquote>\n    \n<blockquote>Note that this formulation assumes inner alignment to the prediction objective.</blockquote>\n    \n<blockquote>Note that this is a distinct claim from that of <a href=\"https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX\">Shard Theory</a>, which says that the effective agent(s) will not optimize for the outer objective <em>due to inner misalignment.</em> Predictive orthogonality refers to the outer objective and the form of idealized inner-aligned policies.</blockquote>\n    \n<blockquote>In the Eleuther discord</blockquote>\n    \n<blockquote>And if there is an inner alignment failure such that GPT forms preferences over the consequences of its actions, it’s not clear a priori that it will care about non-myopic text prediction over something else.</blockquote>\n    \n<blockquote>Having spoken to Gwern since, his perspective seems more akin to seeing physics as an agent that <a href=\"https://en.wikipedia.org/wiki/Principle<em>of</em>minimum<em>energy\">minimizes free energy</a>, a <a href=\"https://en.wikipedia.org/wiki/Free</em>energy_principle\">principle</a> which extends into the domain of self-organizing systems. I think this is a nuanced and valuable framing, with a potential implication/hypothesis that dynamical world models like GPT must learn the same type of optimizer-y cognition as agentic AI.</blockquote>\n    \n<blockquote>except arguably log-loss on a self-supervised test set, which isn’t very interpretable</blockquote>\n    \n<blockquote>The way GPT is trained actually processes each token as question and answer simultaneously.</blockquote>\n    \n<blockquote>One could argue that the focus on closed-ended tasks is necessary for benchmarking language models. Yes, and the focus on capabilities measurable with standardized benchmarks is part of the supervised learning mindset. </blockquote>\n    \n<blockquote>to abuse the term</blockquote>\n    \n<blockquote>Every usage of the word “question” here is in the functional, not semantic or grammatical sense – any prompt is a question for GPT.</blockquote>\n    \n<blockquote>Of course, there are also other interventions we can make except asking the right question at the beginning.</blockquote>\n    \n<blockquote>23.  <strong><a href=\"#fnrefbjl6s2y0l5a\">^</a></strong></blockquote>\n    \n    Jean Baudrillard, Simulacra and Simulation\n    \n<blockquote>A <a href=\"https://en.wikipedia.org/wiki/Scoring<em>rule#Proper</em>scoring_rules\">proper scoring rule</a> is optimized by predicting the “true” probabilities of the distribution which generates observations, and thus incentivizes honest probabilistic guesses. Log-loss (such as GPT is trained with) is a proper scoring rule.</blockquote>\n    \n<blockquote>Predictive accuracy is deontological with respect to the output as an <em>action</em>, but may still incentivize instrumentally convergent inner implementation, with the output prediction itself as the “consequentialist” objective.</blockquote>\n    \n<blockquote>This isn’t strictly true because of attention gradients: GPT's computation is optimized not only to predict the next token correctly, but also to cause <em>future tokens to be predicted correctly</em> when looked up by attention. I may write a post about this in the future.</blockquote>\n    \n<blockquote>actually, the <a href=\"https://generative.ink/posts/language-models-are-multiverse-generators/\">multiverse</a>, if physics is stochastic</blockquote>\n    \n<blockquote>The reason we don’t see a bunch of simulated alternate universes after humans guessed the laws of physics is because our reality has a huge state vector, making evolution according to the laws of physics infeasible to compute. Thanks to locality, we do have simulations of small configurations, though.</blockquote>\n    \n<blockquote>30.  <strong><a href=\"#fnrefbfhs37ysptj\">^</a></strong></blockquote>\n    \n    GANs and diffusion models can be unconditioned (unsupervised) or conditioned (self-supervised) \n    \n<blockquote>The human imagination is surely shaped by self-supervised learning (predictive learning on e.g. sensory datastreams), but probably also other influences, including innate structure and reinforcement.</blockquote></p>"
  },
  {
    "id": "20240821234146849695503",
    "title": "Vim Reference Guide",
    "source": "/uploads/20240821234146815128325-vim_reference_guide_v2p0.pdf",
    "fileType": "PDF",
    "status": "unread",
    "tags": [
      "Vim",
      "Reference",
      "Guide"
    ],
    "read": {
      "text": "52 min read",
      "minutes": 51.06,
      "time": 3063600,
      "words": 10212
    }
  },
  {
    "id": "20240821234228488338387",
    "title": "Virtue Ethics",
    "source": "https://plato.stanford.edu/entries/ethics-virtue/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Ethics",
      "Philosophy"
    ],
    "read": {
      "text": "68 min read",
      "minutes": 67.82,
      "time": 4069200,
      "words": 13564
    },
    "markdown": "<p><blockquote>In the West, virtue ethics’ founding fathers are Plato and Aristotle, and in the East it can be traced back to Mencius and Confucius. It persisted as the dominant approach in Western moral philosophy until at least the Enlightenment, suffered a momentary eclipse during the nineteenth century, but re-emerged in Anglo-American philosophy in the late 1950s. It was heralded by Anscombe’s famous article “Modern Moral Philosophy” (Anscombe 1958) which crystallized an increasing dissatisfaction with the forms of deontology and utilitarianism then prevailing. Neither of them, at that time, paid attention to a number of topics that had always figured in the virtue ethics tradition—virtues and vices, motives and moral character, moral education, moral wisdom or discernment, friendship and family relationships, a deep concept of happiness, the role of the emotions in our moral life and the fundamentally important questions of what sorts of persons we should be and how we should live.</blockquote></p><p><blockquote>, and utilitarians have developed consequentialist virtue theories (Driver 2001; Hurka 2001). It has also generated virtue ethical readings of philosophers other than Plato and Aristotle, such as Martineau, Hume and Nietzsche, and thereby different forms of virtue ethics have developed (Slote 2001; Swanton 2003, 2011a).</blockquote></p><p><blockquote>is discussed in connection with eudaimonist versions of virtue ethics in the next.</blockquote></p><p><blockquote>A virtue is an excellent trait of character. It is a disposition, well entrenched in its possessor—something that, as we say, goes all the way down, unlike a habit such as being a tea-drinker—to notice, expect, value, feel, desire, choose, act, and react in certain characteristic ways. To possess a virtue is to be a certain sort of person with a certain complex mindset. A significant aspect of this mindset is the wholehearted acceptance of a distinctive range of considerations as reasons for action. An honest person cannot be identified simply as one who, for example, practices honest dealing and does not cheat. If such actions are done merely because the agent thinks that honesty is the best policy, or because they fear being caught out, rather than through recognising “To do otherwise would be dishonest” as the relevant reason, they are not the actions of an honest person. An honest person cannot be identified simply as one who, for example, tells the truth because it <em>is</em> the truth, for one can have the virtue of honesty without being tactless or indiscreet. The honest person recognises “That would be a lie” as a strong (though perhaps not overriding) reason for not making certain statements in certain circumstances, and gives due, but not overriding, weight to “That would be the truth” as a reason for making them.</blockquote></p><p>An honest person’s reasons and choices with respect to honest and dishonest actions reflect her views about honesty, truth, and deception—but of course such views manifest themselves with respect to other actions, and to emotional reactions as well. Valuing honesty as she does, she chooses, where possible to work with honest people, to have honest friends, to bring up her children to be honest. She disapproves of, dislikes, deplores dishonesty, is not amused by certain tales of chicanery, despises or pities those who succeed through deception rather than thinking they have been clever, is unsurprised, or pleased (as appropriate) when honesty triumphs, is shocked or distressed when those near and dear to her do what is dishonest and so on. Given that a virtue is such a multi-track disposition, it would obviously be reckless to attribute one to an agent on the basis of a single observed action or even a series of similar actions, especially if you don’t know the agent’s reasons for doing as she did (Sreenivasan 2002).</p><p>Possessing a virtue is a matter of degree. To possess such a disposition fully is to possess full or perfect virtue, which is rare, and there are a number of ways of falling short of this ideal (Athanassoulis 2000). Most people who can truly be described as fairly virtuous, and certainly markedly better than those who can truly be described as dishonest, self-centred and greedy, still have their blind spots—little areas where they do not act for the reasons one would expect. So someone honest or kind in most situations, and notably so in demanding ones, may nevertheless be trivially tainted by snobbery, inclined to be disingenuous about their forebears and less than kind to strangers with the wrong accent.</p><p>Further, it is not easy to get one’s emotions in harmony with one’s rational recognition of certain reasons for action. I may be honest enough to recognise that I must own up to a mistake because it would be dishonest not to do so without my acceptance being so wholehearted that I can own up easily, with no inner conflict. Following (and adapting) Aristotle, virtue ethicists draw a distinction between full or perfect virtue and “continence”, or strength of will. The fully virtuous do what they should without a struggle against contrary desires; the continent have to control a desire or temptation to do otherwise.</p><p>Describing the continent as “falling short” of perfect virtue appears to go against the intuition that there is something particularly admirable about people who manage to act well when it is especially hard for them to do so, but the plausibility of this depends on exactly what “makes it hard” (Foot 1978: 11–14). If it is the circumstances in which the agent acts—say that she is very poor when she sees someone drop a full purse or that she is in deep grief when someone visits seeking help—then indeed it is particularly admirable of her to restore the purse or give the help when it is hard for her to do so. But if what makes it hard is an imperfection in her character—the temptation to keep what is not hers, or a callous indifference to the suffering of others—then it is not.</p><p><blockquote>Another way in which one can easily fall short of full virtue is through lacking <em>phronesis</em>—moral or practical wisdom.</blockquote></p><p>The concept of a virtue is the concept of something that makes its possessor good: a virtuous person is a morally good, excellent or admirable person who acts and feels as she should. These are commonly accepted truisms. But it is equally common, in relation to particular (putative) examples of virtues to give these truisms up. We may say of someone that he is generous or honest “to a fault”. It is commonly asserted that someone’s compassion might lead them to act wrongly, to tell a lie they should not have told, for example, in their desire to prevent someone else’s hurt feelings. It is also said that courage, in a desperado, enables him to do far more wicked things than he would have been able to do if he were timid. So it would appear that generosity, honesty, compassion and courage despite being virtues, are sometimes faults. Someone who is generous, honest, compassionate, and courageous might not be a morally good person—or, if it is still held to be a truism that they are, then morally good people may be led by what makes them morally good to act wrongly! How have we arrived at such an odd conclusion?</p><p><blockquote>or practical wisdom.</blockquote></p><p><blockquote>that are the subject of much scholarly debate, but the (related) modern concept is best understood by thinking of what the virtuous morally mature adult has that nice children, including nice adolescents, lack. Both the virtuous adult and the nice child have good intentions, but the child is much more prone to mess things up because he is ignorant of what he needs to know in order to do what he intends. A virtuous adult is not, of course, infallible and may also, on occasion, fail to do what she intended to do through lack of knowledge, but only on those occasions on which the lack of knowledge is not culpable. So, for example, children and adolescents often harm those they intend to benefit either because they do not know how to set about securing the benefit or because their understanding of what is beneficial and harmful is limited and often mistaken. Such ignorance in small children is rarely, if ever culpable. Adults, on the other hand, are culpable if they mess things up by being thoughtless, insensitive, reckless, impulsive, shortsighted, and by assuming that what suits them will suit everyone instead of taking a more objective viewpoint. They are also culpable if their understanding of what is beneficial and harmful is mistaken. It is part of practical wisdom to know how to secure real benefits effectively; those who have practical wisdom will not make the mistake of concealing the hurtful truth from the person who really needs to know it in the belief that they are benefiting him.</blockquote></p><p>Quite generally, given that good intentions are intentions to act well or “do the right thing”, we may say that practical wisdom is the knowledge or understanding that enables its possessor, unlike the nice adolescents, to do just that, in any given situation. The detailed specification of what is involved in such knowledge or understanding has not yet appeared in the literature, but some aspects of it are becoming well known. Even many deontologists now stress the point that their action-guiding rules cannot, reliably, be applied without practical wisdom, because correct application requires situational appreciation—the capacity to recognise, in any particular situation, those features of it that are morally salient. This brings out two aspects of practical wisdom.</p><p>One is that it characteristically comes only with experience of life. Amongst the morally relevant features of a situation may be the likely consequences, for the people involved, of a certain action, and this is something that adolescents are notoriously clueless about precisely because they are inexperienced. It is part of practical wisdom to be wise about human beings and human life. (It should go without saying that the virtuous are mindful of the consequences of possible actions. How could they fail to be reckless, thoughtless and short-sighted if they were not?)</p><p>The second is the practically wise agent’s capacity to recognise some features of a situation as more important than others, or indeed, in that situation, as the only relevant ones. The wise do not see things in the same way as the nice adolescents who, with their under-developed virtues, still tend to see the personally disadvantageous nature of a certain action as competing in importance with its honesty or benevolence or justice.</p><p>These aspects coalesce in the description of the practically wise as those who understand what is truly worthwhile, truly important, and thereby truly advantageous in life, who know, in short, how to live well.\n<blockquote>While all forms of virtue ethics agree that virtue is central and practical wisdom required, they differ in how they combine these and other concepts to illuminate what we should do in particular contexts and how we should live our lives as a whole. In what follows we sketch four distinct forms taken by contemporary virtue ethics, namely, a) eudaimonist virtue ethics, b) agent-based and exemplarist virtue ethics, c) target-centered virtue ethics, and d) Platonistic virtue ethics.</blockquote></p><p><blockquote>The distinctive feature of eudaimonist versions of virtue ethics is that they define virtues in terms of their relationship to <em>eudaimonia</em>. A virtue is a trait that contributes to or is a constituent of <em>eudaimonia</em> and we ought to develop virtues, the eudaimonist claims, precisely because they contribute to <em>eudaimonia</em>.</blockquote></p><p><blockquote>, or of what it is to live well as a human being, believing it to consist largely in physical pleasure or luxury for example.</blockquote></p><p><blockquote>is, avowedly, a moralized or value-laden concept of happiness, something like “true” or “real” happiness or “the sort of happiness worth seeking or having.” It is thereby the sort of concept about which there can be substantial disagreement between people with different views about human life that cannot be resolved by appeal to some external standard on which, despite their different views, the parties to the disagreement concur (Hursthouse 1999: 188–189).</blockquote></p><p><blockquote>, but a wasted life.</blockquote></p><p><blockquote>(Annas 1993).</blockquote></p><p><blockquote>and what confers virtue status on a character trait. (For a discussion of the differences between eudaimonists see Baril 2014. For recent defenses of eudaimonism see Annas 2011; LeBar 2013b; Badhwar 2014; and Bloomfield 2014.)</blockquote></p><p><blockquote>Rather than deriving the normativity of virtue from the value of <em>eudaimonia</em>, agent-based virtue ethicists argue that other forms of normativity—including the value of <em>eudaimonia</em>—are traced back to and ultimately explained in terms of the motivational and dispositional qualities of agents.</blockquote></p><p><blockquote>characteristically would not do, and he would feel guilty if he did = an act such that it is not the case that he might do it = an act that expresses a vice = an act that is against a requirement of virtue (the virtuous self)” (Zagzebski 2004: 160). Her definitions of duties, good and bad ends, and good and bad states of affairs are similarly grounded in the motivational and dispositional states of exemplary agents (1998, 2004, 2010).</blockquote></p><p><blockquote>or states of affairs) which is taken to be more fundamental.</blockquote></p><p><blockquote>enables Zagzebski to distinguish between performing the right action and doing so for the right reasons (a distinction that, as Brady (2004) observes, Slote has trouble drawing).</blockquote></p><p>Another point on which agent-based forms of virtue ethics might differ concerns how one identifies virtuous motivations and dispositions. According to Zagzebski’s exemplarist account, “We do not have criteria for goodness in advance of identifying the exemplars of goodness” (Zagzebski 2004: 41). As we observe the people around us, we find ourselves wanting to be like some of them (in at least some respects) and not wanting to be like others. The former provide us with positive exemplars and the latter with negative ones. Our understanding of better and worse motivations and virtuous and vicious dispositions is grounded in these primitive responses to exemplars (2004: 53). This is not to say that every time we act we stop and ask ourselves what one of our exemplars would do in this situations. Our moral concepts become more refined over time as we encounter a wider variety of exemplars and begin to draw systematic connections between them, noting what they have in common, how they differ, and which of these commonalities and differences matter, morally speaking. Recognizable motivational profiles emerge and come to be labeled as virtues or vices, and these, in turn, shape our understanding of the obligations we have and the ends we should pursue. However, even though the systematising of moral thought can travel a long way from our starting point, according to the exemplarist it never reaches a stage where reference to exemplars is replaced by the recognition of something more fundamental. At the end of the day, according to the exemplarist, our moral system still rests on our basic propensity to take a liking (or disliking) to exemplars. Nevertheless, one could be an agent-based theorist without advancing the exemplarist’s account of the origins or reference conditions for judgments of good and bad, virtuous and vicious.</p><p><blockquote>The touchstone for eudaimonist virtue ethicists is a flourishing human life. For agent-based virtue ethicists it is an exemplary agent’s motivations. The target-centered view developed by Christine Swanton (2003), by contrast, begins with our existing conceptions of the virtues. We already have a passable idea of which traits are virtues and what they involve. Of course, this untutored understanding can be clarified and improved, and it is one of the tasks of the virtue ethicist to help us do precisely that. But rather than stripping things back to something as basic as the motivations we want to imitate or building it up to something as elaborate as an entire flourishing life, the target-centered view begins where most ethics students find themselves, namely, with the idea that generosity, courage, self-discipline, compassion, and the like get a tick of approval. It then examines what these traits involve.</blockquote></p><p><blockquote>is that at which it is aimed. Courage aims to control fear and handle danger, while generosity aims to share time, talents, or possessions with others in ways that benefit them.</blockquote></p><p><blockquote>target-centered account would not even require an action to be good in order to be right. On such a view, “An act is right if and only if it is not overall vicious” (240). (For further discussion of target-centered virtue ethics see Van Zyl 2014; and Smith 2016).</blockquote></p><p><blockquote>The fourth form a virtue ethic might adopt takes its inspiration from Plato. The Socrates of Plato’s dialogues devotes a great deal of time to asking his fellow Athenians to explain the nature of virtues like justice, courage, piety, and wisdom. So it is clear that Plato counts as a virtue theorist. But it is a matter of some debate whether he should be read as a virtue ethicist (White 2015). What is not open to debate is whether Plato has had an important influence on the contemporary revival of interest in virtue ethics. A number of those who have contributed to the revival have done so as Plato scholars (e.g., Prior 1991; Kamtekar 1998; Annas 1999; and Reshotko 2006). However, often they have ended up championing a eudaimonist version of virtue ethics (see Prior 2001 and Annas 2011), rather than a version that would warrant a separate classification. Nevertheless, there are two variants that call for distinct treatment.</blockquote></p><p>Timothy Chappell takes the defining feature of Platonistic virtue ethics to be that “Good agency in the truest and fullest sense presupposes the contemplation of the Form of the Good” (2014). Chappell follows Iris Murdoch in arguing that “In the moral life the enemy is the fat relentless ego” (Murdoch 1971: 51). Constantly attending to our needs, our desires, our passions, and our thoughts skews our perspective on what the world is actually like and blinds us to the goods around us. Contemplating the goodness of something we encounter—which is to say, carefully attending to it “for its own sake, in order to understand it” (Chappell 2014: 300)—breaks this natural tendency by drawing our attention away from ourselves. Contemplating such goodness with regularity makes room for new habits of thought that focus more readily and more honestly on things other than the self. It alters the quality of our consciousness. And “anything which alters consciousness in the direction of unselfishness, objectivity, and realism is to be connected with virtue” (Murdoch 1971: 82). The virtues get defined, then, in terms of qualities that help one “pierce the veil of selfish consciousness and join the world as it really is” (91). And good agency is defined by the possession and exercise of such virtues. Within Chappell’s and Murdoch’s framework, then, not all normative properties get defined in terms of virtue. Goodness, in particular, is not so defined. But the kind of goodness which is possible for creatures like us is defined by virtue, and any answer to the question of what one should do or how one should live will appeal to the virtues.</p><p>Another Platonistic variant of virtue ethics is exemplified by Robert Merrihew Adams. Unlike Murdoch and Chappell, his starting point is not a set of claims about our consciousness of goodness. Rather, he begins with an account of the metaphysics of goodness. Like Murdoch and others influenced by Platonism, Adams’s account of goodness is built around a conception of a supremely perfect good. And like Augustine, Adams takes that perfect good to be God. God is both the exemplification and the source of all goodness. Other things are good, he suggests, to the extent that they resemble God (Adams 1999).</p><p>The resemblance requirement identifies a necessary condition for being good, but it does not yet give us a sufficient condition. This is because there are ways in which finite creatures might resemble God that would not be suitable to the type of creature they are. For example, if God were all-knowing, then the belief, “I am all-knowing,” would be a suitable belief for God to have. In God, such a belief—because true—would be part of God’s perfection. However, as neither you nor I are all-knowing, the belief, “I am all-knowing,” in one of us would not be good. To rule out such cases we need to introduce another factor. That factor is the fitting response to goodness, which Adams suggests is love. Adams uses love to weed out problematic resemblances: “being excellent in the way that a finite thing can be consists in resembling God in a way that could serve God as a reason for loving the thing” (Adams 1999: 36).</p><p>Virtues come into the account as one of the ways in which some things (namely, persons) could resemble God. “\\[M\\]ost of the excellences that are most important to us, and of whose value we are most confident, are excellences of persons or of qualities or actions or works or lives or stories of persons” (1999: 42). This is one of the reasons Adams offers for conceiving of the ideal of perfection as a personal God, rather than an impersonal form of the Good. Many of the excellences of persons of which we are most confident are virtues such as love, wisdom, justice, patience, and generosity. And within many theistic traditions, including Adams’s own Christian tradition, such virtues are commonly attributed to divine agents.</p><p><blockquote>(2006) see Pettigrove 2014). Goodness provides the normative foundation. Virtues are not built on that foundation; rather, as one of the varieties of goodness of whose value we are most confident, virtues form part of the foundation. Obligations, by contrast, come into the account at a different level. Moral obligations, Adams argues, are determined by the expectations and demands that “arise in a relationship or system of relationships that is good or valuable” (1999: 244). Other things being equal, the more virtuous the parties to the relationship, the more binding the obligation. Thus, within Adams’s account, the good (which includes virtue) is prior to the right. However, once good relationships have given rise to obligations, those obligations take on a life of their own. Their bindingness is not traced directly to considerations of goodness. Rather, they are determined by the expectations of the parties and the demands of the relationship.</blockquote>\n<blockquote>A number of objections have been raised against virtue ethics, some of which bear more directly on one form of virtue ethics than on others. In this section we consider eight objections, namely, the a) application, b) adequacy, c) relativism, d) conflict, e) self-effacement, f) justification, g) egoism, and h) situationist problems.</blockquote></p><p>a) In the early days of virtue ethics’ revival, the approach was associated with an “anti-codifiability” thesis about ethics, directed against the prevailing pretensions of normative theory. At the time, utilitarians and deontologists commonly (though not universally) held that the task of ethical theory was to come up with a code consisting of universal rules or principles (possibly only one, as in the case of act-utilitarianism) which would have two significant features: i) the rule(s) would amount to a decision procedure for determining what the right action was in any particular case; ii) the rule(s) would be stated in such terms that any non-virtuous person could understand and apply it (them) correctly.</p><p><blockquote>in short—is needed to apply rules or principles correctly. Hence many (though by no means all) utilitarians and deontologists have explicitly abandoned (ii) and much less emphasis is placed on (i).</blockquote></p><p>Nevertheless, the complaint that virtue ethics does not produce codifiable principles is still a commonly voiced criticism of the approach, expressed as the objection that it is, in principle, unable to provide action-guidance.</p><p>Initially, the objection was based on a misunderstanding. Blinkered by slogans that described virtue ethics as “concerned with Being rather than Doing,” as addressing “What sort of person should I be?” but not “What should I do?” as being “agent-centered rather than act-centered,” its critics maintained that it was unable to provide action-guidance. Hence, rather than being a normative rival to utilitarian and deontological ethics, it could claim to be no more than a valuable supplement to them. The rather odd idea was that all virtue ethics could offer was, “Identify a moral exemplar and do what he would do,” as though the university student trying to decide whether to study music (her preference) or engineering (her parents’ preference) was supposed to ask herself, “What would Socrates study if he were in my circumstances?”</p><p>But the objection failed to take note of Anscombe’s hint that a great deal of specific action guidance could be found in rules employing the virtue and vice terms (“v-rules”) such as “Do what is honest/charitable; do not do what is dishonest/uncharitable” (Hursthouse 1999). (It is a noteworthy feature of our virtue and vice vocabulary that, although our list of generally recognised virtue terms is comparatively short, our list of vice terms is remarkably, and usefully, long, far exceeding anything that anyone who thinks in terms of standard deontological rules has ever come up with. Much invaluable action guidance comes from avoiding courses of action that would be irresponsible, feckless, lazy, inconsiderate, uncooperative, harsh, intolerant, selfish, mercenary, indiscreet, tactless, arrogant, unsympathetic, cold, incautious, unenterprising, pusillanimous, feeble, presumptuous, rude, hypocritical, self-indulgent, materialistic, grasping, short-sighted, vindictive, calculating, ungrateful, grudging, brutal, profligate, disloyal, and on and on.)</p><p>(b) A closely related objection has to do with whether virtue ethics can provide an adequate account of right action. This worry can take two forms. (i) One might think a virtue ethical account of right action is extensionally inadequate. It is possible to perform a right action without being virtuous and a virtuous person can occasionally perform the wrong action without that calling her virtue into question. If virtue is neither necessary nor sufficient for right action, one might wonder whether the relationship between rightness/wrongness and virtue/vice is close enough for the former to be identified in terms of the latter. (ii) Alternatively, even if one thought it possible to produce a virtue ethical account that picked out all (and only) right actions, one might still think that at least in some cases virtue is not what explains rightness (Adams 2006:6–8).</p><p>Some virtue ethicists respond to the adequacy objection by rejecting the assumption that virtue ethics ought to be in the business of providing an account of right action in the first place. Following in the footsteps of Anscombe (1958) and MacIntyre (1985), Talbot Brewer (2009) argues that to work with the categories of rightness and wrongness is already to get off on the wrong foot. Contemporary conceptions of right and wrong action, built as they are around a notion of moral duty that presupposes a framework of divine (or moral) law or around a conception of obligation that is defined in contrast to self-interest, carry baggage the virtue ethicist is better off without. Virtue ethics can address the questions of how one should live, what kind of person one should become, and even what one should do without that committing it to providing an account of ‘right action’. One might choose, instead, to work with aretaic concepts (defined in terms of virtues and vices) and axiological concepts (defined in terms of good and bad, better and worse) and leave out deontic notions (like right/wrong action, duty, and obligation) altogether.</p><p>Other virtue ethicists wish to retain the concept of right action but note that in the current philosophical discussion a number of distinct qualities march under that banner. In some contexts, ‘right action’ identifies the best action an agent might perform in the circumstances. In others, it designates an action that is commendable (even if not the best possible). In still others, it picks out actions that are not blameworthy (even if not commendable). A virtue ethicist might choose to define one of these—for example, the best action—in terms of virtues and vices, but appeal to other normative concepts—such as legitimate expectations—when defining other conceptions of right action.</p><p><blockquote>vices makes it much easier to achieve extensional adequacy. Making room for normative concepts that are not taken to be reducible to virtue and vice concepts makes it even easier to generate a theory that is both extensionally and explanatorily adequate. Whether one needs other concepts and, if so, how many, is still a matter of debate among virtue ethicists, as is the question of whether virtue ethics even ought to be offering an account of right action. Either way virtue ethicists have resources available to them to address the adequacy objection.</blockquote></p><p><blockquote>) the quite general metaethical problem of justifying one’s moral beliefs to those who disagree, whether they be moral sceptics, pluralists or from another culture.</blockquote></p><p>A bolder strategy involves claiming that virtue ethics has less difficulty with cultural relativity than the other two approaches. Much cultural disagreement arises, it may be claimed, from local understandings of the virtues, but the virtues themselves are not relative to culture (Nussbaum 1993).</p><p><blockquote>, irresolvable.</blockquote></p><p>Another problem arguably shared by all three approaches is (e), that of being self-effacing. An ethical theory is self-effacing if, roughly, whatever it claims justifies a particular action, or makes it right, had better not be the agent’s motive for doing it. Michael Stocker (1976) originally introduced it as a problem for deontology and consequentialism. He pointed out that the agent who, rightly, visits a friend in hospital will rather lessen the impact of his visit on her if he tells her either that he is doing it because it is his duty or because he thought it would maximize the general happiness. But as Simon Keller observes, she won’t be any better pleased if he tells her that he is visiting her because it is what a virtuous agent would do, so virtue ethics would appear to have the problem too (Keller 2007). However, virtue ethics’ defenders have argued that not all forms of virtue ethics are subject to this objection (Pettigrove 2011) and those that are are not seriously undermined by the problem (Martinez 2011).</p><p>Another problem for virtue ethics, which is shared by both utilitarianism and deontology, is (f) “the justification problem.” Abstractly conceived, this is the problem of how we justify or ground our ethical beliefs, an issue that is hotly debated at the level of metaethics. In its particular versions, for deontology there is the question of how to justify its claims that certain moral rules are the correct ones, and for utilitarianism of how to justify its claim that all that really matters morally are consequences for happiness or well-being. For virtue ethics, the problem concerns the question of which character traits are the virtues.</p><p>In the metaethical debate, there is widespread disagreement about the possibility of providing an external foundation for ethics—“external” in the sense of being external to ethical beliefs—and the same disagreement is found amongst deontologists and utilitarians. Some believe that their normative ethics can be placed on a secure basis, resistant to any form of scepticism, such as what anyone rationally desires, or would accept or agree on, regardless of their ethical outlook; others that it cannot.</p><p>Virtue ethicists have eschewed any attempt to ground virtue ethics in an external foundation while continuing to maintain that their claims can be validated. Some follow a form of Rawls’s coherentist approach (Slote 2001; Swanton 2003); neo-Aristotelians a form of ethical naturalism.</p><p><blockquote>on what kind of animal they are and what capacities, desires and interests the humans or elephants have.</blockquote></p><p>The best available science today (including evolutionary theory and psychology) supports rather than undermines the ancient Greek assumption that we are social animals, like elephants and wolves and unlike polar bears. No rationalizing explanation in terms of anything like a social contract is needed to explain why we choose to live together, subjugating our egoistic desires in order to secure the advantages of co-operation. Like other social animals, our natural impulses are not solely directed towards our own pleasures and preservation, but include altruistic and cooperative ones.</p><p>This basic fact about us should make more comprehensible the claim that the virtues are at least partially constitutive of human flourishing and also undercut the objection that virtue ethics is, in some sense, egoistic.</p><p><blockquote>But “the virtuous agent” is just “the agent with the virtues” and it is part of our ordinary understanding of the virtue terms that each carries with it its own typical range of reasons for acting. The virtuous agent acts as she does because she believes that someone’s suffering will be averted, or someone benefited, or the truth established, or a debt repaid, or … thereby.</blockquote></p><p><blockquote>life is a life that has been successfully lived (where “success” of course is not to be understood in a materialistic way) and such people die knowing not only that they have made a success of their lives but that they have also brought their lives to a markedly successful completion. Either way, such heroic acts can hardly be regarded as egoistic.</blockquote></p><p><blockquote>is not possible. Secondly, given that we live together, as social animals, the “self-regarding” virtues do benefit others—those who lack them are a great drain on, and sometimes grief to, those who are close to them (as parents with improvident or imprudent adult offspring know only too well).</blockquote></p><p>The most recent objection (h) to virtue ethics claims that work in “situationist” social psychology shows that there are no such things as character traits and thereby no such things as virtues for virtue ethics to be about (Doris 1998; Harman 1999). In reply, some virtue ethicists have argued that the social psychologists’ studies are irrelevant to the multi-track disposition (see above) that a virtue is supposed to be (Sreenivasan 2002; Kamtekar 2004). Mindful of just how multi-track it is, they agree that it would be reckless in the extreme to ascribe a demanding virtue such as charity to people of whom they know no more than that they have exhibited conventional decency; this would indeed be “a fundamental attribution error.” Others have worked to develop alternative, empirically grounded conceptions of character traits (Snow 2010; Miller 2013 and 2014; however see Upton 2016 for objections to Miller). There have been other responses as well (summarized helpfully in Prinz 2009 and Miller 2014). Notable among these is a response by Adams (2006, echoing Merritt 2000) who steers a middle road between “no character traits at all” and the exacting standard of the Aristotelian conception of virtue which, because of its emphasis on phronesis, requires a high level of character integration. On his conception, character traits may be “frail and fragmentary” but still virtues, and not uncommon. But giving up the idea that practical wisdom is the heart of all the virtues, as Adams has to do, is a substantial sacrifice, as Russell (2009) and Kamtekar (2010) argue.</p><p><blockquote>and, quite independently, an upsurge of interest in character education (see below).</blockquote>\n<blockquote>Over the past thirty-five years most of those contributing to the revival of virtue ethics have worked within a neo-Aristotelian, eudaimonist framework. However, as noted in section 2, other forms of virtue ethics have begun to emerge. Theorists have begun to turn to philosophers like Hutcheson, Hume, Nietzsche, Martineau, and Heidegger for resources they might use to develop alternatives (see Russell 2006; Swanton 2013 and 2015; Taylor 2015; and Harcourt 2015). Others have turned their attention eastward, exploring Confucian, Buddhist, and Hindu traditions (Yu 2007; Slingerland 2011; Finnigan and Tanaka 2011; McRae 2012; Angle and Slote 2013; Davis 2014; Flanagan 2015; Perrett and Pettigrove 2015; and Sim 2015). These explorations promise to open up new avenues for the development of virtue ethics.</blockquote></p><p>Although virtue ethics has grown remarkably in the last thirty-five years, it is still very much in the minority, particularly in the area of applied ethics. Many editors of big textbook collections on “moral problems” or “applied ethics” now try to include articles representative of each of the three normative approaches but are often unable to find a virtue ethics article addressing a particular issue. This is sometimes, no doubt, because “the” issue has been set up as a deontologicial/utilitarian debate, but it is often simply because no virtue ethicist has yet written on the topic. However, the last decade has seen an increase in the amount of attention applied virtue ethics has received (Walker and Ivanhoe 2007; Hartman 2013; Austin 2014; Van Hooft 2014; and Annas 2015). This area can certainly be expected to grow in the future, and it looks as though applying virtue ethics in the field of environmental ethics may prove particularly fruitful (Sandler 2007; Hursthouse 2007, 2011; Zwolinski and Schmidtz 2013; Cafaro 2015).</p><p>Whether virtue ethics can be expected to grow into “virtue politics”—i.e. to extend from moral philosophy into political philosophy—is not so clear. Gisela Striker (2006) has argued that Aristotle’s ethics cannot be understood adequately without attending to its place in his politics. That suggests that at least those virtue ethicists who take their inspiration from Aristotle should have resources to offer for the development of virtue politics. But, while Plato and Aristotle can be great inspirations as far as virtue ethics is concerned, neither, on the face of it, are attractive sources of insight where politics is concerned. However, recent work suggests that Aristotelian ideas can, after all, generate a satisfyingly liberal political philosophy (Nussbaum 2006; LeBar 2013a). Moreover, as noted above, virtue ethics does not have to be neo-Aristotelian. It may be that the virtue ethics of Hutcheson and Hume can be naturally extended into a modern political philosophy (Hursthouse 1990–91; Slote 1993).</p><p>Following Plato and Aristotle, modern virtue ethics has always emphasised the importance of moral education, not as the inculcation of rules but as the training of character. There is now a growing movement towards virtues education, amongst both academics (Carr 1999; Athanassoulis 2014; Curren 2015) and teachers in the classroom. One exciting thing about research in this area is its engagement with other academic disciplines, including psychology, educational theory, and theology (see Cline 2015; and Snow 2015).</p><p>Finally, one of the more productive developments of virtue ethics has come through the study of particular virtues and vices. There are now a number of careful studies of the cardinal virtues and capital vices (Pieper 1966; Taylor 2006; Curzer 2012; Timpe and Boyd 2014). Others have explored less widely discussed virtues or vices, such as civility, decency, truthfulness, ambition, and meekness (Calhoun 2000; Kekes 2002; Williams 2002; and Pettigrove 2007 and 2012). One of the questions these studies raise is “How many virtues are there?” A second is, “How are these virtues related to one another?” Some virtue ethicists have been happy to work on the assumption that there is no principled reason for limiting the number of virtues and plenty of reason for positing a plurality of them (Swanton 2003; Battaly 2015). Others have been concerned that such an open-handed approach to the virtues will make it difficult for virtue ethicists to come up with an adequate account of right action or deal with the conflict problem discussed above. Dan Russell has proposed cardinality and a version of the unity thesis as a solution to what he calls “the enumeration problem” (the problem of too many virtues). The apparent proliferation of virtues can be significantly reduced if we group virtues together with some being cardinal and others subordinate extensions of those cardinal virtues. Possible conflicts between the remaining virtues can then be managed if they are tied together in some way as part of a unified whole (Russell 2009). This highlights two important avenues for future research, one of which explores individual virtues and the other of which analyses how they might be related to one another.</p>"
  },
  {
    "id": "20240821234245064731093",
    "title": "Deontology",
    "source": "https://plato.stanford.edu/entries/ethics-deontological/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Ethics",
      "Philosophy"
    ],
    "read": {
      "text": "66 min read",
      "minutes": 65.39,
      "time": 3923400,
      "words": 13078
    },
    "markdown": "<p><blockquote>.</blockquote>\n<blockquote>Because deontological theories are best understood in contrast to consequentialist ones, a brief look at consequentialism and a survey of the problems with it that motivate its deontological opponents, provides a helpful prelude to taking up deontological theories themselves. Consequentialists hold that choices—acts and/or intentions—are to be morally assessed solely by the states of affairs they bring about. Consequentialists thus must specify initially the states of affairs that are intrinsically valuable—often called, collectively, “the Good.” They then are in a position to assert that whatever choices increase the Good, that is, bring about more of it, are the choices that it is morally right to make and to execute. (The Good in that sense is said to be prior to “the Right.”)</blockquote></p><p>Consequentialists can and do differ widely in terms of specifying the Good. Some consequentialists are monists about the Good. Utilitarians, for example, identify the Good with pleasure, happiness, desire satisfaction, or “welfare” in some other sense. Other consequentialists are pluralists regarding the Good. Some of such pluralists believe that how the Good is distributed among persons (or all sentient beings) is itself partly constitutive of the Good, whereas conventional utilitarians merely add or average each person’s share of the Good to achieve the Good’s maximization.</p><p>Moreover, there are some consequentialists who hold that the doing or refraining from doing, of certain kinds of acts are themselves intrinsically valuable states of affairs constitutive of the Good. An example of this is the positing of rights not being violated, or duties being kept, as part of the Good to be maximized—the so-called “utilitarianism of rights” (Nozick 1974).</p><p>None of these pluralist positions erase the difference between consequentialism and deontology. For the essence of consequentialism is still present in such positions: an action would be right only insofar as it maximizes these Good-making states of affairs being caused to exist.</p><p>However much consequentialists differ about what the Good consists in, they all agree that the morally right choices are those that increase (either directly or indirectly) the Good. Moreover, consequentialists generally agree that the Good is “agent-neutral” (Parfit 1984; Nagel 1986). That is, valuable states of affairs are states of affairs that all agents have reason to achieve without regard to whether such states of affairs are achieved through the exercise of one’s own agency or not.</p><p>Consequentialism is frequently criticized on a number of grounds. Two of these are particularly apt for revealing the temptations motivating the alternative approach to deontic ethics that is deontology. The two criticisms pertinent here are that consequentialism is, on the one hand, overly demanding, and, on the other hand, that it is not demanding enough. The criticism regarding extreme demandingness runs like this: for consequentialists, there is no realm of moral permissions, no realm of going beyond one’s moral duty (supererogation), no realm of moral indifference. All acts are seemingly either required or forbidden. And there also seems to be no space for the consequentialist in which to show partiality to one’s own projects or to one’s family, friends, and countrymen, leading some critics of consequentialism to deem it a profoundly alienating and perhaps self-effacing moral theory (Williams 1973).</p><p><blockquote>kind of act, for it does not matter how harmful it is to some so long as it is more beneficial to others.</blockquote></p><p>A well-worn example of this over-permissiveness of consequentialism is that of a case standardly called, Transplant. A surgeon has five patients dying of organ failure and one healthy patient whose organs can save the five. In the right circumstances, surgeon will be permitted (and indeed required) by consequentialism to kill the healthy patient to obtain his organs, assuming there are no relevant consequences other than the saving of the five and the death of the one. Likewise, consequentialism will permit (in a case that we shall call, Fat Man) that a fat man be pushed in front of a runaway trolley if his being crushed by the trolley will halt its advance towards five workers trapped on the track. We shall return to these examples later on.</p><p>Consequentialists are of course not bereft of replies to these two criticisms. Some retreat from maximizing the Good to “satisficing”—that is, making the achievement of only a certain level of the Good mandatory (Slote 1984). This move opens up some space for personal projects and relationships, as well as a realm of the morally permissible. It is not clear, however, that satisficing is adequately motivated, except to avoid the problems of maximizing. Nor is it clear that the level of mandatory satisficing can be nonarbitrarily specified, or that satisficing will not require deontological constraints to protect satisficers from maximizers.</p><p>Another move is to introduce a positive/negative duty distinction within consequentialism. On this view, our (negative) duty is not to make the world worse by actions having bad consequences; lacking is a corresponding (positive) duty to make the world better by actions having good consequences (Bentham 1789 (1948); Quinton 2007). We thus have a consequentialist duty not to kill the one in Transplant or in Fat Man; and there is no counterbalancing duty to save five that overrides this. Yet as with the satisficing move, it is unclear how a consistent consequentialist can motivate this restriction on all-out optimization of the Good.</p><p><blockquote>—or character-trait inculcation—and assesses acts only indirectly by reference to such rules (or character-traits) (Alexander 1985). Its proponents contend that indirect consequentialism can avoid the criticisms of direct (act) consequentialism because it will not legitimate egregious violations of ordinary moral standards—e.g., the killing of the innocent to bring about some better state of affairs—nor will it be overly demanding and thus alienating each of us from our own projects.</blockquote></p><p>The relevance here of these defensive maneuvers by consequentialists is their common attempt to mimic the intuitively plausible aspects of a non-consequentialist, deontological approach to ethics. For as we shall now explore, the strengths of deontological approaches lie: (1) in their categorical prohibition of actions like the killing of innocents, even when good consequences are in the offing; and (2) in their permission to each of us to pursue our own projects free of any constant demand that we shape those projects so as to make everyone else well off.\n<blockquote>Having now briefly taken a look at deontologists’ foil, consequentialist theories of right action, we turn now to examine deontological theories. In contrast to consequentialist theories, deontological theories judge the morality of choices by criteria different from the states of affairs those choices bring about. The most familiar forms of deontology, and also the forms presenting the greatest contrast to consequentialism, hold that some choices cannot be justified by their effects—that no matter how morally good their consequences, some choices are morally forbidden. On such familiar deontological accounts of morality, agents cannot make certain wrongful choices even if by doing so the number of those exact kinds of wrongful choices will be minimized (because other agents will be prevented from engaging in similar wrongful choices). For such deontologists, what makes a choice right is its conformity with a moral norm. Such norms are to be simply obeyed by each moral agent; such norm-keepings are not to be maximized by each agent. In this sense, for such deontologists, the Right is said to have priority over the Good. If an act is not in accord with the Right, it may not be undertaken, no matter the Good that it might produce (including even a Good consisting of acts in accordance with the Right).</blockquote></p><p>Analogously, deontologists typically supplement non-consequentialist obligations with non-consequentialist permissions (Scheffler 1982). That is, certain actions can be right even though not maximizing of good consequences, for the rightness of such actions consists in their instantiating certain norms (here, of permission and not of obligation). Such actions are permitted, not just in the weak sense that there is no obligation not to do them, but also in the strong sense that one is permitted to do them even though they are productive of less good consequences than their alternatives (Moore 2008). Such strongly permitted actions include actions one is obligated to do, but (importantly) also included are actions one is not obligated to do. It is this last feature of such actions that warrants their separate mention for deontologists.</p><p><blockquote>The most traditional mode of taxonomizing deontological theories is to divide them between agent-centered versus victim-centered (or “patient-centered”) theories (Scheffler 1988; Kamm 2007). Consider first agent-centered deontological theories. According to agent-centered theories, we each have both permissions and obligations that give us agent-relative reasons for action. An agent-relative reason is an objective reason, just as are agent neutral reasons; neither is to be confused with either the relativistic reasons of a relativist meta-ethics, nor with the subjective reasons that form the nerve of psychological explanations of human action (Nagel 1986). An agent-relative reason is so-called because it is a reason relative to the agent whose reason it is; it need not (although it may) constitute a reason for anyone else. Thus, an agent-relative <em>obligation</em> is an obligation for a particular agent to take or refrain from taking some action; and because it is agent-relative, the obligation does not necessarily give anyone else a reason to support that action. Each parent, for example, is commonly thought to have such special obligations to his/her child, obligations not shared by anyone else. Likewise, an agent-relative <em>permission</em> is a permission for some agent to do some act even though others may not be permitted to aid that agent in the doing of his permitted action. Each parent, to revert to the same example, is commonly thought to be permitted (at the least) to save his own child even at the cost of not saving two other children to whom he has no special relation. Agent-centered theories and the agent-relative reasons on which they are based not only enjoin each of us to do or not to do certain things; they also instruct me to treat <em>my</em> friends, <em>my</em> family, <em>my</em> promisees in certain ways because they are <em>mine</em>, even if by neglecting them I could do more for others’ friends, families, and promisees.</blockquote></p><p>At the heart of agent-centered theories (with their agent-relative reasons) is the idea of agency. The moral plausibility of agent-centered theories is rooted here. The idea is that morality is intensely personal, in the sense that we are each enjoined to keep our own moral house in order. Our categorical obligations are not to focus on how our actions cause or enable other agents to do evil; the focus of our categorical obligations is to keep our own agency free of moral taint.</p><p>Each agent’s distinctive moral concern with his/her own agency puts some pressure on agent-centered theories to clarify how and when our agency is or is not involved in various situations. Agent-centered theories famously divide between those that emphasize the role of intention or other mental states in constituting the morally important kind of agency, and those that emphasize the actions of agents as playing such a role. There are also agent-centered theories that emphasize both intentions and actions equally in constituting the morally relevant agency of persons.</p><p><blockquote>).</blockquote></p><p><blockquote>we are risking the result to some extent, however minimal, for the result to be what we intend to bring about by our act.) Also, we can cause or risk such results without intending them. For example, we can intend to kill and even try to kill someone without killing him; and we can kill him without intending or trying to kill him, as when we kill accidentally. Intending thus does not collapse into risking, causing, or predicting; and on the version of agent-centered deontology here considered, it is intending (or perhaps trying) alone that marks the involvement of our agency in a way so as to bring agent-centered obligations and permissions into play.</blockquote></p><p>Deontologists of this stripe are committed to something like the doctrine of double effect, a long-established doctrine of Catholic theology (Woodward 2001). The Doctrine in its most familiar form asserts that we are categorically forbidden to intend evils such as killing the innocent or torturing others, even though doing such acts would minimize the doing of like acts by others (or even ourselves) in the future. By contrast, if we only risk, cause, or predict that our acts will have consequences making them acts of killing or of torture, then we might be able to justify the doing of such acts by the killing/torture-minimizing consequences of such actions. Whether such distinctions are plausible is standardly taken to measure the plausibility of an intention-focused version of the agent-centered version of deontology.</p><p>There are other versions of mental-state focused agent relativity that do not focus on intentions (Hurd 1994). Some of these versions focus on predictive belief as much as on intention (at least when the belief is of a high degree of certainty). Other versions focus on intended ends (“motives”) alone. Still others focus on the deliberative processes that precede the formation of intentions, so that even to contemplate the doing of an evil act impermissibly invokes our agency (Anscombe 1958; Geach 1969; Nagel 1979). But intention-focused versions are the most familiar versions of so-called “inner wickedness” versions of agent-centered deontology.</p><p>The second kind of agent-centered deontology is one focused on actions, not mental states. Such a view can concede that all human actions must originate with some kind of mental state, often styled a volition or a willing; such a view can even concede that volitions or willings are an intention of a certain kind (Moore 1993, Ch. 6). Indeed, such source of human actions in willing is what plausibly connects actions to the agency that is of moral concern on the agent-centered version of deontology. Yet to will the movement of a finger on a trigger is distinct from an intention to kill a person by that finger movement. The act view of agency is thus distinct from the intentions (or other mental state) view of agency.</p><p><blockquote>of such innocent. Much (on this view) is loaded into the requirement of causation.</blockquote></p><p><blockquote>to prevent such deaths. Holding a baby’s head under water until it drowns is a killing; seeing a baby lying face down in a puddle and doing nothing to save it when one could do so easily is a failure to prevent its death. Our categorical obligations are usually negative in content: we are not to kill the baby. We may have an obligation to save it, but this will not be an agent-relative obligation, on the view here considered, unless we have some special relationship to the baby.</blockquote></p><p><blockquote>a death to occur when: (1) one’s action merely removes a defense the victim otherwise would have had against death; and (2) such removal returns the victim to some morally appropriate baseline (Kamm 1994, 1996; MacMahan 2003). Thus, mercy-killings, or euthanasia, are outside of our deontological obligations (and thus eligible for justification by good consequences) so long as one’s act: (1) only removes a defense against death that the agent herself had earlier provided, such as disconnecting medical equipment that is keeping the patient alive when that disconnecting is done by the medical personnel that attached the patient to the equipment originally; and (2) the equipment could justifiably have been hooked up to another patient, where it could do some good, had the doctors known at the time of connection what they know at the time of disconnection.</blockquote></p><p><blockquote>(or aid) some other agent to cause such evil (Hart and Honore 1985). Thus, one is not categorically forbidden to drive the terrorists to where they can kill the policeman (if the alternative is death of one’s family), even though one would be categorically forbidden to kill the policeman oneself (even where the alternative is death of one’s family) (Moore 2008). Nor is one categorically forbidden to select which of a group of villagers shall be unjustly executed by another who is pursuing his own purposes (Williams 1973).</blockquote></p><p><blockquote>an evil such as a death when one merely redirects a presently existing threat to many so that it now threatens only one (or a few) (Thomson 1985). In the time-honored example of the run-away trolley (Trolley), one may turn a trolley so that it runs over one trapped workman so as to save five workmen trapped on the other track, even though it is not permissible for an agent to have initiated the movement of the trolley towards the one to save five (Foot 1967; Thomson 1985).</blockquote></p><p><blockquote>such evils by doing acts necessary for such evils to occur (G. Williams 1961; Brody 1996). Thus, when a victim is about to fall to his death anyway, dragging a rescuer with him too, the rescuer may cut the rope connecting them. Rescuer is accelerating, but not causing, the death that was about to occur anyway.</blockquote></p><p><blockquote>death, for that would be a killing, a “doing;” but one may fail to prevent death, allow (in the narrow sense) death to occur, enable another to cause death, redirect a life-threatening item from many to one, or accelerate a death about to happen anyway, if good enough consequences are in the offing. As with the Doctrine of Double Effect, how plausible one finds these applications of the doctrine of doing and allowing will determine how plausible one finds this cause-based view of human agency.</blockquote></p><p><blockquote>, that is, to kill in execution of an intention to kill.</blockquote></p><p><blockquote>when we are sure we cannot act so as to fulfill such intention (Hurd 1994)? If our agent-relative obligation is neither of these alone, but is rather, that we are not to kill in execution of an intention to kill, both such instances of seeming overbreadth in the reach of our obligations, are avoided.</blockquote></p><p>Whichever of these three agent-centered theories one finds most plausible, they each suffer from some common problems. A fundamental worry is the moral unattractiveness of the focus on self that is the nerve of any agent-centered deontology. The importance of each person’s agency to himself/herself has a narcissistic flavor to it that seems unattractive to many. It seemingly justifies each of us keeping our own moral house in order even at the expense of the world becoming much worse. The worry is not that agent-centered deontology is just another form of egoism, according to which the content of one’s duties exclusively concern oneself; even so, the character of agent-relative duties is such that they betoken an emphasis on self that is unattractive in the same way that such emphasis makes egoism unattractive. Secondly, many find the distinctions invited by the Doctrine of Double Effect and the (five versions of the) Doctrine of Doing and Allowing to be either morally unattractive or conceptually incoherent. Such critics find the differences between intending/foreseeing, causing/omitting, causing/allowing, causing/enabling, causing/redirecting, causing/accelerating to be morally insignificant. (On act/omission (Rachels 1975); on doing/allowing (Kagan 1989); on intending/foreseeing (Bennett 1981; Davis 1984).) They urge, for example, that failing to prevent a death one could easily prevent is as blameworthy as causing a death, so that a morality that radically distinguishes the two is implausible. Alternatively, such critics urge on conceptual grounds that no clear distinctions can be drawn in these matters, that foreseeing with certainty is indistinguishable from intending (Bennett 1981), that omitting is one kind of causing (Schaffer 2012), and so forth.</p><p>Thirdly, there is the worry about “avoision.” By casting our categorical obligations in such agent-centered terms, one invites a kind of manipulation that is legalistic and Jesuitical, what Leo Katz dubs “avoision” (Katz 1996). Some think, for example, that one can transform a prohibited intention into a permissible predictive belief (and thus escape intention-focused forms of agent-relative duty) by the simple expedient of finding some other end with which to motivate the action in question.</p><p><blockquote>what happened through our choices (Frey 1995). Yet as an account of deontology, this seems worrisomely broad. It disallows consequentialist justifications whenever: we foresee the death of an innocent; we omit to save, where our saving would have made a difference and we knew it; where we remove a life-saving device, knowing the patient will die. If deontological norms are so broad in content as to cover all these foreseeings, omittings, and allowings, then good consequences (such as a net saving of innocent lives) are ineligible to justify them. This makes for a wildly counterintuitive deontology: surely I can, for example, justify not throwing the rope to one (and thus omit to save him) in order to save two others equally in need. This breadth of obligation also makes for a conflict-ridden deontology: by refusing to cabin our categorical obligations by the distinctions of the Doctrine of Double Effect and the Doctrine of Doing and Allowing, situations of conflict between our stringent obligations proliferate in a troublesome way (Anscombe 1962).</blockquote></p><p><blockquote>A second group of deontological moral theories can be classified, as <em>patient</em>\\-centered, as distinguished from the <em>agent</em>\\-centered version of deontology just considered. These theories are rights-based rather than duty-based; and some versions purport to be quite agent-neutral in the reasons they give moral agents.</blockquote></p><p><blockquote>of another’s body, labor, and talent without the latter’s consent. One finds this notion expressed, albeit in different ways, in the work of the so-called Right Libertarians (e.g., Robert Nozick, Eric Mack), but also in the works of the Left-Libertarians as well (e.g., Michael Otsuka, Hillel Steiner, Peter Vallentyne) (Nozick 1974; Mack 2000; Steiner 1994; Vallentyne and Steiner 2000; Vallentyne, Steiner, and Otsuka 2005). On this view, the scope of strong moral duties—those that are the correlatives of others’ rights—is jurisdictionally limited and does not extend to resources for producing the Good that would not exist in the absence of those intruded upon—that is, their bodies, labors, and talents. In addition to the Libertarians, others whose views include this prohibition on using others include Quinn, Kamm, Alexander, Ferzan, Gauthier, and Walen (Quinn 1989; Kamm 1996; Alexander 2016; Alexander and Ferzan 2009, 2012; Gauthier 1986; Walen 2014, 2016).</blockquote></p><p>Just as do agent-centered theories, so too do patient-centered theories (such as that forbidding the using of another) seek to explain common intuitions about such classic hypothetical cases as Trolley and Transplant (or Fat Man) (Thomson 1985). In Trolley, a runaway trolley will kill five workers unless diverted to a siding where it will kill one worker. Most people regard it as permissible and perhaps mandatory to switch the trolley to the siding. By contrast, in Transplant, where a surgeon can kill one healthy patient and transplant his organs to five dying patients, thereby saving their lives, the universal reaction is condemnation. (The same is by-and-large true in Fat Man, where the runaway trolley cannot be switched off the main track but can be stopped before reaching the five workers by pushing a fat man into its path, resulting in his death.)</p><p>The injunction against using arguably accounts for these contrasting reactions. After all, in each example, one life is sacrificed to save five. Yet there appears to be a difference in the means through which the net four lives are saved. In Transplant (and Fat Man), the doomed person is used to benefit the others. They could not be saved in the absence of his body. In Trolley, on the other hand, the doomed victim is not used. The workers would be saved whether or not he is present on the second track.</p><p><blockquote>does not implicitly refer to the intention of the user) (Alexander 2016). And in assessing the culpability of risky conduct, any good consequences must be discounted, not only by the perceived risk that they will not occur, but also by the perceived risk that they will be brought about by a using; for any such consequences, however good they otherwise are, cannot be considered in determining the permissibility and, derivatively, the culpability of acts (Alexander 2016).</blockquote></p><p>Patient-centered deontologists handle differently other stock examples of the agent-centered deontologist. Take the acceleration cases as an example. When all will die in a lifeboat unless one is killed and eaten; when Siamese twins are conjoined such that both will die unless the organs of one are given to the other via an operation that kills the first; when all of a group of soldiers will die unless the body of one is used to hold down the enemy barbed wire, allowing the rest to save themselves; when a group of villagers will all be shot by a blood-thirsty tyrant unless they select one of their numbers to slake the tyrants lust for death—in all such cases, the causing/accelerating-distinguishing agent-centered deontologists would permit the killing but the usings-focused patient-centered deontologist would not. (For the latter, all killings are merely accelerations of death.)</p><p><blockquote>wrongs of killing, injuring, and so forth when done not to use others as means, but for some other purpose or for no purpose at all? The answer is that such patient-centered deontological constraints must be supplemented by consequentialist-derived moral norms to give an adequate account of morality. Killing, injuring, and so forth will usually be unjustifiable on a consequentialist calculus, especially if everyone’s interests are given equal regard. It is when killing and injuring are otherwise justifiable that the deontological constraint against using has its normative bite over and against what is already prohibited by consequentialism. (This narrowness of patient-centered deontology makes it counterintuitive to agent-centered deontologists, who regard prohibitions on killing of the innocent, etc., as paradigmatically deontological.)</blockquote></p><p><blockquote>in this way. For these reasons, any positive duties will not be rights-based ones on the view here considered; they will be consequentially-justified duties that can be trumped by the right not to be coerced to perform them.</blockquote></p><p><blockquote>using of another now cannot be traded off against other possible usings at other times by other people.</blockquote></p><p><blockquote>cannot be added to make some greater wrong because there is no person who suffers this greater wrong (cf. Taurek 1977).</blockquote></p><p>This solution to the paradox of deontology, may seem attractive, but it comes at a high cost. In Trolley, for example, where there is neither agency nor using in the relevant senses and thus no bar to switching, one cannot claim that it is better to switch and save the five. For if the deaths of the five cannot be summed, their deaths are not worse than the death of the one worker on the siding. Although there is no deontological bar to switching, neither is the saving of a net four lives a reason to switch. Worse yet, were the trolley heading for the one worker rather than the five, there would be no reason not to switch the trolley, so a net loss of four lives is no reason not to switch the trolley. If the numbers don’t count, they seemingly don’t count either way.</p><p>The problem of how to account for the significance of numbers without giving up deontology and adopting consequentialism, and without resurrecting the paradox of deontology, is one that a number of deontologists are now working to solve (e.g., Kamm 1996; Scanlon 2003; Otsuka 2006, Hsieh et al. 2006). Until it is solved, it will remain a huge thorn in the deontologist’s side.</p><p><blockquote>Somewhat orthogonal to the distinction between agent-centered versus patient-centered deontological theories are contractualist deontological theories. Morally wrong acts are, on such accounts, those acts that would be forbidden by principles that people in a suitably described social contract would accept (e.g., Rawls 1971; Gauthier 1986), or that would be forbidden only by principles that such people could not “reasonably reject” (e.g., Scanlon 2003).</blockquote></p><p>In deontology, as elsewhere in ethics, is not entirely clear whether a contractualist account is really normative as opposed to metaethical. If such account is a first order normative account, it is probably best construed as a patient-centered deontology; for the central obligation would be to do onto others only that to which they have consented. But so construed, modern contractualist accounts would share the problems that have long bedeviled historical social contract theories: how plausible is it that the “moral magic” of consent is the first principle of morality? And how much of what is commonly regarded as permissible to do to people can (in any realistic sense of the word) be said to be actually consented to by them, expressly or even implicitly?</p><p>In fact modern contractualisms look meta-ethical, and not normative. Thomas Scanlon’s contractualism, for example, which posits at its core those norms of action that we can justify to each other, is best construed as an ontological and epistemological account of moral notions. The same may be said of David Gauthier’s contractualism. Yet so construed, metaethical contractualism as a method for deriving moral norms does not necessarily lead to deontology as a first order ethics. John Harsanyi, for example, argues that parties to the social contract would choose utilitarianism over the principles John Rawls argues would be chosen (Harsanyi 1973). Nor is it clear that meta-ethical contractualism, when it does generate a deontological ethic, favors either an agent centered or a patient centered version of such an ethic.</p><p><blockquote>If any philosopher is regarded as central to deontological moral theories, it is surely Immanuel Kant. Indeed, each of the branches of deontological ethics—the agent-centered, the patient-centered, and the contractualist—can lay claim to being Kantian.</blockquote></p><p><blockquote>.)</blockquote>\n<blockquote>Having canvassed the two main types of deontological theories (together with a contractualist variation of each), it is time to assess deontological morality more generally. On the one hand, deontological morality, in contrast to consequentialism, leaves space for agents to give special concern to their families, friends, and projects. At least that is so if the deontological morality contains no strong duty of general beneficence, or, if it does, it places a cap on that duty’s demands. Deontological morality, therefore, avoids the overly demanding and alienating aspects of consequentialism and accords more with conventional notions of our moral duties.</blockquote></p><p>Likewise, deontological moralities, unlike most views of consequentialism, leave space for the supererogatory. A deontologist can do more that is morally praiseworthy than morality demands. A consequentialist cannot, assuming none of the consequentialists’ defensive maneuvers earlier referenced work. For such a pure or simple consequentialist, if one’s act is not morally demanded, it is morally wrong and forbidden. Whereas for the deontologist, there are acts that are neither morally wrong nor demanded, some—but only some—of which are morally praiseworthy.</p><p>As we have seen, deontological theories all possess the strong advantage of being able to account for strong, widely shared moral intuitions about our duties better than can consequentialism. The contrasting reactions to Trolley, Fat Man, Transplant, and other examples earlier given, are illustrative of this.</p><p><blockquote>particular people, not duties to bring about states of affairs that no particular person has an individual right to have realized.</blockquote>\n<blockquote>On the other hand, deontological theories have their own weak spots. The most glaring one is the seeming irrationality of our having duties or permissions to make the world morally worse. Deontologists need their own, non-consequentialist model of rationality, one that is a viable alternative to the intuitively plausible, “act-to-produce-the-best-consequences” model of rationality that motivates consequentialist theories. Until this is done, deontology will always be paradoxical. There are several distinct hurdles that the deontologist must overcome.</blockquote></p><p>One hurdle is to confront the apparent fact that careful reflection about the degrees of wrongdoing that are possible under any single moral norm does not make it easy to see deontological morality as consisting of general, canonically-formulated texts (conformity to which could then be said to constitute the distrinct form of practical rationality unique to deontological ethics); rather, such apparently simple texts as, “thou shalt not murder,” look more like mere epistemic aids summarizing a much more nuanced and detailed (and thus less text-like) moral reality (Hurd and Moore forthcoming).</p><p><blockquote>) and deontologists like everybody else need to justify such deference. Hopefully they can do so other than by reference to some person-like but omniscient Deity as the supposed source of such texts, because many deontologists cannot accept such theism (Moore 1995). Moreover, even for those with theistic commitments, they may prefer to join Kant’s insistence that ethics proceed from reason alone, even in a theistic world.</blockquote></p><p>The third hurdle exists even if the first two are crossed adequately. This hurdle is to deal with the seeming demand of deontological ethics that on occasion one’s categorical obligations require one to preserve the purity of one’s own moral agency at the cost of having one’s actions make the world be in a morally worse state of affairs—at least, “worse” in the agent-neutral sense of the word used by consequentialists. Patient-centered versions of deontology cannot easily escape this problem, as we have shown. It is not even clear that they have the conceptual resources to make agency important enough to escape this moral paradox. Yet even agent-centered versions face this paradox; having the conceptual resources (of agency and agent-relative reasons) is not the same as making it plausible just how a secular, objective morality can allow each person’s agency to be so uniquely crucial to that person.</p><p><blockquote>. Kant’s bold proclamation that “a conflict of duties is inconceivable” (Kant 1780, p. 25) is the conclusion wanted, but reasons for believing it are difficult to produce. The intending/foreseeing, doing/allowing, causing/aiding, and related distinctions certainly reduce potential conflicts for the agent-centered versions of deontology; whether they can totally eliminate such conflicts is a yet unresolved question.</blockquote></p><p><blockquote>duties; (2) whether only such consequences over some threshold can do so; or (3) whether only threatened breach of other deontological duties can do so.</blockquote></p><p>Thirdly, there is the manipulability worry mentioned before with respect to agent-centered versions of deontology. To the extent potential conflict is eliminated by resort to the Doctrine of Double Effect, the Doctrine of Doing and Allowing, and so forth (and it is not clear to what extent patient-centered versions rely on these doctrines and distinctions to mitigate potential conflict), then a potential for “avoision” is opened up. Such avoision is the manipulation of means (using omissions, foresight, risk, allowings, aidings, acceleratings, redirectings, etc.) to achieve permissibly what otherwise deontological morality would forbid (see Katz 1996). Avoision is an undesirable feature of any ethical system that allows such strategic manipulation of its doctrines.</p><p>Fourth, there is what might be called the paradox of relative stringency. There is an aura of paradox in asserting that all deontological duties are categorical—to be done no matter the consequences—and yet asserting that some of such duties are more stringent than others. A common thought is that “there cannot be degrees of wrongness with intrinsically wrong acts…” (Frey 1995, p. 78, n.3; also Hurka 2019). Yet relative stringency—“degrees of wrongness”—seems forced upon the deontologist by one if not two considerations. First, duties of differential stringency can be weighed against one another if there is conflict between them, so that a conflict-resolving, overall duty becomes possible if duties can be more or less stringent. Second, when we punish for the wrongs consisting in our violation of deontological duties, we (rightly) do not punish all violations equally. The greater the wrong, the greater the punishment deserved; and relative stringency of duty violated (or importance of rights) seems the best way of making sense of greater versus lesser wrongs (Hurd and Moore forthcoming).</p><p><blockquote>of deontology.</blockquote></p><p>Deontologists have six possible ways of dealing with such “moral catastrophes” (although only two of these are very plausible). First, they can just bite the bullet and declare that sometimes doing what is morally right will have tragic results but that allowing such tragic results to occur is still the right thing to do. Complying with moral norms will surely be difficult on those occasions, but the moral norms apply nonetheless with full force, overriding all other considerations. We might call this the Kantian response, after Kant’s famous hyperbole: “Better the whole people should perish,” than that injustice be done (Kant 1780, p. 100). One might also call this the absolutist conception of deontology, because such a view maintains that conformity to norms has absolute force and not merely great weight.</p><p><blockquote>in discussing the paradox of deontological constraints. John Taurek famously argued that it is a mistake to assume harms to two persons are twice as bad as a comparable harm to one person. For each of the two suffers only his own harm and not the harm of the other (Taurek 1977). Taurek’s argument can be employed to deny the existence of moral catastrophes and thus the worry about them that deontologists would otherwise have. Robert Nozick also stresses the separateness of persons and therefore urges that there is no entity that suffers double the harm when each of two persons is harmed (Nozick 1974). (Of course, Nozick, perhaps inconsistently, also acknowledges the existence of moral catastrophes.) Most deontologists reject Taurek’s radical conclusion that we need not be morally more obligated to avert harm to the many than to avert harm to the few; but they do accept the notion that harms should not be aggregated. Deontologists’ approaches to the nonaggregation problem when the choice is between saving the many and saving the few are: (1) save the many so as to acknowledge the importance of each of the extra persons; (2) conduct a weighted coin flip; (3) flip a coin; or (4) save anyone you want (a denial of moral catastrophes) (Broome 1998; Doggett 2013; Doucet 2013; Dougherty 2013; Halstead 2016: Henning 2015; Hirose 2007, 2015; Hsieh et al. 2006; Huseby 2011; Kamm 1993; Rasmussen 2012; Saunders 2009; Scanlon 2003; Suikkanen 2004; Timmerman 2004; Wasserman and Strudler 2003).</blockquote></p><p><blockquote>to save the lives of two others, but he may do so to save a thousand lives if the “threshold” is higher than two lives but lower than a thousand.</blockquote></p><p>There are two varieties of threshold deontology that are worth distinguishing. On the simple version, there is some fixed threshold of awfulness beyond which morality’s categorical norms no longer have their overriding force. Such a threshold is fixed in the sense that it does not vary with the stringency of the categorical duty being violated. The alternative is what might be called “sliding scale threshold deontology.” On this version, the threshold varies in proportion to the degree of wrong being done—the wrongness of stepping on a snail has a lower threshold (over which the wrong can be justified) than does the wrong of stepping on a baby.</p><p><blockquote>duty” version of deontology developed to deal with the problem of conflicting duties, yet threshold deontology is usually interpreted with such a high threshold that it more closely mimics the outcomes reached by a “pure,” absolutist kind of deontology. Threshold deontology faces several theoretical difficulties. Foremost among them is giving a theoretically tenable account of the location of such a threshold, either absolutely or on a sliding scale (Alexander 2000; Ellis 1992; Moore 2019; Arneson 2019; Cole 2019; Alexander 2019). Why is the threshold for torture of the innocent at one thousand lives, say, as opposed to nine hundred or two thousand? Another problem is that whatever the threshold, as the dire consequences approach it, counter-intuitive results appear to follow. For example, it may be permissible, if we are one-life-at-risk short of the threshold, to pull one more person into danger who will then be saved, along with the others at risk, by killing an innocent person (Alexander 2000). Thirdly, there is some uncertainty about how one is to reason after the threshold has been reached: are we to calculate at the margin on straight consequentialist grounds, use an agent-weighted mode of summing, or do something else? A fourth problem is that threshold deontology threatens to collapse into a kind of consequentialism. Indeed, it can be perhaps shown that the sliding scale version of threshold deontology is extensionally equivalent to an agency-weighted form of consequentialism (Sen 1982).</blockquote></p><p>The remaining four strategies for dealing with the problem of dire consequence cases all have the flavor of evasion by the deontologist. Consider first the famous view of Elizabeth Anscombe: such cases (real or imagined) can never present themselves to the consciousness of a truly moral agent because such agent will realize it is immoral to even think about violating moral norms in order to avert disaster (Anscombe 1958; Geach 1969; Nagel 1979). Such rhetorical excesses should be seen for what they are, a peculiar way of stating Kantian absolutism motivated by an impatience with the question.</p><p>Another response by deontologists, this one most famously associated with Bernard Williams, shares some of the “don’t think about it” features of the Anscombean response. According to Williams (1973), situations of moral horror are simply “beyond morality,” and even beyond reason. (This view is reminiscent of the ancient view of natural necessity, revived by Sir Francis Bacon, that such cases are beyond human law and can only be judged by the natural law of instinct.) Williams tells us that in such cases we just act. Interestingly, Williams contemplates that such “existentialist” decision-making will result in our doing what we have to do in such cases—for example, we torture the innocent to prevent nuclear holocaust.</p><p>Surely this is an unhappy view of the power and reach of human law, morality, or reason. Indeed, Williams (like Bacon and Cicero before him) thinks there is an answer to what should be done, albeit an answer very different than Anscombe’s. But both views share the weakness of thinking that morality and even reason runs out on us when the going gets tough.</p><p><blockquote>is morally praiseworthy for having done it.</blockquote></p><p>Deontology does have to grapple with how to mesh deontic judgments of wrongness with “hypological” (Zimmerman 2002) judgments of blameworthiness (Alexander 2004). Yet it would be an oddly cohering morality that condemned an act as wrong yet praised the doer of it. Deontic and hypological judgments ought to have more to do with each other than that. Moreover, it is unclear what action-guiding potential such an oddly cohered morality would have: should an agent facing such a choice avoid doing wrong, or should he go for the praise?</p><p>The last possible strategy for the deontologist in order to deal with dire consequences, other than by denying their existence, as per Taurek, is to distinguish moral reasons from all-things-considered reasons and to argue that whereas moral reasons dictate obedience to deontological norms even at the cost of catastrophic consequences, all-things-considered reasons dictate otherwise. (This is one reading of Bernard William’s famous discussion of moral luck, where non-moral reasons seemingly can trump moral reasons (Williams 1975, 1981); this is also a strategy some consequentialists (e.g., Portmore 2003) seize as well in order to handle the demandingness and alienation problems endemic to consequentialism.) But like the preceding strategy, this one seems desperate. Why should one even care that moral reasons align with deontology if the important reasons, the all-things-considered reasons that actually govern decisions, align with consequentialism?\n<blockquote>The perceived weaknesses of deontological theories have led some to consider how to eliminate or at least reduce those weaknesses while preserving deontology’s advantages. One way to do this is to embrace both consequentialism and deontology, combining them into some kind of a mixed theory. Given the differing notions of rationality underlying each kind of theory, this is easier said than done. After all, one cannot simply weigh agent-relative reasons against agent-neutral reasons, without stripping the former sorts of reasons of their distinctive character.</blockquote></p><p>A time-honored way of reconciling opposing theories is to allocate them to different jurisdictions. Tom Nagel’s reconciliation of the two theories is a version of this, inasmuch as he allocates the agent-neutral reasons of consequentialism to our “objective” viewpoint, whereas the agent-relative reasons of deontology are seen as part of our inherent subjectivity (Nagel 1986). Yet Nagel’s allocations are non-exclusive; the same situation can be seen from either subjective or objective viewpoints, meaning that it is mysterious how we are to combine them into some overall view.</p><p>A less mysterious way of combining deontology with consequentialism is to assign to each a jurisdiction that is exclusive of the other. One possibility here is to regard the agent-neutral reasons of consequentialism as a kind of default rationality/morality in the sense that when an agent-relative permission or obligation applies, it governs, but in the considerable logical space where neither applies, consequentialism holds sway (Moore 2008). Remembering that for the threshold deontologist, consequentialist reasons may still determine right action even in areas governed by agent-relative obligations or permissions, once the level of bad consequences crosses the relevant threshold (Moore 2012).</p><p><blockquote>In contrast to mixed theories, deontologists who seek to keep their deontology pure hope to expand agent-relative reasons to cover all of morality and yet to mimic the advantages of consequentialism. Doing this holds out the promise of denying sense to the otherwise damning question, how could it be moral to make (or allow) the world to be worse (for they deny that there is any states-of-affairs “worseness” in terms of which to frame such a question) (Foot 1985). To make this plausible, one needs to expand the coverage of agent-relative reasons to cover what is now plausibly a matter of consequentialist reasons, such as positive duties to strangers. Moreover, deontologists taking this route need a content to the permissive and obligating norms of deontology that allows them to mimic the outcomes making consequentialism attractive. This requires a picture of morality’s norms that is extremely detailed in content, so that what looks like a consequentialist balance can be generated by a complex series of norms with extremely detailed priority rules and exception clauses (Richardson 1990). Few consequentialists will believe that this is a viable enterprise.</blockquote></p><p><blockquote>The mirror image of the pure deontologist just described is the indirect or two-level consequentialist. For this view too seeks to appropriate the strengths of both deontology and consequentialism, not by embracing both, but by showing that an appropriately defined version of one can do for both. The indirect consequentialist, of course, seeks to do this from the side of consequentialism alone.</blockquote></p><p><blockquote>. Nor can the indirect consequentialist adequately explain why those who violate the indirect consequentialist’s rules have “wronged” those who might be harmed as a result, that is, why the latter have a personal complaint against the former. (This is true irrespective of whether the rule-violation produces good consequences; but it is especially so when good consequences result from the rule-violation.) The bottom line is that if deontology has intuitive advantages over consequentialism, it is far from obvious whether those advantages can be captured by moving to indirect consequentialism, even if there is a version of indirect consequentialism that could avoid the dire consequences problem that bedevils deontological theories.</blockquote>\n<blockquote>Recently, deontologists have begun to ask how an actor should evaluate courses of action in which it is uncertain whether a deontological constraint will be violated. For example, should one detonate dynamite in a mining operation if there is a chance that the explosion will cause the Fat Man to tumble into the path of the trolley that would otherwise kill five? (Assume that were the chance the same that the explosion would instead divert the trolley in Trolley, killing one but saving five, the detonation would be permissible.) Or should one take a drive to observe the scenery if there is a slightly increased chance that, because of the possibility of traffic, doing so will cause one to miss a lunch one had promised to attend? Whether deontological constraints focus on agents’ intentions or beliefs, or whether they focus on agents’ counting positively in their deliberations others’ use as means, how should the uncertainty of outcomes be taken into account by deontologists? This question has been addressed by Aboodi, Borer, and Enoch (2008); Alexander (2016; 2018); Lazar (2015; 2017a, 2017b, 2018); Smith (2014); Tarsney (2018); and Tomlin (2019).</blockquote>\n<blockquote>Deontological theories are normative theories. They do not presuppose any particular position on moral ontology or on moral epistemology. Presumably, a deontologist can be a moral realist of either the natural (moral properties are identical to natural properties) or nonnatural (moral properties are not themselves natural properties even if they are nonreductively related to natural properties) variety. Or a deontologist can be an expressivist, a constructivist, a transcendentalist, a conventionalist, or a Divine command theorist regarding the nature of morality. Likewise, a deontologist can claim that we know the content of deontological morality by direct intuition, by Kantian reflection on our normative situation, or by reaching reflective equilibrium between our particular moral judgments and the theories we construct to explain them (theories of intuitions).</blockquote></p><p>Nonetheless, although deontological theories can be agnostic regarding metaethics, some metaethical accounts seem less hospitable than others to deontology. For example, the stock furniture of deontological normative ethics—rights, duties, permissions—fits uneasily in the realist-naturalist’s corner of the metaethical universe. (Which is why many naturalists, if they are moral realists in their meta-ethics, are consequentialists in their ethics.) Nonnatural realism, conventionalism, transcendentalism, and Divine command seem more hospitable metaethical homes for deontology. (For example, the paradox of deontology above discussed may seem more tractable if morality is a matter of personal directives of a Supreme Commander to each of his human subordinates.) If these rough connections hold, then weaknesses with those metaethical accounts most hospitable to deontology will weaken deontology as a normative theory of action. Some deontologists have thus argued that these connections need not hold and that a naturalist-realist meta-ethics can ground a deontological ethics (Moore 2004).</p>"
  },
  {
    "id": "20240821234307261445841",
    "title": "Consequentialism",
    "source": "https://plato.stanford.edu/entries/consequentialism/",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Ethics",
      "Philosophy"
    ],
    "read": {
      "text": "67 min read",
      "minutes": 66.275,
      "time": 3976500,
      "words": 13255
    },
    "note": "",
    "markdown": "<p>Consequentialism, as its name suggests, is simply the view that normative properties depend only on consequences. This historically important and still popular theory embodies the basic intuition that what is best or right is whatever makes the world best in the future, because we cannot change the past, so worrying about the past is no more useful than crying over spilled milk. This general approach can be applied at different levels to different normative properties of different kinds of things, but the most prominent example is probably consequentialism about the moral rightness of acts, which holds that whether an act is morally right depends only on the consequences of that act or of something related to that act, such as the motive behind the act or a general rule requiring acts of the same kind.\n<blockquote>The paradigm case of consequentialism is utilitarianism, whose classic proponents were Jeremy Bentham (1789), John Stuart Mill (1861), and Henry Sidgwick (1907). (For predecessors, see Schneewind 1997, 2002.) Classic utilitarians held hedonistic act consequentialism. <em>Act consequentialism</em> is the claim that an act is morally right if and only if that act maximizes the good, that is, if and only if the total amount of good for all minus the total amount of bad for all is greater than this net amount for any incompatible act available to the agent on that occasion. (Cf. Moore 1912, chs. 1–2.) <em>Hedonism</em> then claims that pleasure is the only intrinsic good and that pain is the only intrinsic bad.</blockquote></p><p>These claims are often summarized in the slogan that an act is right if and only if it causes “the greatest happiness for the greatest number.” This slogan is misleading, however. An act can increase happiness for most (the greatest number of) people but still fail to maximize the net good in the world if the smaller number of people whose happiness is not increased lose much more than the greater number gains. The principle of utility would not allow that kind of sacrifice of the smaller number to the greater number unless the net good overall is increased more than any alternative.</p><p>Classic utilitarianism is consequentialist as opposed to deontological because of what it denies. It denies that moral rightness depends directly on anything other than consequences, such as whether the agent promised in the past to do the act now. Of course, the fact that the agent promised to do the act might indirectly affect the act’s consequences if breaking the promise will make other people unhappy. Nonetheless, according to classic utilitarianism, what makes it morally wrong to break the promise is its future effects on those other people rather than the fact that the agent promised in the past (Sinnott-Armstrong 2009).</p><p>Since classic utilitarianism reduces all morally relevant factors (Kagan 1998, 17–22) to consequences, it might appear simple. However, classic utilitarianism is actually a complex combination of many distinct claims, including the following claims about the moral rightness of acts:</p><p><blockquote>(as opposed to the circumstances or the intrinsic nature of the act or anything that happens before the act).</blockquote>\n<blockquote>> Actual Consequentialism = whether an act is morally right depends only on the <em>actual</em> consequences (as opposed to foreseen, foreseeable, intended, or likely consequences).</blockquote>\n<blockquote>> Direct Consequentialism = whether an act is morally right depends only on the consequences of <em>that act itself</em> (as opposed to the consequences of the agent’s motive, of a rule or practice that covers other acts of the same kind, and so on).</blockquote>\n<blockquote>> Evaluative Consequentialism = moral rightness depends only on the <em>value</em> of the consequences (as opposed to non-evaluative features of the consequences).</blockquote>\n<blockquote>> Hedonism = the value of the consequences depends only on the <em>pleasures</em> and <em>pains</em> in the consequences (as opposed to other supposed goods, such as freedom, knowledge, life, and so on).</blockquote>\n<blockquote>> Maximizing Consequentialism = moral rightness depends only on which consequences are <em>best</em> (as opposed to merely satisfactory or an improvement over the status quo).</blockquote>\n<blockquote>> Aggregative Consequentialism = which consequences are best is some function of the values of <em>parts</em> of those consequences (as opposed to rankings of whole worlds or sets of consequences).</blockquote>\n<blockquote>> Total Consequentialism = moral rightness depends only on the <em>total</em> net good in the consequences (as opposed to the average net good per person).</blockquote>\n<blockquote>> Universal Consequentialism = moral rightness depends on the consequences for <em>all</em> people or sentient beings (as opposed to only the individual agent, members of the individual’s society, present people, or any other limited group).</blockquote>\n<blockquote>> Equal Consideration = in determining moral rightness, benefits to one person matter <em>just as much</em> as similar benefits to any other person (as opposed to putting more weight on the worse or worst off).</blockquote>\n<blockquote>> Agent-neutrality = whether some consequences are better than others does not depend on whether the consequences are evaluated from the perspective of the agent (as opposed to an observer).</blockquote></p><p>These claims could be clarified, supplemented, and subdivided further. What matters here is just that most pairs of these claims are logically independent, so a moral theorist could consistently accept some of them without accepting others. Yet classic utilitarians accepted them all. That fact makes classic utilitarianism a more complex theory than it might appear at first sight.</p><p>It also makes classic utilitarianism subject to attack from many angles. Persistent opponents posed plenty of problems for classic utilitarianism. Each objection led some utilitarians to give up some of the original claims of classic utilitarianism. By dropping one or more of those claims, descendants of utilitarianism can construct a wide variety of moral theories. Advocates of these theories often call them consequentialism rather than utilitarianism so that their theories will not be subject to refutation by association with the classic utilitarian theory.\n<blockquote>This array of alternatives raises the question of which moral theories count as consequentialist (as opposed to deontological) and why. In actual usage, the term “consequentialism” seems to be used as a family resemblance term to refer to any descendant of classic utilitarianism that remains close enough to its ancestor in the important respects. Of course, different philosophers see different respects as the important ones (Portmore 2020). Hence, there is no agreement on which theories count as consequentialist under this definition.</blockquote></p><p>To resolve this vagueness, we need to determine which of the various claims of classic utilitarianism are essential to consequentialism. One claim seems clearly necessary. Any consequentialist theory must accept the claim that I labeled “consequentialism”, namely, that certain normative properties depend only on consequences. If that claim is dropped, the theory ceases to be consequentialist.</p><p>It is less clear whether that claim by itself is sufficient to make a theory consequentialist. Several philosophers assert that a moral theory should not be classified as consequentialist unless it is agent-neutral (McNaughton and Rawling 1991, Howard-Snyder 1994, Pettit 1997). This narrower definition is motivated by the fact that many self-styled critics of consequentialism argue against agent-neutrality.</p><p>Other philosophers prefer a broader definition that does not require a moral theory to be agent-neutral in order to be consequentialist (Bennett 1989; Broome 1991, 5–6; and Skorupski 1995). Criticisms of agent-neutrality can then be understood as directed against one part of classic utilitarianism that need not be adopted by every moral theory that is consequentialist. Moreover, according to those who prefer a broader definition of consequentialism, the narrower definition conflates independent claims and obscures a crucial commonality between agent-neutral consequentialism and other moral theories that focus exclusively on consequences, such as moral egoism and recent self-styled consequentialists who allow agent-relativity into their theories of value (Sen 1982, Broome 1991, Portmore 2001, 2003, 2011).</p><p>A definition solely in terms of consequences might seem too broad, because it includes absurd theories such as the theory that an act is morally right if it increases the number of goats in Texas. Of course, such theories are implausible. Still, it is not implausible to call them consequentialist, since they do look only at consequences. The implausibility of one version of consequentialism does not make consequentialism implausible in general, since other versions of consequentialism still might be plausible.</p><p>Besides, anyone who wants to pick out a smaller set of moral theories that excludes this absurd theory may talk about evaluative consequentialism, which is the claim that moral rightness depends only on the value of the consequences. Then those who want to talk about the even smaller group of moral theories that accepts both evaluative consequentialism and agent-neutrality may describe them as agent-neutral evaluative consequentialism. If anyone still insists on calling these smaller groups of theories by the simple name, ‘consequentialism’, this narrower word usage will not affect any substantive issue.</p><p>Still, if the definition of consequentialism becomes too broad, it might seem to lose force. Some philosophers have argued that any moral theory, or at least any plausible moral theory, could be represented as a version of consequentialism (Sosa 1993, Portmore 2009, Dreier 1993 and 2011; but see Brown 2011). If so, then it means little to label a theory as consequentialist. The real content comes only by contrasting theories that are not consequentialist.</p><p>In the end, what matters is only that we get clear about which theories a particular commentator counts as consequentialist or not and which claims are supposed to make them consequentialist or not. Only then can we know which claims are at stake when this commentator supports or criticizes what they call “consequentialism”. Then we can ask whether each objection really refutes that particular claim.\n<blockquote>Some moral theorists seek a single simple basic principle because they assume that simplicity is needed in order to decide what is right when less basic principles or reasons conflict. This assumption seems to make hedonism attractive. Unfortunately, however, hedonism is not as simple as they assume, because hedonists count both pleasures and pains. Pleasure is distinct from the absence of pain, and pain is distinct from the absence of pleasure, since sometimes people feel neither pleasure nor pain, and sometimes they feel both at once. Nonetheless, hedonism was adopted partly because it seemed simpler than competing views.</blockquote></p><p><blockquote>hedonists sometimes respond that great poetry almost always creates more pleasure than trivial games (or sex and drugs and rock-and-roll), because the pleasures of poetry are more certain (or probable), durable (or lasting), fecund (likely to lead to other pleasures), pure (unlikely to lead to pains), and so on.</blockquote></p><p><blockquote>hedonism has been subjected to much criticism, including charges that it is incoherent and does not count as hedonism (Moore 1903, 80–81; cf. Feldman 1997, 106–24).</blockquote></p><p><blockquote>pleasures are intrinsically valuable, because other things are valuable independently of whether they lead to pleasure or avoid pain. For example, my love for my wife does not seem to become less valuable when I get less pleasure from her because she contracts some horrible disease. Similarly, freedom seems valuable even when it creates anxiety, and even when it is freedom to do something (such as leave one’s country) that one does not want to do. Again, many people value knowledge of distant galaxies regardless of whether this knowledge will create pleasure or avoid pain.</blockquote></p><p><blockquote>friendship, knowledge, freedom, and achievements, all of which are lacking for deluded people on the experience machine.</blockquote></p><p><blockquote>pleasure occurs only when the state of affairs in which the person takes pleasure exists (that is, when the daughter actually gets good grades). But the relevant states of affairs would not really exist if one were hooked up to the experience machine. Hence, hedonists who value propositional pleasure rather than or in addition to sensational pleasure can deny that more pleasure is achieved by hooking oneself up to such an experience machine (Feldman 1997, 79–105; see also Tännsjö 1998 and Feldman 2004 for more on hedonism).</blockquote></p><p><blockquote>.</blockquote></p><p>One problem for preference utilitarianism concerns how to make interpersonal comparisons (though this problem also arises for several other theories of value). If we want to know what one person prefers, we can ask what that person would choose in conflicts. We cannot, however, use the same method to determine whether one person’s preference is stronger or weaker than another person’s preference, since these different people might choose differently in the decisive conflicts. We need to settle which preference (or pleasure) is stronger because we may know that Jones prefers A’s being done to A’s not being done (and Jones would receive more pleasure from A’s being done than from A’s not being done), whereas Smith prefers A’s not being done (and Smith would receive more pleasure from A’s not being done than from A’s being done). To determine whether it is right to do A or not to do A, we must be able to compare the strengths of Jones’s and Smith’s preferences (or the amounts of pleasure each would receive in her preferred outcome) in order to determine whether doing A or not doing A would be better overall. Utilitarians and consequentialists have proposed many ways to solve this problem of interpersonal comparison, and each attempt has received criticisms. Debates about this problem still rage. (For a recent discussion with references, see Coakley 2015.)</p><p>Preference utilitarianism is also often criticized on the grounds that some preferences are misinformed, crazy, horrendous, or trivial. I might prefer to drink the liquid in a glass because I think that it is beer, though it really is strong acid. Or I might prefer to die merely because I am clinically depressed. Or I might prefer to torture children. Or I might prefer to spend my life learning to write as small as possible. In all such cases, opponents of preference utilitarianism can deny that what I prefer is really good. Preference utilitarians can respond by limiting the preferences that make something good, such as by referring to informed desires that do not disappear after therapy (Brandt 1979). However, it is not clear that such qualifications can solve all of the problems for a preference theory of value without making the theory circular by depending on substantive assumptions about which preferences are for good things.</p><p><blockquote>, for example, takes into account the values of beauty and truth (or knowledge) in addition to pleasure (Moore 1903, 83–85, 194; 1912). Other consequentialists add the intrinsic values of friendship or love, freedom or ability, justice or fairness, desert, life, virtue, and so on.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>.</blockquote></p><p>Similarly, some consequentialists hold that an act is right if and only if it maximizes some function of both happiness and capabilities (Sen 1985, Nussbaum 2000). Disabilities are then seen as bad regardless of whether they are accompanied by pain or loss of pleasure.</p><p><blockquote>. This approach could be built into total consequentialism with rights weighed against happiness and other values or, alternatively, the disvalue of rights violations could be lexically ranked prior to any other kind of loss or harm (cf. Rawls 1971, 42). Such a lexical ranking within a consequentialist moral theory would yield the result that nobody is ever justified in violating rights for the sake of happiness or any value other than rights, although it would still allow some rights violations in order to avoid or prevent other rights violations.</blockquote></p><p>When consequentialists incorporate a variety of values, they need to rank or weigh each value against the others. This is often difficult. Some consequentialists even hold that certain values are incommensurable or incomparable in that no comparison of their values is possible (Griffin 1986 and Chang 1997). This position allows consequentialists to recognize the possibility of irresolvable moral dilemmas (Sinnott-Armstrong 1988, 81; Railton 2003, 249–91).</p><p>Pluralism about values also enables consequentialists to handle many of the problems that plague hedonistic utilitarianism. For example, opponents often charge that classical utilitarians cannot explain our obligations to keep promises and not to lie when no pain is caused or pleasure is lost. Whether or not hedonists can meet this challenge, pluralists can hold that knowledge is intrinsically good and/or that false belief is intrinsically bad. Then, if deception causes false beliefs, deception is instrumentally bad, and agents ought not to lie without a good reason, even when lying causes no pain or loss of pleasure. Since lying is an attempt to deceive, to lie is to attempt to do what is morally wrong (in the absence of defeating factors). Similarly, if a promise to do an act is an attempt to make an audience believe that the promiser will do the act, then to break a promise is for a promiser to make false a belief that the promiser created or tried to create. Although there is more tale to tell, the disvalue of false belief can be part of a consequentialist story about why it is morally wrong to break promises.</p><p><blockquote>. However, this usage is not uniform, since even non-welfarist views are sometimes called utilitarian. Whatever you call them, the important point is that consequentialism and the other elements of classical utilitarianism are compatible with many different theories about which things are good or valuable.</blockquote></p><p><blockquote>.</blockquote></p><p><blockquote>. Compare one outcome where most people are destitute but a few lucky people have extremely large amounts of goods with another outcome that contains slightly less total goods but where every person has nearly the same amount of goods. Egalitarian critics of classical utilitarianism argue that the latter outcome is better, so more than the total amount of good matters. Traditional hedonistic utilitarians who prefer the latter outcome often try to justify egalitarian distributions of goods by appealing to a principle of diminishing marginal utility. Other consequentialists, however, incorporate a more robust commitment to equality. Early on, Sidgwick (1907, 417) responded to such objections by allowing distribution to break ties between other values. More recently, some consequentialists have added some notion of fairness (Broome 1991, 192–200) or desert (Feldman 1997, 154–74) to their test of which outcome is best. (See also Kagan 1998, 48–59.) Others turn to prioritarianism, which puts more weight on people who are worse off (Adler and Norheim 2022, Arneson 2022). Such consequentialists do not simply add up values; they look at patterns.</blockquote></p><p><blockquote>implies that the government should provide contraceptives, since that program reduces pain (and other disvalues), even though it also decreases total net pleasure (or good). Unfortunately, negative utilitarianism also seems to imply that the government should painlessly kill everyone it can, since dead people feel no pain (and have no false beliefs, diseases, or disabilities – though killing them does cause loss of ability). A more popular response is average utilitarianism, which says that the best consequences are those with the highest average utility (cf. Rawls 1971, 161–75). The average utility would be higher with the contraceptive program than without it, so average utilitarianism yields the more plausible result—that the government should adopt the contraceptive program. Critics sometimes charge that the average utility could also be increased by killing the worst off, but this claim is not at all clear, because such killing would put everyone in danger (since, after the worst off are killed, another group becomes the worst off, and then they might be killed next). Still, average utilitarianism faces problems of its own (such as “the mere addition paradox” in Parfit 1984, chap. 19). In any case, all maximizing consequentialists, whether or not they are pluralists, must decide whether moral rightness depends on maximizing total good or average good.</blockquote></p><p>A final challenge to consequentialists’ accounts of value derives from Geach 1956 and has been pressed by Thomson 2001. Thomson argues that “A is a good X” (such as a good poison) does not entail “A is good”, so the term “good” is an attributive adjective and cannot legitimately be used without qualification. On this view, it is senseless to call something good unless this means that it is good for someone or in some respect or for some use or at some activity or as an instance of some kind. Consequentialists are supposed to violate this restriction when they say that the total or average consequences or the world as a whole is good without any such qualification. However, consequentialists can respond either that the term “good” has predicative uses in addition to its attributive uses or that when they call a world or total set of consequences good, they are calling it good for consequences or for a world (Sinnott-Armstrong 2003a). If so, the fact that “good” is often used attributively creates no problem for consequentialists.\n<blockquote>A second set of problems for classic utilitarianism is epistemological. Classic utilitarianism seems to require that agents calculate all consequences of each act for every person for all time. That’s impossible.</blockquote></p><p><blockquote>, that is, as a method that agents consciously apply to acts in advance to help them make decisions. However, most classic and contemporary utilitarians and consequentialists do not propose their principles as decision procedures. (Bales 1971) Bentham wrote, “It is not to be expected that this process \\[his hedonic calculus\\] should be strictly pursued previously to every moral judgment.” (1789, Chap. IV, Sec. VI) Mill agreed, “it is a misapprehension of the utilitarian mode of thought to conceive it as implying that people should fix their minds upon so wide a generality as the world, or society at large.” (1861, Chap. II, Par. 19) Sidgwick added, “It is not necessary that the end which gives the criterion of rightness should always be the end at which we consciously aim.” (1907, 413)</blockquote></p><p><blockquote>of what is morally right or morally ought to be done. Their theories are intended to spell out the necessary and sufficient conditions for an act to be morally right, regardless of whether the agent can tell in advance whether those conditions are met. Just as the laws of physics govern golf ball flight, but golfers need not calculate physical forces while planning shots; so overall utility can determine which decisions are morally right, even if agents need not calculate utilities while making decisions. If the principle of utility is used as a criterion of the right rather than as a decision procedure, then classical utilitarianism does not require that anyone know the total consequences of anything before making a decision.</blockquote></p><p>Furthermore, a utilitarian criterion of right implies that it would not be morally right to use the principle of utility as a decision procedure in cases where it would not maximize utility to try to calculate utilities before acting. Utilitarians regularly argue that most people in most circumstances ought not to try to calculate utilities, because they are too likely to make serious miscalculations that will lead them to perform actions that reduce utility. It is even possible to hold that most agents usually ought to follow their moral intuitions, because these intuitions evolved to lead us to perform acts that maximize utility, at least in likely circumstances (Hare 1981, 46–47). Some utilitarians (Sidgwick 1907, 489–90) suggest that a utilitarian decision procedure may be adopted as an esoteric morality by an elite group that is better at calculating utilities, but utilitarians can, instead, hold that nobody should use the principle of utility as a decision procedure.</p><p>This move is supposed to make consequentialism self-refuting, according to some opponents. However, there is nothing incoherent about proposing a decision procedure that is separate from one’s criterion of the right. Similar distinctions apply in other normative realms. The criterion of a good stock investment is its total return, but the best decision procedure still might be to reduce risk by buying an index fund or blue-chip stocks. Criteria can, thus, be self-effacing without being self-refuting (Parfit 1984, chs. 1 and 4).</p><p>Others object that this move takes the force out of consequentialism, because it leads agents to ignore consequentialism when they make real decisions. However, a criterion of the right can be useful at a higher level by helping us choose among available decision procedures and refine our decision procedures as circumstances change and we gain more experience and knowledge. Hence, most consequentialists do not mind giving up consequentialism as a direct decision procedure as long as consequences remain the criterion of rightness (but see Chappell 2001).</p><p>If overall utility is the criterion of moral rightness, then it might seem that nobody could know what is morally right. If so, classical utilitarianism leads to moral skepticism. However, utilitarians insist that we can have strong reasons to believe that certain acts reduce utility, even if we have not yet inspected or predicted every consequence of those acts. For example, in normal circumstances, if someone were to torture and kill his children, it is possible that this would maximize utility, but that is very unlikely. Maybe they would have grown up to be mass murders, but it is at least as likely that they would grow up to cure serious diseases or do other great things, and it is much more likely that they would have led normally happy (or at least not destructive) lives. So observers as well as agents have adequate reasons to believe that such acts are morally wrong, according to act utilitarianism. In many other cases, it will still be hard to tell whether an act will maximize utility, but that shows only that there are severe limits to our knowledge of what is morally right. That should be neither surprising nor problematic for utilitarians.</p><p>If utilitarians want their theory to allow more moral knowledge, they can make a different kind of move by turning from actual consequences to expected or expectable consequences. Suppose that Alice finds a runaway teenager who asks for money to get home. Alice wants to help and reasonably believes that buying a bus ticket home for this runaway will help, so she buys a bus ticket and puts the runaway on the bus. Unfortunately, the bus is involved in a freak accident, and the runaway is killed. If actual consequences are what determine moral wrongness, then it was morally wrong for Alice to buy the bus ticket for this runaway. Opponents claim that this result is absurd enough to refute classic utilitarianism.</p><p><blockquote>.</blockquote></p><p><blockquote>, unlike the case of Alice. Some philosophers deny that probability can be fully objective, but at least the consequences here are foreseeable by others who are more informed than Don can be at the time. For Don to feed the rotten meat to his sister is, therefore, morally wrong if likely consequences are what matter, but not morally wrong if what matter are foreseen or foreseeable or intended consequences.</blockquote></p><p><blockquote>. Consequentialist moral theories that focus on reasonably foreseeable consequences are then not subjective insofar as they do not depend on anything inside the actual subject’s mind, but they are subjective insofar as they do depend on which consequences this particular subject would foresee if he or she were better informed or more rational.</blockquote></p><p><blockquote>, makes it much easier for agents and observers to justify moral judgments of acts because it obviates the need to predict non-proximate consequences in distant times and places. Hence, this move is worth considering, even though it has never been developed as far as I know and deviates far from traditional consequentialism, which counts not only proximate consequences but all upshots — that is, everything for which the act is a causally necessary condition.</blockquote>\n<blockquote>Another problem for utilitarianism is that it seems to overlook justice and rights. One common illustration is called Transplant. Imagine that each of five patients in a hospital will die without an organ transplant. The patient in Room 1 needs a heart, the patient in Room 2 needs a liver, the patient in Room 3 needs a kidney, and so on. The person in Room 6 is in the hospital for routine tests. Luckily (for them, not for him!), his tissue is compatible with the other five patients, and a specialist is available to transplant his organs into the other five. This operation would save all five of their lives, while killing the “donor”. There is no other way to save any of the other five patients (Foot 1966, Thomson 1976; compare related cases in Carritt 1947 and McCloskey 1965).</blockquote></p><p>We need to add that the organ recipients will emerge healthy, the source of the organs will remain secret, the doctor won’t be caught or punished for cutting up the “donor”, and the doctor knows all of this to a high degree of probability (despite the fact that many others will help in the operation). Still, with the right details filled in (no matter how unrealistic), it looks as if cutting up the “donor” will maximize utility, since five lives have more utility than one life (assuming that the five lives do not contribute too much to overpopulation). If so, then classical utilitarianism implies that it would not be morally wrong for the doctor to perform the transplant and even that it would be morally wrong for the doctor not to perform the transplant. Most people find this result abominable. They take this example to show how bad it can be when utilitarians overlook individual rights, such as the unwilling donor’s right to life.</p><p>Utilitarians can bite the bullet, again. They can deny that it is morally wrong to cut up the “donor” in these circumstances. Of course, doctors still should not cut up their patients in anything close to normal circumstances, but this example is so abnormal and unrealistic that we should not expect our normal moral rules to apply, and we should not trust our moral intuitions, which evolved to fit normal situations (Sprigge 1965). Many utilitarians are happy to reject common moral intuitions in this case, like many others (cf. Singer 1974, Unger 1996, Norcross 1997).</p><p>Most utilitarians lack such strong stomachs (or teeth), so they modify utilitarianism to bring it in line with common moral intuitions, including the intuition that doctors should not cut up innocent patients. One attempt claims that a killing is worse than a death. The doctor would have to kill the “donor” in order to prevent the deaths of the five patients, but nobody is killed if the five patients die. If one killing is worse than five deaths that do not involve killing, then the world that results from the doctor performing the transplant is worse than the world that results from the doctor not performing the transplant. With this new theory of value, consequentialists can agree with others that it is morally wrong for the doctor to cut up the “donor” in this example.</p><p><blockquote>the value of life by not causing loss of life (cf. Pettit 1997).</blockquote></p><p><blockquote>, plus the claim that the world with the transplant is worse from the perspective of the doctor, could justify the doctor’s judgment that it would be morally wrong for him to perform the transplant. A key move here is to adopt the agent’s perspective in judging the agent’s act. Agent-neutral consequentialists judge all acts from the observer’s perspective, so they would judge the doctor’s act to be wrong, since the world with the transplant is better from an observer’s perspective. In contrast, an agent-relative approach requires observers to adopt the doctor’s perspective in judging whether it would be morally wrong for the doctor to perform the transplant. This kind of agent-relative consequentialism is then supposed to capture commonsense moral intuitions in such cases (Portmore 2011).</blockquote></p><p>Agent-relativity is also supposed to solve other problems. W. D. Ross (1930, 34–35) argued that, if breaking a promise created only slightly more happiness overall than keeping the promise, then the agent morally ought to break the promise according to classic utilitarianism. This supposed counterexample cannot be avoided simply by claiming that keeping promises has agent-neutral value, since keeping one promise might prevent someone else from keeping another promise. Still, agent-relative consequentialists can respond that keeping a promise has great value from the perspective of the agent who made the promise and chooses whether or not to keep it, so the world where a promise is kept is better from the agent’s perspective than another world where the promise is not kept, unless enough other values override the value of keeping the promise. In this way, agent-relative consequentialists can explain why agents morally ought not to break their promises in just the kind of case that Ross raised.</p><p>Similarly, critics of utilitarianism often argue that utilitarians cannot be good friends, because a good friend places more weight on the welfare of his or her friends than on the welfare of strangers, but utilitarianism requires impartiality among all people. However, agent-relative consequentialists can assign more weight to the welfare of a friend of an agent when assessing the value of the consequences of that agent’s acts. In this way, consequentialists try to capture common moral intuitions about the duties of friendship (see also Jackson 1991).</p><p>One final variation still causes trouble. Imagine that the doctor herself wounded the five people who need organs. If the doctor does not save their lives, then she will have killed them herself. In this case, even if the doctor can disvalue killings by herself more than killings by other people, the world still seems better from her own perspective if she performs the transplant. Critics will object that it is, nonetheless, morally wrong for the doctor to perform the transplant. Many people will not find this intuition as clear as in the other cases, but consequentialists who do find it immoral for the doctor to perform the transplant even in this case will need to modify consequentialism in some other way in order to yield the desired judgment.</p><p>This problem cannot be solved by building rights or fairness or desert into the theory of value. The five do not deserve to die, and they do deserve their lives, just as much as the one does. Each option violates someone’s right not to be killed and is unfair to someone. So consequentialists need more than just new values if they want to avoid endorsing this transplant.</p><p><blockquote>direct consequentialist (Pettit and Smith 2000, Driver 2012).</blockquote></p><p><blockquote>, which holds that whether an act is morally right depends on whether it stems from or expresses a state of character that maximizes good consequences and, hence, is a virtue.</blockquote></p><p><blockquote>: an act is morally wrong if and only if it violates a rule whose public acceptance maximizes the good.</blockquote></p><p>The indirectness of such rule utilitarianism provides a way to remain consequentialist and yet capture the common moral intuition that it is immoral to perform the transplant in the above situation. Suppose people generally accepted a rule that allows a doctor to transplant organs from a healthy person without consent when the doctor believes that this transplant will maximize utility. Widely accepting this rule would lead to many transplants that do not maximize utility, since doctors (like most people) are prone to errors in predicting consequences and weighing utilities. Moreover, if the rule is publicly known, then patients will fear that they might be used as organ sources, so they would be less likely to go to a doctor when they need one. The medical profession depends on trust that this public rule would undermine. For such reasons, some rule utilitarians conclude that it would not maximize utility for people generally to accept a rule that allows doctors to transplant organs from unwilling donors. If this claim is correct, then rule utilitarianism implies that it is morally wrong for a particular doctor to use an unwilling donor, even for a particular transplant that would have better consequences than any alternative even from the doctor’s own perspective. Common moral intuition is thereby preserved.</p><p>Rule utilitarianism faces several potential counterexamples (such as whether public rules allowing slavery could sometimes maximize utility) and needs to be formulated more precisely (particularly in order to avoid collapsing into act-utilitarianism; cf. Lyons 1965). Such details are discussed in another entry in this encyclopedia (see Hooker on rule-consequentialism). Here I will just point out that direct consequentialists find it convoluted and implausible to judge a particular act by the consequences of something else (Smart 1956). Why should mistakes by other doctors in other cases make this doctor’s act morally wrong, when this doctor knows for sure that he is not mistaken in this case? Rule consequentialists can respond that we should not claim special rights or permissions that we are not willing to grant to every other person, and that it is arrogant to think we are less prone to mistakes than other people are. However, this doctor can reply that he is willing to give everyone the right to violate the usual rules in the rare cases when they do know for sure that violating those rules really maximizes utility. Anyway, even if rule utilitarianism accords with some common substantive moral intuitions, it still seems counterintuitive in other ways. This makes it worthwhile to consider how direct consequentialists can bring their views in line with common moral intuitions, and whether they need to do so.\n<blockquote>Another popular charge is that classic utilitarianism demands too much, because it requires us to do acts that are or should be moral options (neither obligatory nor forbidden). (Scheffler 1982) For example, imagine that my old shoes are serviceable but dirty, so I want a new pair of shoes that costs $100. I could wear my old shoes and give the $100 to a charity that will use my money to save someone else’s life. It would seem to maximize utility for me to give the $100 to the charity. If it is morally wrong to do anything other than what maximizes utility, then it is morally wrong for me to buy the shoes. But buying the shoes does not seem morally wrong. It might be morally better to give the money to charity, but such contributions seem supererogatory, that is, above and beyond the call of duty. Of course, there are many more cases like this. When I watch television, I always (or almost always) could do more good by helping others, but it does not seem morally wrong to watch television. When I choose to teach philosophy rather than working for CARE or the Peace Corps, my choice probably fails to maximize utility overall. If we were required to maximize utility, then we would have to make very different choices in many areas of our lives. The requirement to maximize utility, thus, strikes many people as too demanding because it interferes with the personal decisions that most of us feel should be left up to the individual.</blockquote></p><p>Some utilitarians respond by arguing that we really are morally required to change our lives so as to do a lot more to increase overall utility (see Kagan 1989, P. Singer 1993, and Unger 1996). Such hard-liners claim that most of what most people do is morally wrong, because most people rarely maximize utility. Some such wrongdoing might be blameless when agents act from innocent or even desirable motives, but it is still supposed to be moral wrongdoing. Opponents of utilitarianism find this claim implausible, but it is not obvious that their counter-utilitarian intuitions are reliable or well-grounded (Murphy 2000, chs. 1–4; cf. Mulgan 2001, Singer 2005, Greene 2013).</p><p><blockquote>only when both it fails to maximize utility and its agent is liable to punishment for the failure (Mill 1861). It does not always maximize utility to punish people for failing to maximize utility. Thus, on this view, it is not always morally wrong to fail to do what one morally ought to do. If Mill is correct about this, then utilitarians can say that we ought to give much more to charity, but we are not required or obliged to do so, and failing to do so is not morally wrong (cf. Sinnott-Armstrong 2005).</blockquote></p><p>Many utilitarians still want to avoid the claim that we morally ought to give so much to charity. One way around this claim uses a rule-utilitarian theory of what we morally ought to do. If it costs too much to internalize rules implying that we ought to give so much to charity, then, according to such rule-utilitarianism, it is not true that we ought to give so much to charity (Hooker 2000, ch. 8).</p><p>Another route follows an agent-relative theory of value. If there is more value in benefiting oneself or one’s family and friends than there is disvalue in letting strangers die (without killing them), then spending resources on oneself or one’s family and friends would maximize the good. A problem is that such consequentialism would seem to imply that we morally ought not to contribute those resources to charity, although such contributions seem at least permissible.</p><p>More personal leeway could also be allowed by deploying the legal notion of proximate causation. When a starving stranger would stay alive if and only if one contributed to a charity, contributing to the charity still need not be the proximate cause of the stranger’s life, and failing to contribute need not be the proximate cause of his or her death. Thus, if an act is morally right when it includes the most net good in its proximate consequences, then it might not be morally wrong either to contribute to the charity or to fail to do so. This potential position, as mentioned above, has not yet been developed, as far as I know.</p><p><blockquote>, which holds that we morally ought to improve the world or make it better than it would be if we did nothing, but we don’t have to improve it as much as we can (Elliot and Jamieson, 2009). Both satisficing and progressive consequentialism allow us to devote some of our time and money to personal projects that do not maximize overall good.</blockquote></p><p><blockquote>could say that one ought to give $1000 in contrast with $100 but not in contrast with $10,000 (cf. Snedegar 2017). Such positions can also hold that less or less severe negative sanctions are justified when an agent’s act is worse than a smaller set of alternatives compared to when the agent’s act is worse than a larger set of alternatives. This approach then becomes less demanding, both because it sees less negative sanctions as justified when the agent fails to do the best act possible, and also because it avoids saying that everyday actions are simply wrong without comparison to any set of alternatives.</blockquote></p><p>Opponents still object that all such consequentialist theories are misdirected. When I decide to visit a friend instead of working for a charity, I can know that my act is not immoral even if I have not calculated that the visit will create enough overall good or that it will improve the world. These critics hold that friendship requires us to do certain favors for friends without weighing our friends’ welfare impartially against the welfare of strangers. Similarly, if I need to choose between saving my drowning wife and saving a drowning stranger, it would be “one thought too many” (Williams 1981) for me to calculate the consequences of each act. I morally should save my wife straightaway without calculating utilities.</p><p>In response, utilitarians can remind critics that the principle of utility is intended as only a criterion of right and not as a decision procedure, so utilitarianism does not imply that people ought to calculate utilities before acting (Railton 1984). Consequentialists can also allow the special perspective of a friend or spouse to be reflected in agent-relative value assessments (Sen 1982, Broome 1991, Portmore 2001, 2003) or probability assessments (Jackson 1991). It remains controversial, however, whether any form of consequentialism can adequately incorporate common moral intuitions about friendship.\n<blockquote>Even if consequentialists can accommodate or explain away common moral intuitions, that might seem only to answer objections without yet giving any positive reason to accept consequentialism. However, most people begin with the <em>presumption</em> that we morally ought to make the world better when we can. The question then is only whether any moral constraints or moral options need to be added to the basic consequentialist factor in moral reasoning. (Kagan 1989, 1998) If no objection reveals any need for anything beyond consequences, then consequences alone seem to determine what is morally right or wrong, just as consequentialists claim.</blockquote></p><p>This line of reasoning will not convince opponents who remain unsatisfied by consequentialist responses to objections. Moreover, even if consequentialists do respond adequately to every proposed objection, that would not show that consequentialism is correct or even defensible. It might face new problems that nobody has yet recognized. Even if every possible objection is refuted, we might have no reason to reject consequentialism but still no reason to accept it.</p><p><blockquote>will be only as strong as the set of objections to the alternatives, and the argument fails if even one competitor survives. Moreover, the argument assumes that the original list is complete. It is hard to see how that assumption could be justified.</blockquote></p><p><blockquote>of our moral intuitions. This argument might surprise those who think of consequentialism as counterintuitive, but in fact consequentialists can explain many moral intuitions that trouble deontological theories. Moderate deontologists, for example, often judge that it is morally wrong to kill one person to save five but not morally wrong to kill one person to save a million. They never specify the line between what is morally wrong and what is not morally wrong, and it is hard to imagine any non-arbitrary way for deontologists to justify a cutoff point. In contrast, consequentialists can simply say that the line belongs wherever the benefits most outweigh the costs, including any bad side effects (cf. Sinnott-Armstrong 2007). Similarly, when two promises conflict, it often seems clear which one we should keep, and that intuition can often be explained by the amount of harm that would be caused by breaking each promise. In contrast, deontologists are hard pressed to explain which promise is overriding if the reason to keep each promise is simply that it was made (Sinnott-Armstrong 2009). If consequentialists can better explain more common moral intuitions, then consequentialism might have more explanatory coherence overall, despite being counterintuitive in some cases. (Compare Sidgwick 1907, Book IV, Chap. III; and Sverdlik 2011.) And even if act consequentialists cannot argue in this way, it still might work for rule consequentialists (such as Hooker 2000).</blockquote></p><p><blockquote>arguments from abstract moral intuitions. Sidgwick (1907, Book III, Chap. XIII) seemed to think that the principle of utility follows from certain very general self-evident principles, including universalizability (if an act ought to be done, then every other act that resembles it in all relevant respects also ought to be done), rationality (one ought to aim at the good generally rather than at any particular part of the good), and equality (“the good of any one individual is of no more importance, from the point of view ... of the Universe, than the good of any other”).</blockquote></p><p>Other consequentialists are more skeptical about moral intuitions, so they seek foundations outside morality, either in non-normative facts or in non-moral norms. Mill (1861) is infamous for his “proof” of the principle of utility from empirical observations about what we desire (cf. Sayre-McCord 2001). In contrast, Hare (1963, 1981) tries to derive his version of utilitarianism from substantively neutral accounts of morality, of moral language, and of rationality (cf. Sinnott-Armstrong 2001). Similarly, Gewirth (1978) tries to derive his variant of consequentialism from metaphysical truths about actions.</p><p><blockquote>. Harsanyi (1977, 1978) argues that all informed, rational people whose impartiality is ensured because they do not know their place in society would favor a kind of consequentialism. Broome (1991) elaborates and extends Harsanyi’s argument.</blockquote></p><p>Other forms of arguments have also been invoked on behalf of consequentialism (e.g. Cummiskey 1996, P. Singer 1993; Sinnott-Armstrong 1992). However, each of these arguments has also been subjected to criticisms.</p><p>Even if none of these arguments proves consequentialism, there still might be no adequate reason to deny consequentialism. We might have no reason either to deny consequentialism or to assert it. Consequentialism could then remain a live option even if it is not proven.</p>"
  },
  {
    "id": "20240821234347795766070",
    "title": "Trump's Lies",
    "source": "https://www.npr.org/2024/08/11/nx-s1-5070566/trump-news-conference",
    "fileType": "URL",
    "status": "unread",
    "tags": [
      "Politics",
      "News"
    ],
    "read": {
      "text": "56 min read",
      "minutes": 55.12,
      "time": 3307200,
      "words": 11024
    },
    "markdown": "<p><blockquote>Former President Donald Trump, the Republican presidential nominee, speaks during a news conference at his Mar-a-Lago estate in Florida on Aug. 8. <strong>Joe Raedle/Getty Images</strong> <strong>**hide caption</strong>**</blockquote></p><p><blockquote>**</blockquote></p><p>Joe Raedle/Getty Images</p><p>There were a host of false things that Donald Trump said during his hour-long news conference Thursday that have gotten attention.</p><p><blockquote>.</blockquote></p><p>But there was so much more. A team of NPR reporters and editors reviewed the transcript of his news conference and found at least 162 misstatements, exaggerations and outright lies in 64 minutes. That’s more than two a minute. It’s a stunning number for anyone – and even more problematic for a person running to lead the free world.</p><p><blockquote>.</blockquote></p><p>The expectation, though, is that they will treat the truth as something important and correct any errors.</p><p>But what former President Trump did this past Thursday went well beyond the bounds of what most politicians would do.</p><p>Here’s what we found, going chronologically from the beginning of Trump’s remarks to the end:</p><p><blockquote>The U.S. economy has rebounded from the pandemic downturn more rapidly than most other countries around the world. Growth has slowed in recent months, but gross domestic product still grew at a relatively healthy annual clip of 2.8% in April, May and June – which is faster than the pace in three of the four years when Trump was president. — <em>Scott Horsley, NPR chief economics correspondent</em></blockquote></p><p><blockquote>We don’t have great, up-to-date data on gang activity in the U.S., but violent crime trends offer a good glimpse into safety in the country. Nationally, violent crime – that includes murder, rape, robbery and aggravated assault – has been trending way down after a surge in 2020, according to the <a href=\"https://www.fbi.gov/news/press-releases/fbi-releases-2024-quarterly-crime-report-and-use-of-force-data-update\">most recent data from the FBI</a>. That data is preliminary and incomplete, covering around <a href=\"https://jasher.substack.com/p/the-fbis-data-shows-a-massive-decline\">three-quarters</a> of the country, but other crime analysts <a href=\"https://jasher.substack.com/p/crime-at-midyear-sizable-declines\">have found similar trends.</a> Crime levels, of course, <a href=\"https://www.ahdatalytics.com/dashboards/ytd-murder-comparison/\">vary locally</a>: murders are down in Philadelphia, for instance, but up in Charlotte, N.C. <em>— Meg Anderson, NPR National Desk reporter covering criminal justice</em></blockquote></p><p><blockquote>The U.S. is not in the “most dangerous position” from a foreign-policy standpoint than ever before. Biden pulled troops out of Afghanistan in his first year in office — though the withdrawal itself was chaotic and a target of much criticism — and since then, U.S. troops have not been actively engaged in a war for the first time in 20 years. The U.S. is supporting Ukraine and Israel, of course, and has troops in Iraq and Syria, but they’re not fighting on any regular basis.</blockquote></p><p><blockquote><strong>4-5.</strong> “<strong>We have a lot of bad things coming up. You could end up in a Depression of the 1929 variety, which would be a devastating thing, took many years– took many decades to recover from it, and we’re very close to that.”</strong></blockquote></p><p><blockquote><strong>6\\. “And we’re very close to a world war. In my opinion, we’re very close to a world war.”</strong></blockquote></p><p><blockquote><strong>7\\.</strong> “<strong>Kamala's record is horrible. She's a radical left person at a level that nobody's seen.”</strong> </blockquote></p><p>It’s debatable how liberal Harris is. Some in California didn’t like her record on criminal justice and thought she was not progressive enough. She’s clearly liked by progressives and her voting scores as a senator are on the liberal end of the spectrum, but is she “radical left” and “at a level that nobody’s seen”? There are plenty of people alive and in history who would be considered far more liberal and more radical.</p><p><blockquote>Few, if any, reasonable people would say Walz is a “radical left man.” He had a progressive record as governor with a Democratic legislature, but the things passed are hardly radical – free school lunch, protecting abortion rights, legalizing marijuana, restricting access to certain types of guns. All of these things have majority support from voters. What’s more, that “progressive” record ignores Walz’s first term as governor when he worked with Republicans because Democrats didn’t control the legislature. And it ignores Walz’s time as a congressman when he was considered a more moderate member given that he was from a district that had been previously held by a Republican.</blockquote></p><p><blockquote>Last year, Walz <a href=\"https://www.npr.org/2023/04/21/1171069066/states-protect-transgender-affirming-care-minnesota-colorado-maryland-illinois\">championed and signed a bill</a> that prevented state courts of officials from complying with child-removal requests, extraditions, arrests or subpoenas related to gender-affirming health care that a person receives or provides in Minnesota. “Heavy into the transgender world” is vague and misleading.</blockquote></p><p><blockquote>Walz has never called for having no borders. He has voiced opposition to a wall because he doesn't think it will stop illegal immigration. He <a href=\"https://transcripts.cnn.com/show/acd/date/2024-07-30/segment/01\">told Anderson Cooper on CNN</a>, for example, that a wall \"is not how you stop\" illegal immigration He called for more border-control agents, electronics and more legal ways to immigrate.</blockquote></p><p><blockquote>Trump <a href=\"https://abcnews.go.com/US/despite-new-criticism-trump-told-walz-2020-happy/story?id=112616502\">himself praised Walz’s handling of the aftermath</a> of the George Floyd murder at the hands of a police officer. And it’s certainly hyperbole to say he “doesn’t want any form of safety for our country.” Walz served in the U.S. National Guard for 24 years, so clearly, he’s interested in the country having national security. And domestically, he’s never been a “defund the police” advocate. Walz opposed a ballot measure that would have gotten rid of minimum police staffing levels, for example. That angered advocates. He <a href=\"https://minnesotareformer.com/2024/08/07/heres-what-tim-walz-has-done-as-governor-of-minnesota/\">signed police reforms into law</a>, but that does not prove wanting no safety.</blockquote></p><p><blockquote>Walz has not said he wants people coming in from prisons. Trump is trying to tie his claim that other countries are sending prisoners to the United States to Democrats’ immigration policies.</blockquote></p><p><blockquote>Harris has said a lot to the contrary of not caring about the levels of migrants coming across the border, let alone people coming in from prisons. In fact, when in Guatemala, she said her message for people thinking of immigrating to the United States was: \"<a href=\"https://www.npr.org/2021/06/07/1004074139/harris-tells-guatemalans-not-to-migrate-to-the-united-states\">Do not come. Do not come</a>.\"</blockquote></p><p><blockquote>Harris was never appointed “border czar.” That’s a phrase that was used incorrectly by some media outlets. Biden tasked Harris with leading the “<a href=\"http://whitehouse.gov/briefing-room/speeches-remarks/2021/03/24/remarks-by-president-biden-and-vice-president-harris-in-a-meeting-on-immigration/\">diplomatic effort</a>” with leaders in Central American countries, where many migrants are coming from.</blockquote></p><p>Biden said he wants Harris “to lead our efforts with Mexico and the Northern Triangle and the countries that help — are going to need help in stemming the movement of so many folks, stemming the migration to our southern border.” He added that Harris “agreed to lead our diplomatic effort and work with those nations to accept — the returnees, and enhance migration enforcement at their borders — at their borders.”</p><p>Harris herself that day spoke of “the need to address root causes for the migration that we’ve been seeing.”</p><p><blockquote>The stock market did not “crash.” The stock market fell sharply at the end of last week as investors fretted about a softening job market. This was amplified on Monday when Japan’s stock market tumbled 12%, sparking a selloff around the world. Stocks in Japan and elsewhere have since regained much of this ground, however. The Dow Jones Industrial Average jumped 683 points on the day of Trump’s news conference. — <em>Scott Horsley</em></blockquote></p><p><blockquote>Most good polls have shown Harris gaining not just nationally, but also in the swing states, though these same polls show a very close race.</blockquote></p><p><blockquote>Trump is not substantially leading, and Rasmussen is <a href=\"https://projects.fivethirtyeight.com/pollster-ratings/\">viewed as one of the least credible</a> pollsters in the country.</blockquote></p><p><blockquote>Polls have not shown substantial leads. <a href=\"https://www.cnbc.com/2024/08/08/trump-holds-2-point-lead-over-harris-with-a-big-advantage-on-economy-cnbc-survey-shows.html\">CNBC</a> had Trump leading by 2, unchanged from his 2-point lead in July.</blockquote></p><p><blockquote>Again, polls in swing states have shown a tightened race.</blockquote></p><p><blockquote>Vice President Harris was never asked to lead immigration policy. That’s the job of Homeland Security Secretary Alejandro Mayorkas. Again, the term “border czar” was used inaccurately by some media outlets, and it’s a term conservatives have been using to attack her, in part, because she has only visited the Southern U.S. border a few times since 2021. But in reality, Harris was tapped by President Biden <a href=\"https://www.npr.org/2024/07/22/nx-s1-5048025/kamala-harris-immigration-policy-border-central-america\">to address the root causes of migration</a>. Her approach has focused on deterrence. She’s told migrants to not come to the U.S., and she has been able to secure <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2024/03/25/fact-sheet-vice-president-harris-announces-public-private-partnership-has-generated-more-than-5-2-billion-in-private-sector-commitments-for-northern-central-america/\">more than $5 billion in commitments</a> from private companies to help boost the economy in Central American countries. — <em>Sergio Martínez-Beltrán, NPR immigration correspondent based in Texas</em> </blockquote></p><p><blockquote>It’s unclear where Trump is getting this number from. According to <a href=\"https://www.cbp.gov/newsroom/stats/nationwide-encounters\">U.S. Customs and Border Protection</a>, since 2021 agents have had more than 7.3 million encounters nationwide with migrants trying to cross into the country illegally. Under Biden, unlawful crossings hit an all-time high last year, but that number has decreased significantly, in part, due to Biden’s asylum restrictions at the Southern U.S. border. An <a href=\"https://www.dhs.gov/sites/default/files/2024-05/2024<em>0418</em>ohss<em>estimates-of-the-unauthorized-immigrant-population-residing-in-the-united-states-january-2018%E2%80%93january-2022.pdf\">April report</a> from the Office of Homeland Security Statistics found there’s nearly 11 million unauthorized migrants in the country. — </em>Sergio Martínez-Beltrán_</blockquote></p><p><blockquote>Neither Russia nor Ukraine is revealing its own casualty figures, so there are only very broad estimates. — <em>Andrew Sussman</em> </blockquote></p><p><blockquote>Grocery prices actually jumped sharply during Trump’s last year in office, as pandemic lockdowns disrupted the food supply chain and Americans were suddenly forced to eat more of their meals at home. Grocery inflation in June 2020 hit 5.6%. This was masked, however, by a plunge in other prices, as the global economy fell into pandemic recession.</blockquote></p><p><blockquote>than they were before the pandemic – a potent reminder of the rising cost of living.</blockquote></p><p><blockquote><strong>24\\. “We've agreed with NBC, fairly full agreement, subject to them, on Sept. 10th.”</strong></blockquote></p><p>This is ABC, not NBC.</p><p><blockquote>Harris hasn’t done interviews since getting into the campaign, but she has done them in the past, so saying “she can’t do” one or that she is “barely competent” are just insults. Trump tends to revert to questioning the intelligence of Black women who challenge him. In fact, Trump did it nine times in this news conference, saying either Harris is not that “smart” (five times) \"incompetent” (three times) or “barely competent,” as he did here.</blockquote></p><p><blockquote>Immigration experts have said they have not been able to find any evidence of this. Adam Isacson, director for defense oversight at the Washington Office on Latin America, told <a href=\"http://factcheck.org/\">FactCheck.org</a>: “It’s hard to prove a negative — nobody’s writing a report saying, ‘Ecuador is not opening its mental institutions’ — but what I can say is that I work full-time on migration, am on many coalition mailing lists, correspond constantly with partners in the region, and scan 300+ RSS feeds and Twitter lists of press outlets and activists region wide, and I have not seen a single report indicating that this is happening. … As far as I can tell, it’s a total fabrication.”</blockquote></p><p><blockquote>noted three years later: “Back in 1980, it seemed to be a humanitarian and patriotic gesture to accept provisionally, without papers or visas, all those fleeing from the port of Mariel. More than 125,000 came. Most were true refugees, many had families here, and the great majority has settled into American communities without mishap. But the Cuban dictator played a cruel joke. He opened his jails and mental hospitals and put their inmates on the boats too.”</blockquote></p><p><blockquote>, immigrants are less likely to commit a crime than U.S.-born people and certainly at no higher rates that the population writ large. (Trump goes on to repeat this claim minutes later in the news conference as well, so it is included in our count here.)</blockquote></p><p><blockquote>Trump may have this opinion, but he says it as if it’s fact, and a <a href=\"https://www.cbsnews.com/pictures/presidents-ranked-worst-best/\">2022 survey of historians</a> ranked Biden in the top half of presidents. Trump, on the other hand, was No. 43. The two below Trump were James Buchanan, who did little to stop the impending U.S. Civil War, and the impeached and nearly convicted Andrew Johnson.</blockquote></p><p><blockquote>A <a href=\"https://www.latimes.com/opinion/story/2024-07-07/vice-president-trump-biden-running-mate-election-2024\">recent rating of vice presidents</a> did not show this. Harris was in the bottom half of vice presidents, but Spiro Agnew, Dan Quayle, Henry A. Wallace and were toward the bottom of the list.</blockquote></p><p><blockquote>This might have been true about a year ago or so, but not anymore. An NBC poll then showed Harris had the lowest favorability rating of any modern VP they’d tested. But her numbers have turned around. The NPR poll had Harris with a 46%/48% favorable to unfavorable rating, which was higher than Trump’s and his running mate, JD Vance, who is <a href=\"https://www.newsweek.com/jd-vance-least-liked-vp-nominee-decades-polls-1929470\">among the least popular running mates in recent history</a>.</blockquote></p><p><blockquote>Harris was not “defeated,” because she dropped out of the Democratic presidential race before Iowa. But even if one considers her dropping out on Dec. 3, 2019, a defeat, she was not the first of the Democratic candidates in that primary campaign to do so. At least <a href=\"https://www.npr.org/2019/01/31/689980506/which-democrats-are-running-in-2020-and-which-still-might\">10 others dropped out sooner</a>.</blockquote></p><p><blockquote>There’s nothing in the U.S. Constitution about picking presidential candidates. This is a party process, and everything has been done within party rules. And, again, the presidency wasn’t taken away: Biden is still president.</blockquote></p><p><blockquote>This was never floated as a possibility to get Biden to withdraw from the race. Biden’s Cabinet members are all people he appointed and who are loyal to him. In addition, the 25th Amendment outlines a procedure for removing a sitting president from office, not from running for a second term.</blockquote></p><p><blockquote>This was not said; he did not hear; no Democrats in the know are talking to Trump; and this dialogue is made up.</blockquote></p><p><blockquote>The race is statistically tied in national polls and in the states. In some national polls, Harris leads. In some, Trump does.</blockquote></p><p><blockquote>Again, this is Trump talking about how Biden stepped aside, and there’s nothing in the Constitution about how the political parties should pick candidates. And nothing was taken away.</blockquote></p><p><blockquote>Trump can’t speak to Biden’s state of mind; all evidence is that Nancy Pelosi is perfectly sane – see her recent multiple rounds of interviews about her book, <a href=\"https://www.npr.org/2024/08/06/nx-s1-4932870/pelosi-talks-power-and-bidens-exit-from-the-2024-race\">including with NPR</a>; again, Trump doesn’t know Biden’s state of mind; and again, nobody took it away.</blockquote></p><p><blockquote>(1) As previously noted, she was not put in charge of the border and certainly did not have “everything” to do with it; (2) she was not appointed to head the border; (3) if “they” is the White House, then “they” did not call her “border czar”; (4) Trump doesn’t know what Harris might have thought about the term; (5) Harris did not go to a place at the border “you would love to go and have dinner with your husband or whoever.”</blockquote></p><p><blockquote>in El Paso, Texas, visited an area where asylum seekers were screened, and met with migrants. Republicans criticized her at the time for not going to the Rio Grande Valley.</blockquote></p><p><blockquote>World history is filled with cases where one country has crossed a border and invaded a neighboring country.</blockquote></p><p><blockquote>As San Francisco’s district attorney from 2004 to 2011, and then California’s attorney general until 2017, it’s true that Kamala Harris was deeply connected to how crime was prosecuted during that particular period. However, no single person is responsible for destroying any city or state, not to mention that both are not destroyed.</blockquote></p><p><blockquote>During her campaign for the 2020 nomination, she rolled out a plan that <a href=\"https://www.politico.com/story/2019/09/09/kamala-harris-criminal-justice-reform-1485443\">would have phased out cash bail</a>, and she <a href=\"https://www.facebook.com/photo.php?fbid=10157660207382923&id=24413227922&set=a.391094312922\">pledged to eliminate it</a> as president because “no one should have to sit in jail for days or even years because they don’t have the money to pay bail.” But in the same campaign, during a debate, former Hawaii Rep. Tulsi Gabbard <a href=\"https://www.pbs.org/newshour/show/a-look-at-kamala-harris-legal-career-and-political-record\">criticized</a> Harris for keeping cash bail in place as district attorney.</blockquote></p><p><blockquote>The justice system was not weaponized against Trump. Biden went through pains to not show any interference with the Justice Department. And Trump was found guilty by a jury of his peers in New York in a state case.</blockquote></p><p><blockquote>(1) Trump did not “win” the classified documents case against him in Florida; (2) this was not “the big case” against him; (3) there was plenty of coverage of it; and (4) he goes on to repeat that he won the case later.</blockquote></p><p>For context: the judge in the case controversially dismissed it, claiming the special counsel was unconstitutionally appointed despite Supreme Court decisions upholding independent counsels. The Justice Department has signaled it will appeal by the end of August but by the time the decision comes back, the election will be over.</p><p>Trump had four criminal cases against him including the classified documents case – the fraudulent business practices case in New York, for which he was convicted on 34 felony counts; an election interference case in Georgia; and the other federal case dealing with Jan. 6. If there was a biggest case, it was the last one.</p><p><blockquote>There has been lots of criticism of the judge in the case, Aileen Cannon, who Trump appointed. She had very little experience as a trial judge, made several decisions that were questioned by legal experts and early in this case, had a ruling, in which she called for a special master to review classified documents first, overturned by the 11th Circuit.</blockquote></p><p><blockquote>This was not “Biden’s case.” It was to be tried by special counsel Jack Smith, who was appointed by Attorney General Merrick Garland. The Biden White House has made efforts to keep an arms-length distance from the investigation. Biden often declined to comment on the Justice Department’s and state investigations into Trump when it would likely have been politically advantageous for him to talk about it on the campaign trail.</blockquote></p><p><blockquote>This appears to be a misrepresentation of what special counsel Robert Hur said of Biden in a report he released investigating the president’s handling of classified documents. Hur said he wouldn’t be charging Biden, called the president “an elderly man with a poor memory\" and said a jury might find sympathy with him because of it. He did not say Biden was incompetent and could not stand trial.</blockquote></p><p><blockquote>This is false. Harris <a href=\"https://www.verifythis.com/article/news/verify/elections-verify/trumps-claim-kamala-harris-did-not-pass-bar-exam-misleading/536-58ff74fa-b025-47d2-882e-45b718878666\">passed her bar exam on the second try</a>. She failed on first attempt, which is not unusual for California’s bar exam given its difficulty.</blockquote></p><p><blockquote>Trump was not doing “very well” with Black voters. Biden was not doing as well with Black voters as he did in 2020, according to most surveys, but that didn’t mean Black voters were moving heavily toward Trump. Many seemed more likely not to vote. There were signs that Trump was doing better with Black men, but there wasn’t much good evidence to support this in polling, considering most national polls have such high margins of error with voter groups. A typical national survey might have 1,000 voters and 100 or so Black voters, give or take. That’s typically a margin of error upward of +/- 10 percentage points, meaning results could be a whopping 10 points higher or lower.</blockquote></p><p><blockquote>Like with Black voters, it’s difficult to tell in most national surveys exactly how well a candidate is doing with Latino voters because of high margins of error. “Extremely well” depends on how it’s defined, but this is an exaggeration.</blockquote></p><p><blockquote>Jewish voters traditionally vote <a href=\"https://www.jewishvirtuallibrary.org/jewish-voting-record-in-u-s-presidential-elections\">roughly 2-to-1 for Democrats</a> in presidential elections, so this seems more like a hope than reality.</blockquote></p><p><blockquote>It’s just not the case that Trump is “way up.” <a href=\"https://maristpoll.marist.edu/wp-content/uploads/2024/08/NPR<em>PBS-News</em>Marist-Poll<em>USA-NOS-and-Tables</em>486202408050954.pdf\">NPR polling</a> finds that while Trump is doing as well as ever with white men without college degrees, Harris – and Biden before her – is actually leading with white men with college degrees, a group Trump won in 2020, according to <a href=\"https://www.cnn.com/election/2020/exit-polls/president/national-results\">exit polls</a>.</blockquote></p><p><blockquote>Trump is not doing well with Black females. Black women are a key pillar Democratic voting group, and Black voters have moved more in Harris’ favor since she’s gotten in.</blockquote></p><p><blockquote>This is not the case. See earlier fact check. (He repeats this again later in the press conference, so it is included here in the count.)</blockquote></p><p><blockquote>A Fox News poll last month showed Pennsylvania Gov. Josh Shapiro, a finalist to be Harris’ running mate, had a <a href=\"https://www.foxnews.com/official-polls/fox-news-poll-harris-trump-dead-heat-pennsylvania\">61% approval rating</a> in the state. <a href=\"https://www.abc27.com/pennsylvania-politics/new-poll-highlights-josh-shapiro-approval-rating-during-vp-search/\">Other polls</a> also found him with a net-positive rating, though, not quite as high.</blockquote></p><p><blockquote>It was reported that the numbers come from faulty information about the size of a crowd at Trump’s rally. More accurate estimates appear to be <a href=\"https://www.newsweek.com/fact-check-logan-paul-new-jersey-donald-trump-rally-1913041\">anywhere from 30,000 to 60,000</a>. Still, a very large crowd, but Trump is exaggerating here.</blockquote></p><p><blockquote>(1-3) Trump gave at least three incorrect estimates here, downplaying Harris’ crowd sizes (2,000, 1,500 and 1,000); (4) He also far overestimated how big his crowd sizes are compared to Harris’; (5-6) He twice said the press is dishonest about her crowd size and about his.</blockquote></p><p><blockquote>or more at each rally. What the exact number is might be unclear — as is often the case with crowd-size estimates — but they were bigger than 2,000 and 1,500. Reporters have often commented on the size of Trump’s crowds. Frequently, they are very large, certainly larger than ones that Hillary Clinton drew in 2016 or Joe Biden this year, but Trump also regularly exaggerates their sizes.</blockquote></p><p><blockquote>This is speculation, and that there is simply no way to know what would have happened in either case if he'd been reelected.</blockquote></p><p><blockquote>Again, this is speculative. Energy and food prices jumped sharply around the world following Russia’s invasion of Ukraine and the resulting sanctions on Russian energy. Gasoline prices in the U.S. hit a record high topping $5 a gallon. But domestic energy production has not suffered during the Biden administration. In fact, <a href=\"https://www.eia.gov/todayinenergy/detail.php?id=61545\">U.S. oil</a> and <a href=\"https://www.eia.gov/todayinenergy/detail.php?id=61263#:~:text=U.S.%20dry%20natural%20gas%20production,Bcf%2Fd\">natural gas</a>%20from%202022.) production hit record highs last year. AAA reports the average price of gasoline today is $3.45/gallon. — <em>Scott Horsley</em></blockquote></p><p><blockquote>Oil and gas production has largely been determined by energy companies. They were disciplined about not expanding production when prices were low but have become more aggressive as prices climbed. While Kamala Harris opposed “fracking” for oil and gas during her 2019 presidential campaign, she now says she would not try to outlaw the practice – which is important in battleground states such as Pennsylvania. — <em>Scott Horsley</em></blockquote></p><p><blockquote>The Biden administration has set a goal of having <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/04/17/fact-sheet-biden-harris-administration-announces-new-private-and-public-sector-investments-for-affordable-electric-vehicles/\">50% of new vehicle sales be electric by 2030</a>. It has primarily tried to achieve this through carrots rather than sticks, offering incentives to make electric cars more affordable, encouraging the development of electric charging stations and using the federal government’s own purchasing power to create demand. — <em>Scott Horsley</em></blockquote></p><p><blockquote>A shift to electric vehicles will require a rapid updating and expansion of the U.S. power grid, according to the <a href=\"https://www.epri.com/research/products/000000003002030215\">Electric Power Research Institute</a>. However, as EVs become more efficient, the increased demand could be reduced by as much as 50% per mile traveled over the next three decades. — <em>Scott Horsley</em></blockquote></p><p><blockquote>Electric vehicles are typically heavier than gasoline-powered vehicles, because of the batteries. But the <a href=\"https://link.springer.com/article/10.1007/s10098-022-02433-8\">weight difference is about 30%</a>, not 250% as Trump said. What’s more, American vehicles have been getting heavier for decades, long before the move to EVs, thanks to the popularity of pickup trucks and SUVs.</blockquote></p><p><blockquote>While many bridges and other transportation infrastructure <a href=\"https://infrastructurereportcard.org/\">need improvement</a>, the <a href=\"https://link.springer.com/article/10.1007/s10098-022-02433-8\">additional weight of EVs</a> is just one of many factors that will need to be considered. Another challenge is that bridges and highways are typically funded through gasoline taxes. The shift to EVs, which don’t use gasoline, will require an alternate source of highway funding.</blockquote></p><p><blockquote>There were at least six different misstatements here – (1) Trump has had large crowds, but “in history,” there certainly there have been people with larger crowds, from Barack Obama and others; (2, 3) her crowds have been larger than 1,000, which he repeats twice; (4) no serious analysts have said this is the end of Trump’s campaign. This race is very close; (5) there’s no evidence for crowds of the size Trump notes in South Carolina and Alabama; (6) people do talk about Trump’s crowd sizes.</blockquote></p><p><blockquote>Someone has likely heard of whatever the unnamed country is.</blockquote></p><p><blockquote>The races in Georgia and Pennsylvania are within the margin of error, according to an average of the polls.</blockquote></p><p><blockquote>It does, and here’s why. Demographically, Georgia has become very different from South Carolina and Alabama. Georgia’s population is now majority-minority, according to the U.S. Census Bureau. Alabama and South Carolina are 64% and 63% white, respectively.</blockquote></p><p>Georgia’s Black population is also significant politically — 33% of the state’s population is Black. By comparison, Alabama is 27% Black, South Carolina 26%. Latinos also make up 11% of Georgia’s population and Asian Americans are 5%, both of which are higher than Alabama and South Carolina. And Georgia’s population is marginally younger — 15% of Georgia’s population is older than 65% compared to 18% in Alabama and 19% in South Carolina.</p><p><blockquote>Winning them by a lot is highly unlikely, considering how close the states have been in recent elections, but perhaps more pressing is Trump’s insinuation that there were voting problems in the two states, which there were not. That’s why Trump is upset with Republican Georgia Gov. Brian Kemp, for example, because he upheld the valid 2020 election results even in the face of pressure from Trump.</blockquote></p><p><blockquote>This wholly ignores the Jan. 6 siege on the Capitol, which took place because of Trump’s election lies.</blockquote></p><p><blockquote>Again, this is a very close race.</blockquote></p><p><blockquote>This is false. Since Super Tuesday, Democrats have outspent Trump’s campaign and outside groups supporting him by more than double, according to data provided by AdImpact and analyzed by NPR — $373.5 million to $150.6 million.</blockquote></p><p><blockquote>There is plenty of evidence that Harris is “smart enough to do a news conference,” as she has done in the past.</blockquote></p><p><blockquote>Again, no serious analyst believes this.</blockquote></p><p><blockquote>The Justice Department investigation into the events of Jan. 6, 2021, is the largest and most complex federal criminal probe in U.S. history, the attorney general has said. More than 140 law enforcement officers were injured that day, in what U.S. Attorney Matthew Graves has described as the biggest mass casualty event involving police. It’s hard to find any comparable event in recent American history.</blockquote></p><p>As of Aug. 6, 2024, according to Graves’s office, prosecutors have charged more than 160 people with using a deadly or dangerous weapon or causing serious bodily injury to an officer. Prosecutors have also secured convictions on the rarely-deployed charge of seditious conspiracy, or attempting to overthrow the government by use of force, against top leaders of the Oath Keepers and the Proud Boys.</p><p><blockquote><strong>102\\. “Nobody was killed on Jan. 6th.”</strong> </blockquote></p><p><blockquote>was also a result of Jan. 6.</blockquote></p><p><blockquote>It was not the biggest crowd he’s ever spoken to. His inauguration would have topped that. And others have had bigger crowds, as noted earlier.</blockquote></p><p><blockquote>While Trump did utter those words, it is misleading. Trump also said the word <a href=\"https://www.justsecurity.org/91904/dissecting-trumps-peacefully-and-patriotically-defense-of-the-january-6th-attack/\">“fight” multiple times</a>, and he told the already angry crowd because of the election lies he fed them: “We fight like Hell and if you don’t fight like Hell, you’re not going to have a country anymore.” Trump aides testified that he “refused” to tweet the word “peaceful” in the days leading up to the rally because he thought it might discourage people from being there, and he was concerned about his crowd size.</blockquote></p><p><blockquote>First, the speeches did not take place at the “same real estate.” Trump spoke from a position just south of the Ellipse. Martin Luther King Jr. spoke from the steps of the Lincoln Memorial</blockquote></p><p>Second, the crowds were not the same size and Trump’s was certainly not larger. It is an extraordinary claim and shows just how much Trump cares about crowd size.</p><p><blockquote>Again, there’s nothing in the Constitution about how parties should pick their presidents.</blockquote></p><p><blockquote>As explained earlier, this is not how Biden wound up stepping aside. The story is yet another Trump invention. He also lies here in saying that “they were going to go through a primary system” and “it would have to be” a quick primary system.” There’s no requirement that a primary is held. In fact, for many years, candidates’ selection as party nominees had nothing to do with primaries, and they were not as prevalent as today.</blockquote></p><p><blockquote>As explained earlier, Harris was not the first one out in the 2020 Democratic primary race. And “first loser” appears to be a name Trump made up at this news conference, as Harris has not been referred to that way as a result of her run for the 2020 nomination.</blockquote></p><p><blockquote>Once again, this is a false conspiracy invented by Trump.</blockquote></p><p><blockquote>Trump repeats this false line again.</blockquote></p><p><blockquote>Abortion rights as a political and social issue has certainly not “tempered down.” There are millions of women, especially across the South, who do not have access to abortion and women who have experienced pregnancy losses with the inability to access medications for those necessary procedures.</blockquote></p><p><blockquote>Everybody absolutely did not want that. It was actually quite unpopular for the Supreme Court to overturn <em>Roe</em>. And he again repeats that it has become less of an issue.</blockquote></p><p><blockquote><strong>“I think it's actually going to be a very small issue. What I've done is I've done what every Democrat and every Every Republican wanted to have done.”</strong> </blockquote></p><p><blockquote>Minutes apart from each other, he repeats these three false claims. Abortion rights is not a “very small” issue for millions of voters. Democrats are organizing around it, and it has been seminal to Biden and Harris’ campaigns.</blockquote></p><p><blockquote>This is a distortion Republicans continue to push about what former Virginia Gov. Ralph Northam said. This has been <a href=\"https://www.reuters.com/article/world/fact-check-virginia-governors-2019-comments-about-abortion-bill-are-missing-co-idUSKBN27D2GS/\">fact-checked by others multiple times</a>.</blockquote></p><p><blockquote><strong>“Everybody wanted it in the states.”</strong></blockquote></p><p><blockquote>He once again returns to the issue of abortions, which remains a “factor,” not everybody wanted it in the states, the issue is not “very much subdued.”</blockquote></p><p><blockquote>Harris has not proposed taking away all guns. She has proposed banning assault-style weapons, something that was in place for a decade. Some surveys had shown majority support for this. <a href=\"https://www.monmouth.edu/polling-institute/reports/monmouthpoll<em>us</em>042423/\">Others show</a> a split. (Trump makes this case later, as well, so that is also included in the count.)</blockquote></p><p><blockquote>It’s difficult to compare gun violence and gun laws in the United States to other countries, simply because of the staggering amount of guns we have here. Although the U.S. has less than 5% of the world’s population, it holds <a href=\"https://www.smallarmssurvey.org/database/global-firearms-holdings\">almost 40%</a> or <a href=\"https://www.cfr.org/backgrounder/us-gun-policy-global-comparisons\">more</a> of the world’s civilian-owned guns. And it has “the highest homicide-by-firearm rate of the world’s most developed nations,” per the <a href=\"https://www.cfr.org/backgrounder/us-gun-policy-global-comparisons\">Council on Foreign Relations</a>. Norway, Canada and Australia <a href=\"https://www.cfr.org/backgrounder/us-gun-policy-global-comparisons#chapter-title-0-1\">all tightened</a> their gun restrictions after shootings. <em>— Meg Anderson</em></blockquote></p><p><blockquote>Though Trump didn’t get the numbers exactly right, Chicago did have an incredibly violent July 4th holiday weekend this year. According to Mayor Brandon Johnson, more than 100 people were shot and 19 of those people died. Chicago does have strict gun laws, in part because its state does: Everytown For Gun Safety, a nonprofit that advocates for gun control, <a href=\"https://www.everytown.org/state/illinois/\">ranks Illinois third</a> in the nation for the strength of its gun-control laws. However, no state or city exists within a bubble, and Illinois is surrounded by states with much weaker laws, including Indiana, which is just a short drive from Chicago. <em>— Meg Anderson</em></blockquote></p><p><blockquote>This is, to put it charitably, misleading. It appears that he’s actually referencing the period when the Trump administration signed the deal with the Taliban, in advance of U.S. troops leaving. The deal said the U.S. would be out in 14 months, and in exchange the Taliban wouldn’t harbor terrorists and would stop attacking U.S. service members. Needless to say, the deal didn’t hold. <a href=\"https://apnews.com/article/fact-check-trump-afghanistan-troops-killed-659053265479\">But as the AP notes</a>, “There was an 18-month stretch that saw no combat, or ‘hostile,’ deaths in Afghanistan: from early February 2020 to August 2021.” – <em>Andrew Sussman</em></blockquote></p><p><blockquote>Harris does not support an Israel weapons embargo. A Biden administration official <a href=\"https://www.bbc.com/news/articles/cg798l439ydo\">posted on social media</a> that Harris \"has been clear: she will always ensure Israel is able to defend itself against Iran and Iran-backed terrorist groups.” A leader of the uncommitted movement said Harris “expressed an openness” to a meeting about an embargo, but the Biden administration official said Harris \"will continue to work to protect civilians in Gaza and to uphold international humanitarian law,” not that she would support an embargo.</blockquote></p><p><blockquote>Harris’ husband, Doug Emhoff, is Jewish. The couple has hosted Passover Seders.</blockquote></p><p><blockquote>This claim has not held up to scrutiny. <a href=\"https://www.politico.com/news/2024/08/09/trump-plane-crash-california-00173487\">Politico</a> reported that Trump did have to make an emergency landing in a helicopter with a Black California politician decades ago, but it wasn’t Willie Brown, the former San Francisco mayor and state assembly speaker. It was Nate Holden, a former Los Angeles city councilman and state senator.</blockquote></p><p><blockquote><strong>“He was not a fan of hers very much at that point.”</strong></blockquote></p><p>This is something Trump repeated twice, minutes apart from each other. Brown strongly denies having been on a helicopter with Trump or telling Trump negative things about Harris, whom he dated in the mid-1990s and supports now for president. The relationship ended in 1995.</p><p><blockquote>The 2017 tax cuts were not the biggest in history. As a share of the economy, they <a href=\"https://taxfoundation.org/blog/largest-tax-cuts-hikes-biden-trump-tax-proposals/\">barely make the top 10</a>. They were big enough, however, to blow a big hole in the federal budget, which is why Trump was overseeing a nearly $1 trillion dollar annual deficit before the pandemic. <em>— Scott Horsley</em></blockquote></p><p><blockquote>This is what Trump said will happen if his tax cuts are not renewed. But The 2017 tax cut <a href=\"https://www.npr.org/2019/12/20/789540931/2-years-later-trump-tax-cuts-have-failed-to-deliver-on-gops-promises\">did not deliver</a> the economic boom that its supporters promised, and there’s no reason to think reversing a portion of the cut would cause economic destruction. <em>— Scott Horsley</em></blockquote></p><p><blockquote>Vice President Harris has <a href=\"https://www.sacbee.com/news/politics-government/election/presidential-election/article290870409.html\">echoed</a> President Biden’s pledge not to raise taxes on anyone making less than $400,000. However, Biden has called for raising taxes on wealthy individuals and raising the corporate tax rate from 21% to 28% – halfway back to where it was before the 2017 cut. <em>— Scott Horsley</em></blockquote></p><p><blockquote>No Democratic presidential candidate has advocated “no security.”</blockquote></p><p><blockquote>An <a href=\"https://www.aei.org/foreign-and-defense-policy/the-defense-budget-through-administrations/\">analysis by the American Enterprise Institute, a conservative think tank, showed</a> a “review of historical defense budget trends shows there is more at play in determining overall investments in defense than just which party is in the White House.” Indeed, since the year 2000, U.S.-led wars overseas have resulted in a surge of spending by both Democratic and Republican administrations.</blockquote></p><p><blockquote>Harris, Walz and the Democratic Party have never said they want “no borders.” They certainly oppose Trump’s wall/fence along the entire U.S.-Mexico border, citing the exorbitant cost and its relative ineffectiveness, they say, compared to using other methods. (Trump later says that Harris wants “open borders,” so that’s included in the count here.)</blockquote></p><p><blockquote>Again, this is misleading and suggests Harris wants to increase taxes across the board when they have consistently talked about increasing taxes only on the wealthy. In Harris’ view, those making more than <a href=\"https://www.sacbee.com/news/politics-government/election/presidential-election/article290870409.html\">$400,000 a year</a>.</blockquote></p><p><blockquote>Democrats have consistently advocated for keeping Social Security and making it solvent.</blockquote></p><p><blockquote>In congressional testimony this year, Attorney General Merrick Garland told lawmakers that President Biden had never called him to discuss any of the cases against Trump. Garland also had aides review Justice Department leaders’ email for any correspondence with Manhattan District Attorney Alvin Bragg. In a letter to Congress in June 2024, the Justice Department said it had found no such contacts.</blockquote></p><p><blockquote><strong>143\\. “Any time you have mail-in ballots, you're gonna have problems. ... We should have one-day voting; we should have paper ballots; we should have voter ID; and we should have proof of citizenship.”</strong> </blockquote></p><p><blockquote>found that in the 2024 general election, \"nearly 99% of all registered voters will live in jurisdictions where they can cast a ballot with a paper record of the vote.\"</blockquote></p><p><blockquote><strong>144\\. “The polls have suggested, there are some polls that say we're going to win in a landslide.”</strong> </blockquote></p><p>There are no polls that suggest Trump will win in a landslide. By all accounts, this is a very close race.</p><p><blockquote>The rise in grocery prices is a <a href=\"https://www.npr.org/2024/07/10/nx-s1-5033145/inflation-food-grocery-prices-economy\">common complaint</a>, but Trump exaggerates the scale of the increase. According to the Consumer Price Index, grocery prices have risen 25% since before the pandemic and 21% since President Biden took office. (At the same time, average wages have risen 23% since before the pandemic and 17% since President Biden took office.)</blockquote></p><p><blockquote><strong>“He's sucked all of the oil out.”</strong></blockquote></p><p><blockquote><strong>“They've just, for the sake of getting some votes, for the sake of having gasoline–. You know, that's meant for wars. It's meant for, like, tragedy. It's not meant to keep a gasoline price down, so that somebody can vote for Biden or, in this case, Kamala.”</strong> </blockquote></p><p><blockquote>than when he got in.</blockquote></p><p><blockquote>The opposite is true. Harris has continued her momentum since getting into the race.</blockquote></p><p><blockquote>As addressed earlier, Harris is not entirely responsible for San Francisco or the state of California. Crime trends there were similar to national crime trends during her time as district attorney in San Francisco and as the state’s attorney general. What’s more, <a href=\"https://www.ahdatalytics.com/dashboards/ytd-murder-comparison/\">preliminary data</a> for this year indicates that many cities in California, including San Francisco, are seeing murder rates falling. (Trump repeats the claim one more time later in the news conference, so it is included in the count here.) <em>— Meg Anderson</em></blockquote></p><p><blockquote>Although Harris did <a href=\"https://www.washingtonpost.com/outlook/2020/08/14/her-memoir-kamala-harris-calls-social-change-plays-inside-game/\">refer to herself</a> in her 2019 memoir as a “progressive prosecutor,” her legacy has <a href=\"https://www.npr.org/2024/07/26/nx-s1-5048844/how-a-president-harris-might-handle-criminal-justice-issues\">largely been seen</a> as tougher on crime. She has supported some progressive reforms, such as pretrial diversion, which offers certain criminal defendants things like drug treatment instead of going to trial. — <em>Meg Anderson</em></blockquote></p><p><blockquote>Trump <a href=\"https://www.cnn.com/2024/06/02/politics/fact-check-trump-false-claim-lock-up-hillary-clinton/index.html\">called for Clinton’s imprisonment multiple times</a>, including going along with crowd chants of “lock her up.”</blockquote></p><p><blockquote>Clinton aides requested emails be deleted months before the subpoena, and the FBI said there’s no evidence the messages were deleted with a subpoena in mind. — <em>Carrie Johnson</em></blockquote></p><p><blockquote>The Justice Department closed an investigation into Hillary Clinton’s use of a private email server to conduct some State Department business in 2016. Then-FBI Director Jim Comey gave a press conference to explain his reasoning in July of that election year. Comey said, “We did not find clear evidence that Secretary Clinton or her colleagues intended to violate laws governing the handling of classified information,” but he criticized Clinton and her aides for being “extremely careless in their handling of very sensitive, highly classified information” that flowed through the server.</blockquote></p><p><blockquote><strong>157\\. “A lot of the MAGA, as they call them, but the base. And I think the base is, I think the base is 75% of the country, far beyond the Republican Party.”</strong></blockquote></p><p><blockquote>for popular votes. Lyndon B. Johnson got 61% in 1964, Richard Nixon slightly less than 61% in 1972, Ronald Reagan 59% in 1984. Since then, Barack Obama got nearly 53% in 2008 and 51% in 2012, the first candidate since Eisenhower to win at least 51% of the vote twice.</blockquote></p><p><blockquote>Trump here is talking about membership in the National Rifle Association. Another family member being an NRA member does not make someone else an NRA member “indirectly.”</blockquote></p><p><blockquote>Presumably, Trump is talking about Alice Marie Johnson, who had been <a href=\"https://www.npr.org/2018/06/06/617513060/president-trump-commutes-sentence-of-grandmother-serving-life-in-prison\">convicted on cocaine conspiracy and money laundering charges</a>. Kim Kardashian advocated for Johnson and won a pardon for her from Trump.</blockquote></p><p><blockquote>More than 60 court cases proved there was not widespread fraud or cheating that would have made any difference in any state.</blockquote></p><p><blockquote>This is a conspiracy not based in fact. Immigrants in the country illegally cannot vote in presidential elections, and <a href=\"https://www.cnn.com/2024/07/09/politics/republicans-noncitizen-voting-elections-trump/index.html\">there’s no evidence there is an intentional effort to sign them up in mass numbers</a> to sway elections.</blockquote></p><p><blockquote>The subject of sanctuary cities actually mostly splits Californians. <a href=\"https://www.courthousenews.com/poll-shows-sanctuary-law-divides-california-voters/\">Slim majorities</a> have actually said that they favor the sanctuary-state law and are against their cities opting out of the law. Of course, this breaks down along party lines, and since California is heavily Democratic, those results might not be surprising. But it’s more divided than Trump suggests.</blockquote></p>"
  }
]